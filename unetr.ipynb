{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AddChanneld,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    NormalizeIntensityd,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    "    ToTensord,\n",
    ")\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNETR, UNet\n",
    "\n",
    "from monai.data import (\n",
    "    DataLoader,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    ")\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "size = (96,96,96)\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup transforms for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        AddChanneld(keys=[\"image\", \"label\"]),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        # ScaleIntensityRanged(\n",
    "        #     keys=[\"image\"],\n",
    "        #     a_min=-175,\n",
    "        #     a_max=250,\n",
    "        #     b_min=0.0,\n",
    "        #     b_max=1.0,\n",
    "        #     clip=True,\n",
    "        # ),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=size,\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[0],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[1],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[2],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandRotate90d(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            prob=0.10,\n",
    "            max_k=3,\n",
    "        ),\n",
    "        RandShiftIntensityd(\n",
    "            keys=[\"image\"],\n",
    "            offsets=0.10,\n",
    "            prob=0.50,\n",
    "        ),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        AddChanneld(keys=[\"image\", \"label\"]),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        # ScaleIntensityRanged(\n",
    "        #     keys=[\"image\"], a_min=-175, a_max=250, b_min=0.0, b_max=1.0, clip=True\n",
    "        # ),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download dataset and format in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "def liver_bounding_box(liver):\n",
    "\n",
    "    X, Y, Z = np.where(liver > 0)\n",
    "    return np.min(X), np.max(X), np.min(Y), np.max(Y), np.min(Z), np.max(Z)\n",
    "\n",
    "def get_average_liver_size(dataset_path):\n",
    "\n",
    "    shapes = np.zeros((35,6))\n",
    "    idx = 0\n",
    "\n",
    "    for name in sorted(os.listdir(os.path.join(os.path.abspath(os.getcwd()), 'VEELA/dataset'))):\n",
    "        if '-VE-liv.nii.gz' in name:\n",
    "            liver_nifti = nib.load(os.path.join(os.path.abspath(os.getcwd()), 'VEELA/dataset/' + name))\n",
    "            liver = liver_nifti.get_fdata()\n",
    "            shapes[idx,0], shapes[idx,1], shapes[idx,2], shapes[idx,3], shapes[idx,4], shapes[idx,5] = liver_bounding_box(liver)\n",
    "            idx +=1\n",
    "    \n",
    "    shapes_average = np.mean(shapes, axis = 0).astype(int)\n",
    "    print('Average liver coordinates:\\n\\tx_min: {}\\tx_max: {}\\n\\ty_min: {}\\ty_max: {}\\n\\tz_min: {}\\tz_max: {}\\nAverage size: {}x{}x{}'.format(\n",
    "           int(shapes_average[0]), int(shapes_average[1]), int(shapes_average[2]), int(shapes_average[3]), int(shapes_average[4]), int(shapes_average[5]),\n",
    "           int(abs(shapes_average[0] - shapes_average[1]) + 1), \n",
    "           int(abs(shapes_average[2] - shapes_average[3]) + 1), \n",
    "           int(abs(shapes_average[4] - shapes_average[5]) + 1), \n",
    "    ))\n",
    "    return [int(abs(shapes_average[0] - shapes_average[1]) + 1), int(abs(shapes_average[2] - shapes_average[3]) + 1), int(abs(shapes_average[4] - shapes_average[5]) + 1)], shapes.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_size,liver_coord = get_average_liver_size(os.path.join(os.path.abspath(os.getcwd()), 'VEELA/dataset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_value_to_dict(dict_obj, key, value):\n",
    "\n",
    "    # Check if key exist in dict or not\n",
    "    if key in dict_obj:\n",
    "        # Key exist in dict.\n",
    "        # Check if type of value of key is list or not\n",
    "        if not isinstance(dict_obj[key], list):\n",
    "            # If type is not list then make it list\n",
    "            dict_obj[key] = [dict_obj[key]]\n",
    "        # Append the value in list\n",
    "        dict_obj[key].append(value)\n",
    "    else:\n",
    "        # As key is not in dict,\n",
    "        # so, add key-value pair\n",
    "        dict_obj[key] = value\n",
    "\n",
    "def get_liver_bounding_box(liver):\n",
    "\n",
    "    X, Y, Z = np.where(liver > 0)\n",
    "    return np.array([np.min(X), np.max(X), np.min(Y), np.max(Y), np.min(Z), np.max(Z)])\n",
    "\n",
    "def process_dataset(dataset_path, info_dict):\n",
    "\n",
    "    for name in sorted(os.listdir(dataset_path)):\n",
    "        if '-VE-liv.nii.gz' in name: # LIVER MASKS\n",
    "            liver_nifti = nib.load(dataset_path + '/'+name)\n",
    "            liver_coords = get_liver_bounding_box(liver_nifti.get_fdata())\n",
    "            append_value_to_dict(info_dict, 'Liver coordinates', liver_coords)\n",
    "            append_value_to_dict(info_dict, 'Affine matrix', liver_nifti.affine)\n",
    "        \n",
    "        elif '-VE.nii.gz' in name: # INPUT VOLUME\n",
    "            append_value_to_dict(info_dict, 'Image name', name)\n",
    "            append_value_to_dict(info_dict, 'Volume shape', nib.load(dataset_path + '/'+ name).shape)\n",
    "            append_value_to_dict(info_dict, 'Header', nib.load(dataset_path + '/'+ name).header)\n",
    "            append_value_to_dict(info_dict, 'Image nifti object', nib.load(dataset_path + '/'+ name))\n",
    "        \n",
    "        elif '-VE-por.nii.gz' in name: # PORTAL VEINS\n",
    "            append_value_to_dict(info_dict, 'Portal veins name', name)\n",
    "            append_value_to_dict(info_dict, 'Portal nifti object', nib.load(dataset_path + '/'+ name))\n",
    "        elif '-VE-hep.nii.gz' in name: # HEPATIC VEINS\n",
    "            append_value_to_dict(info_dict, 'Hepatic veins name', name)\n",
    "            append_value_to_dict(info_dict, 'Hepatic nifti object', nib.load(dataset_path + '/'+ name))\n",
    "\n",
    "    return info_dict\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dict = process_dataset(os.path.join(os.path.abspath(os.getcwd()), 'VEELA/dataset'), info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r /home/guijosa/Documents/PythonDocs/UNETR/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.transform as skTrans\n",
    "\n",
    "def create_directory():\n",
    "    os.makedirs(\"./data/imagesTr\")\n",
    "    os.makedirs(\"./data/labelsTr\")\n",
    "    os.makedirs(\"./data/imagesTs\")\n",
    "    os.makedirs(\"./data/labelsTs\")\n",
    "    os.makedirs(\"./data/results\")\n",
    "\n",
    "def split_dataset(info_dict, dataset_path):\n",
    "\n",
    "    for idx, name in enumerate(info_dict['Image name']):\n",
    "        ima = nib.load(os.path.join(dataset_path, name)).get_fdata()\n",
    "        # 3D indexing volume_images\n",
    "        liver = ima[\n",
    "            info_dict['Liver coordinates'][idx][0]:info_dict['Liver coordinates'][idx][1] + 1,\n",
    "            info_dict['Liver coordinates'][idx][2]:info_dict['Liver coordinates'][idx][3] + 1,\n",
    "            info_dict['Liver coordinates'][idx][4]:info_dict['Liver coordinates'][idx][5] + 1\n",
    "        ]\n",
    "        # resized_liver = skTrans.resize(liver, (average_size[0], average_size[1], average_size[2]), order = 1, preserve_range=True)\n",
    "        resized_liver = skTrans.resize(liver, size, order = 1, preserve_range=True)\n",
    "        output_ima = nib.Nifti1Image(resized_liver, info_dict['Affine matrix'][idx], info_dict['Header'][idx])\n",
    "        if len(os.listdir('./data/imagesTr')) < 28:\n",
    "            nib.save(output_ima, './data/imagesTr/' + info_dict['Image name'][idx].split('.')[0] + '-liver.nii.gz')\n",
    "        else:\n",
    "            nib.save(output_ima, './data/imagesTs/' + info_dict['Image name'][idx].split('.')[0] + '-liver.nii.gz')\n",
    "\n",
    "    for idx, name in enumerate(info_dict['Portal veins name']):\n",
    "        ima = nib.load(os.path.join(dataset_path, name)).get_fdata().astype(np.uint8)\n",
    "        # 3D indexing\n",
    "        liver = ima[\n",
    "            info_dict['Liver coordinates'][idx][0]:info_dict['Liver coordinates'][idx][1] + 1,\n",
    "            info_dict['Liver coordinates'][idx][2]:info_dict['Liver coordinates'][idx][3] + 1,\n",
    "            info_dict['Liver coordinates'][idx][4]:info_dict['Liver coordinates'][idx][5] + 1\n",
    "        ]\n",
    "        # resized_liver = skTrans.resize(liver, (average_size[0], average_size[1], average_size[2]), order = 1, preserve_range=True)\n",
    "        resized_liver = skTrans.resize(liver, size, preserve_range=True)\n",
    "\n",
    "        resized_liver[np.where(resized_liver > 0.95)] = 1\n",
    "        resized_liver[np.where(resized_liver != 1)] = 0\n",
    "\n",
    "        output_ima = nib.Nifti1Image(resized_liver, info_dict['Affine matrix'][idx], info_dict['Header'][idx])\n",
    "        if len(os.listdir('./data/labelsTr')) < 28:\n",
    "            nib.save(output_ima, './data/labelsTr/' + info_dict['Image name'][idx].split('.')[0] + '-liver_por_GT.nii.gz')\n",
    "        else:\n",
    "            nib.save(output_ima, './data/labelsTs/'+ info_dict['Image name'][idx].split('.')[0] + '-liver_por_GT.nii.gz')\n",
    "\n",
    "\n",
    "dataset_path = os.path.join(os.path.abspath(os.getcwd()), 'VEELA/dataset')\n",
    "try:\n",
    "    create_directory()\n",
    "    split_dataset(info_dict, dataset_path)\n",
    "    \n",
    "except FileExistsError:\n",
    "    # split_dataset(info_dict, dataset_path)\n",
    "    pass\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-FOLD CROSS VALIDATION\n",
    "\n",
    "# Numer of folds\n",
    "k = 4\n",
    "# Split dataset for Training, Validation and Test\n",
    "split =[23, 5, 7]\n",
    "for fold in range(k):\n",
    "    create_directory()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.choice([1,8,3,5,9,1,6,3,9,5,1,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# EJECUTAR ESTEEEEEEEE\n",
    "\n",
    "# Data to be written\n",
    "dictionary = {\n",
    "    \"labels\": {\n",
    "        \"0\": \"background\",\n",
    "        \"1\": \"portal_vessels\"\n",
    "    },\n",
    "    \"modality\": {\n",
    "        \"0\": \"CT\"\n",
    "    },\n",
    "    \"numTest\": 20,\n",
    "    \"numTraining\": 80,\n",
    "    \"test\": [\n",
    "        \"imagesTs/033-VE-liver.nii.gz\",\n",
    "        \"imagesTs/034-VE-liver.nii.gz\",\n",
    "        \"imagesTs/035-VE-liver.nii.gz\",\n",
    "        \"imagesTs/036-VE-liver.nii.gz\",\n",
    "        \"imagesTs/037-VE-liver.nii.gz\",\n",
    "        \"imagesTs/039-VE-liver.nii.gz\",\n",
    "        \"imagesTs/040-VE-liver.nii.gz\"\n",
    "    ],\n",
    "    \"training\": [\n",
    "    {\n",
    "        \"image\": \"imagesTr/001-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/001-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/002-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/002-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/003-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/003-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/004-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/004-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/005-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/005-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/006-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/006-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/007-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/007-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/008-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/008-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/009-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/009-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/010-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/010-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/011-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/011-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/012-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/012-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/013-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/013-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/014-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/014-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/015-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/015-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/016-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/016-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/017-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/017-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/018-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/018-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/019-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/019-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/020-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/020-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/022-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/022-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/023-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/023-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/025-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/025-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "],\n",
    "    \"validation\": [\n",
    "    {\n",
    "        \"image\": \"imagesTr/027-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/027-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/028-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/028-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/030-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/030-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/031-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/031-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/032-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/032-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "]\n",
    "}\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(dictionary, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"./data/VEELA.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Data to be written\n",
    "dictionary = {\n",
    "   \"description\": \"btcv yucheng\",\n",
    "    \"labels\": {\n",
    "        \"0\": \"background\",\n",
    "        \"1\": \"portal_vessels\"\n",
    "    },\n",
    "    \"licence\": \"yt\",\n",
    "    \"modality\": {\n",
    "        \"0\": \"CT\"\n",
    "    },\n",
    "    \"name\": \"btcv\",\n",
    "    \"numTest\": 20,\n",
    "    \"numTraining\": 80,\n",
    "    \"reference\": \"Vanderbilt University\",\n",
    "    \"release\": \"1.0 02/02/2022\",\n",
    "    \"tensorImageSize\": \"3D\",\n",
    "    \"test\": [\n",
    "        \"imagesTs/033-VE-liver.nii.gz\",\n",
    "        \"imagesTs/034-VE-liver.nii.gz\",\n",
    "        \"imagesTs/035-VE-liver.nii.gz\",\n",
    "        \"imagesTs/036-VE-liver.nii.gz\",\n",
    "        \"imagesTs/037-VE-liver.nii.gz\",\n",
    "        \"imagesTs/039-VE-liver.nii.gz\",\n",
    "        \"imagesTs/040-VE-liver.nii.gz\"\n",
    "    ],\n",
    "    \"training\": [\n",
    "    {\n",
    "        \"image\": \"imagesTr/001-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/001-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/002-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/002-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/003-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/003-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/004-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/004-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/005-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/005-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/006-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/006-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/007-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/007-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/008-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/008-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/009-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/009-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/010-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/010-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/011-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/011-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/012-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/012-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/013-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/013-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/014-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/014-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/015-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/015-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/016-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/016-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/017-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/017-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/018-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/018-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/019-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/019-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/020-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/020-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/022-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/022-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/023-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/023-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/025-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/025-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "],\n",
    "\"validation\": [\n",
    "    {\n",
    "        \"image\": \"imagesTr/027-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/027-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/028-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/028-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/030-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/030-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/031-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/031-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"imagesTr/032-VE-liver.nii.gz\",\n",
    "        \"label\": \"labelsTr/032-VE-liver_por_GT.nii.gz\"\n",
    "    },\n",
    "]\n",
    "}\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(dictionary, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"./data/VEELA.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 23/23 [00:01<00:00, 20.10it/s]\n",
      "Loading dataset: 100%|██████████| 5/5 [00:00<00:00, 23.01it/s]\n"
     ]
    }
   ],
   "source": [
    "datasets = './data/VEELA.json'\n",
    "datalist = load_decathlon_datalist(datasets, True, \"training\")\n",
    "val_files = load_decathlon_datalist(datasets, True, \"validation\")\n",
    "train_ds = CacheDataset(\n",
    "    data=datalist,\n",
    "    transform=train_transforms,\n",
    "    cache_num=23,\n",
    "    cache_rate=1.0,\n",
    "    num_workers=8,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=8, shuffle=True, num_workers=8, pin_memory=True\n",
    ")\n",
    "val_ds = CacheDataset(\n",
    "    data=val_files, transform=val_transforms, cache_num=5, cache_rate=1.0, num_workers=4\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=8, shuffle=False, num_workers=4, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model, Loss, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=(16,32,64,128,256),\n",
    "    strides = (2,2,2,2)\n",
    "\n",
    ").to(device)\n",
    "\n",
    "loss_function = DiceCELoss(sigmoid=True)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = UNETR(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    img_size=size,\n",
    "    feature_size=16,\n",
    "    hidden_size=768, # 1920  768\n",
    "    mlp_dim=3072, # 7680   3072\n",
    "    num_heads=16,\n",
    "    pos_embed=\"perceptron\",\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    "    dropout_rate=0.0,\n",
    ").to(device)\n",
    "\n",
    "loss_function = DiceCELoss(sigmoid=True)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (1,96,96,96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute a typical Pytorch training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (2 / 25000 Steps) (loss=0.99552): 100%|██████████| 3/3 [00:02<00:00,  1.01it/s]\n",
      "Training (5 / 25000 Steps) (loss=0.99533): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (8 / 25000 Steps) (loss=0.99444): 100%|██████████| 3/3 [00:02<00:00,  1.22it/s]\n",
      "Training (11 / 25000 Steps) (loss=0.99489): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (14 / 25000 Steps) (loss=0.99512): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (17 / 25000 Steps) (loss=0.99399): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (20 / 25000 Steps) (loss=0.99275): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "Training (23 / 25000 Steps) (loss=0.99441): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (26 / 25000 Steps) (loss=0.99317): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (29 / 25000 Steps) (loss=0.99507): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (32 / 25000 Steps) (loss=0.99233): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (35 / 25000 Steps) (loss=0.99452): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (38 / 25000 Steps) (loss=0.99310): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (41 / 25000 Steps) (loss=0.99365): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (44 / 25000 Steps) (loss=0.99347): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (47 / 25000 Steps) (loss=0.99234): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (50 / 25000 Steps) (loss=0.99048): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (53 / 25000 Steps) (loss=0.99154): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (56 / 25000 Steps) (loss=0.99272): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (59 / 25000 Steps) (loss=0.99182): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (62 / 25000 Steps) (loss=0.99263): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (65 / 25000 Steps) (loss=0.99228): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (68 / 25000 Steps) (loss=0.99165): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (71 / 25000 Steps) (loss=0.99108): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (74 / 25000 Steps) (loss=0.99183): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (77 / 25000 Steps) (loss=0.98976): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (80 / 25000 Steps) (loss=0.99166): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (83 / 25000 Steps) (loss=0.99293): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (86 / 25000 Steps) (loss=0.99161): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (89 / 25000 Steps) (loss=0.99134): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (92 / 25000 Steps) (loss=0.99134): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (95 / 25000 Steps) (loss=0.99238): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (98 / 25000 Steps) (loss=0.99127): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (101 / 25000 Steps) (loss=0.99171): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (104 / 25000 Steps) (loss=0.98915): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (107 / 25000 Steps) (loss=0.99046): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (110 / 25000 Steps) (loss=0.99153): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (113 / 25000 Steps) (loss=0.99049): 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "Training (116 / 25000 Steps) (loss=0.98948): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (119 / 25000 Steps) (loss=0.99219): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (122 / 25000 Steps) (loss=0.98904): 100%|██████████| 3/3 [00:02<00:00,  1.14it/s]\n",
      "Training (125 / 25000 Steps) (loss=0.99021): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (128 / 25000 Steps) (loss=0.98972): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (131 / 25000 Steps) (loss=0.98828): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (134 / 25000 Steps) (loss=0.98872): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (137 / 25000 Steps) (loss=0.99057): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (140 / 25000 Steps) (loss=0.99093): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (143 / 25000 Steps) (loss=0.98960): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (146 / 25000 Steps) (loss=0.98908): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (149 / 25000 Steps) (loss=0.98998): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (152 / 25000 Steps) (loss=0.99049): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (155 / 25000 Steps) (loss=0.98765): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (158 / 25000 Steps) (loss=0.98884): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (161 / 25000 Steps) (loss=0.98833): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (164 / 25000 Steps) (loss=0.99064): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (167 / 25000 Steps) (loss=0.98945): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (170 / 25000 Steps) (loss=0.98824): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (173 / 25000 Steps) (loss=0.99080): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (176 / 25000 Steps) (loss=0.98971): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (179 / 25000 Steps) (loss=0.99027): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (182 / 25000 Steps) (loss=0.98853): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (185 / 25000 Steps) (loss=0.98786): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (188 / 25000 Steps) (loss=0.98925): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (191 / 25000 Steps) (loss=0.98798): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (194 / 25000 Steps) (loss=0.98896): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (197 / 25000 Steps) (loss=0.98937): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (200 / 25000 Steps) (loss=0.99103): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (203 / 25000 Steps) (loss=0.98859): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (206 / 25000 Steps) (loss=0.98843): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (209 / 25000 Steps) (loss=0.98906): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (212 / 25000 Steps) (loss=0.98884): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (215 / 25000 Steps) (loss=0.98974): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (218 / 25000 Steps) (loss=0.98927): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (221 / 25000 Steps) (loss=0.98693): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (224 / 25000 Steps) (loss=0.98601): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (227 / 25000 Steps) (loss=0.98701): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (230 / 25000 Steps) (loss=0.98702): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (233 / 25000 Steps) (loss=0.98885): 100%|██████████| 3/3 [00:02<00:00,  1.17it/s]\n",
      "Training (236 / 25000 Steps) (loss=0.98655): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (239 / 25000 Steps) (loss=0.98740): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (242 / 25000 Steps) (loss=0.98874): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (245 / 25000 Steps) (loss=0.98532): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (248 / 25000 Steps) (loss=0.98521): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (251 / 25000 Steps) (loss=0.98696): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (254 / 25000 Steps) (loss=0.98745): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (257 / 25000 Steps) (loss=0.98916): 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "Training (260 / 25000 Steps) (loss=0.98876): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (263 / 25000 Steps) (loss=0.98405): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (266 / 25000 Steps) (loss=0.98874): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (269 / 25000 Steps) (loss=0.98500): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (272 / 25000 Steps) (loss=0.98704): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (275 / 25000 Steps) (loss=0.98655): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (278 / 25000 Steps) (loss=0.98633): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (281 / 25000 Steps) (loss=0.98908): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (284 / 25000 Steps) (loss=0.98585): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (287 / 25000 Steps) (loss=0.98573): 100%|██████████| 3/3 [00:02<00:00,  1.32it/s]\n",
      "Training (290 / 25000 Steps) (loss=0.98417): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (293 / 25000 Steps) (loss=0.98351): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (296 / 25000 Steps) (loss=0.98599): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (299 / 25000 Steps) (loss=0.98534): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (302 / 25000 Steps) (loss=0.98468): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (305 / 25000 Steps) (loss=0.98325): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (308 / 25000 Steps) (loss=0.98666): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (311 / 25000 Steps) (loss=0.98610): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (314 / 25000 Steps) (loss=0.98589): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (317 / 25000 Steps) (loss=0.98578): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (320 / 25000 Steps) (loss=0.98401): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (323 / 25000 Steps) (loss=0.98463): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (326 / 25000 Steps) (loss=0.98578): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (329 / 25000 Steps) (loss=0.98599): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (332 / 25000 Steps) (loss=0.98659): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (335 / 25000 Steps) (loss=0.98521): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (338 / 25000 Steps) (loss=0.98437): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (341 / 25000 Steps) (loss=0.98574): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (344 / 25000 Steps) (loss=0.98268): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (347 / 25000 Steps) (loss=0.98394): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (350 / 25000 Steps) (loss=0.98289): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (353 / 25000 Steps) (loss=0.98352): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (356 / 25000 Steps) (loss=0.98448): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (359 / 25000 Steps) (loss=0.98318): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (362 / 25000 Steps) (loss=0.98614): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (365 / 25000 Steps) (loss=0.98350): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (368 / 25000 Steps) (loss=0.98588): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (371 / 25000 Steps) (loss=0.98559): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (374 / 25000 Steps) (loss=0.98149): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (377 / 25000 Steps) (loss=0.98228): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (380 / 25000 Steps) (loss=0.98240): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (383 / 25000 Steps) (loss=0.98181): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (386 / 25000 Steps) (loss=0.98396): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (389 / 25000 Steps) (loss=0.97963): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (392 / 25000 Steps) (loss=0.98349): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (395 / 25000 Steps) (loss=0.98244): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (398 / 25000 Steps) (loss=0.98030): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (401 / 25000 Steps) (loss=0.98305): 100%|██████████| 3/3 [00:02<00:00,  1.08it/s]\n",
      "Training (404 / 25000 Steps) (loss=0.98383): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (407 / 25000 Steps) (loss=0.97996): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (410 / 25000 Steps) (loss=0.98165): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (413 / 25000 Steps) (loss=0.98101): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (416 / 25000 Steps) (loss=0.98016): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (419 / 25000 Steps) (loss=0.98060): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (422 / 25000 Steps) (loss=0.98083): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (425 / 25000 Steps) (loss=0.97849): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (428 / 25000 Steps) (loss=0.98165): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (431 / 25000 Steps) (loss=0.98185): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (434 / 25000 Steps) (loss=0.98201): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (437 / 25000 Steps) (loss=0.97714): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (440 / 25000 Steps) (loss=0.98155): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (443 / 25000 Steps) (loss=0.98190): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (446 / 25000 Steps) (loss=0.97953): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (449 / 25000 Steps) (loss=0.97801): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (452 / 25000 Steps) (loss=0.97934): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (455 / 25000 Steps) (loss=0.97732): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (458 / 25000 Steps) (loss=0.97840): 100%|██████████| 3/3 [00:02<00:00,  1.35it/s]\n",
      "Training (461 / 25000 Steps) (loss=0.97967): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (464 / 25000 Steps) (loss=0.98028): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (467 / 25000 Steps) (loss=0.97748): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (470 / 25000 Steps) (loss=0.98082): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (473 / 25000 Steps) (loss=0.97855): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (476 / 25000 Steps) (loss=0.98103): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (479 / 25000 Steps) (loss=0.97632): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (482 / 25000 Steps) (loss=0.97937): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (485 / 25000 Steps) (loss=0.97902): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (488 / 25000 Steps) (loss=0.97818): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (491 / 25000 Steps) (loss=0.98046): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (494 / 25000 Steps) (loss=0.97457): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (497 / 25000 Steps) (loss=0.98116): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Validate (498 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]it]\n",
      "Training (500 / 25000 Steps) (loss=0.97515): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (500 / 25000 Steps) (loss=0.97515): 100%|██████████| 3/3 [00:02<00:00,  1.09it/s]\n",
      "Training (503 / 25000 Steps) (loss=0.97630): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (506 / 25000 Steps) (loss=0.97546): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (509 / 25000 Steps) (loss=0.97371): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (512 / 25000 Steps) (loss=0.97679): 100%|██████████| 3/3 [00:02<00:00,  1.09it/s]\n",
      "Training (515 / 25000 Steps) (loss=0.97363): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (518 / 25000 Steps) (loss=0.97866): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (521 / 25000 Steps) (loss=0.97950): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (524 / 25000 Steps) (loss=0.97071): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (527 / 25000 Steps) (loss=0.97758): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (530 / 25000 Steps) (loss=0.97290): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (533 / 25000 Steps) (loss=0.97631): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (536 / 25000 Steps) (loss=0.97669): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (539 / 25000 Steps) (loss=0.97397): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (542 / 25000 Steps) (loss=0.97325): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (545 / 25000 Steps) (loss=0.96922): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (548 / 25000 Steps) (loss=0.97705): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (551 / 25000 Steps) (loss=0.97518): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (554 / 25000 Steps) (loss=0.97218): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (557 / 25000 Steps) (loss=0.97515): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (560 / 25000 Steps) (loss=0.96720): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (563 / 25000 Steps) (loss=0.96997): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (566 / 25000 Steps) (loss=0.97267): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (569 / 25000 Steps) (loss=0.97527): 100%|██████████| 3/3 [00:02<00:00,  1.21it/s]\n",
      "Training (572 / 25000 Steps) (loss=0.97492): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (575 / 25000 Steps) (loss=0.97591): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (578 / 25000 Steps) (loss=0.96831): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (581 / 25000 Steps) (loss=0.96937): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (584 / 25000 Steps) (loss=0.97350): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (587 / 25000 Steps) (loss=0.97331): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (590 / 25000 Steps) (loss=0.97039): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "Training (593 / 25000 Steps) (loss=0.97410): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (596 / 25000 Steps) (loss=0.97479): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (599 / 25000 Steps) (loss=0.97093): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (602 / 25000 Steps) (loss=0.97388): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (605 / 25000 Steps) (loss=0.97444): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (608 / 25000 Steps) (loss=0.96585): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (611 / 25000 Steps) (loss=0.96415): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (614 / 25000 Steps) (loss=0.96908): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (617 / 25000 Steps) (loss=0.96568): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (620 / 25000 Steps) (loss=0.96669): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (623 / 25000 Steps) (loss=0.97024): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (626 / 25000 Steps) (loss=0.96452): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (629 / 25000 Steps) (loss=0.96880): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (632 / 25000 Steps) (loss=0.96435): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (635 / 25000 Steps) (loss=0.96446): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (638 / 25000 Steps) (loss=0.96497): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (641 / 25000 Steps) (loss=0.97217): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (644 / 25000 Steps) (loss=0.96441): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (647 / 25000 Steps) (loss=0.96229): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (650 / 25000 Steps) (loss=0.97434): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (653 / 25000 Steps) (loss=0.97068): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (656 / 25000 Steps) (loss=0.96211): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (659 / 25000 Steps) (loss=0.95753): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (662 / 25000 Steps) (loss=0.96478): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (665 / 25000 Steps) (loss=0.96422): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (668 / 25000 Steps) (loss=0.96963): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (671 / 25000 Steps) (loss=0.96309): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (674 / 25000 Steps) (loss=0.96450): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (677 / 25000 Steps) (loss=0.96150): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (680 / 25000 Steps) (loss=0.96264): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (683 / 25000 Steps) (loss=0.95766): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (686 / 25000 Steps) (loss=0.95279): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (689 / 25000 Steps) (loss=0.96366): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (692 / 25000 Steps) (loss=0.95721): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (695 / 25000 Steps) (loss=0.96649): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (698 / 25000 Steps) (loss=0.96303): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (701 / 25000 Steps) (loss=0.95250): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (704 / 25000 Steps) (loss=0.96574): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (707 / 25000 Steps) (loss=0.96341): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (710 / 25000 Steps) (loss=0.95725): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (713 / 25000 Steps) (loss=0.95915): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "Training (716 / 25000 Steps) (loss=0.96535): 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "Training (719 / 25000 Steps) (loss=0.95503): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (722 / 25000 Steps) (loss=0.96243): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (725 / 25000 Steps) (loss=0.95931): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (728 / 25000 Steps) (loss=0.95720): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (731 / 25000 Steps) (loss=0.95676): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (734 / 25000 Steps) (loss=0.95635): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (737 / 25000 Steps) (loss=0.94332): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (740 / 25000 Steps) (loss=0.96002): 100%|██████████| 3/3 [00:02<00:00,  1.20it/s]\n",
      "Training (743 / 25000 Steps) (loss=0.95430): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (746 / 25000 Steps) (loss=0.95953): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (749 / 25000 Steps) (loss=0.94859): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (752 / 25000 Steps) (loss=0.95804): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (755 / 25000 Steps) (loss=0.96246): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (758 / 25000 Steps) (loss=0.95729): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (761 / 25000 Steps) (loss=0.95690): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (764 / 25000 Steps) (loss=0.95806): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (767 / 25000 Steps) (loss=0.95441): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (770 / 25000 Steps) (loss=0.95123): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (773 / 25000 Steps) (loss=0.95761): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (776 / 25000 Steps) (loss=0.95327): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (779 / 25000 Steps) (loss=0.95390): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (782 / 25000 Steps) (loss=0.95528): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (785 / 25000 Steps) (loss=0.94290): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (788 / 25000 Steps) (loss=0.94295): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (791 / 25000 Steps) (loss=0.95311): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (794 / 25000 Steps) (loss=0.95158): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (797 / 25000 Steps) (loss=0.94781): 100%|██████████| 3/3 [00:02<00:00,  1.11it/s]\n",
      "Training (800 / 25000 Steps) (loss=0.95184): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (803 / 25000 Steps) (loss=0.94330): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (806 / 25000 Steps) (loss=0.93772): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (809 / 25000 Steps) (loss=0.95269): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (812 / 25000 Steps) (loss=0.93002): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (815 / 25000 Steps) (loss=0.94831): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (818 / 25000 Steps) (loss=0.93954): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (821 / 25000 Steps) (loss=0.93914): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (824 / 25000 Steps) (loss=0.93128): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (827 / 25000 Steps) (loss=0.93850): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (830 / 25000 Steps) (loss=0.94228): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (833 / 25000 Steps) (loss=0.93555): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (836 / 25000 Steps) (loss=0.93831): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (839 / 25000 Steps) (loss=0.94806): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (842 / 25000 Steps) (loss=0.93844): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (845 / 25000 Steps) (loss=0.94003): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (848 / 25000 Steps) (loss=0.93465): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (851 / 25000 Steps) (loss=0.94168): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (854 / 25000 Steps) (loss=0.93632): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (857 / 25000 Steps) (loss=0.93642): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (860 / 25000 Steps) (loss=0.92060): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (863 / 25000 Steps) (loss=0.93393): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (866 / 25000 Steps) (loss=0.93761): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (869 / 25000 Steps) (loss=0.92974): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (872 / 25000 Steps) (loss=0.93002): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (875 / 25000 Steps) (loss=0.93176): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "Training (878 / 25000 Steps) (loss=0.92759): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (881 / 25000 Steps) (loss=0.93166): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (884 / 25000 Steps) (loss=0.92278): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (887 / 25000 Steps) (loss=0.92052): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (890 / 25000 Steps) (loss=0.92710): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (893 / 25000 Steps) (loss=0.93201): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (896 / 25000 Steps) (loss=0.92642): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (899 / 25000 Steps) (loss=0.93432): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (902 / 25000 Steps) (loss=0.91549): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (905 / 25000 Steps) (loss=0.92423): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (908 / 25000 Steps) (loss=0.92689): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (911 / 25000 Steps) (loss=0.92498): 100%|██████████| 3/3 [00:02<00:00,  1.13it/s]\n",
      "Training (914 / 25000 Steps) (loss=0.91081): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (917 / 25000 Steps) (loss=0.92570): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (920 / 25000 Steps) (loss=0.93476): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (923 / 25000 Steps) (loss=0.92099): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (926 / 25000 Steps) (loss=0.90436): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (929 / 25000 Steps) (loss=0.91089): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (932 / 25000 Steps) (loss=0.93265): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (935 / 25000 Steps) (loss=0.91168): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (938 / 25000 Steps) (loss=0.92450): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (941 / 25000 Steps) (loss=0.92165): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (944 / 25000 Steps) (loss=0.90944): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (947 / 25000 Steps) (loss=0.91486): 100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
      "Training (950 / 25000 Steps) (loss=0.91812): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (953 / 25000 Steps) (loss=0.92322): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (956 / 25000 Steps) (loss=0.91768): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (959 / 25000 Steps) (loss=0.89880): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (962 / 25000 Steps) (loss=0.91207): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (965 / 25000 Steps) (loss=0.90112): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (968 / 25000 Steps) (loss=0.90894): 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]\n",
      "Training (971 / 25000 Steps) (loss=0.91531): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (974 / 25000 Steps) (loss=0.90120): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (977 / 25000 Steps) (loss=0.89637): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (980 / 25000 Steps) (loss=0.89654): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (983 / 25000 Steps) (loss=0.91065): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (986 / 25000 Steps) (loss=0.89832): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (989 / 25000 Steps) (loss=0.89861): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (992 / 25000 Steps) (loss=0.89928): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (995 / 25000 Steps) (loss=0.89827): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (998 / 25000 Steps) (loss=0.89951): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Validate (999 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]/it]\n",
      "Training (1001 / 25000 Steps) (loss=0.90428):  67%|██████▋   | 2/3 [00:02<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (1001 / 25000 Steps) (loss=0.90428): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (1004 / 25000 Steps) (loss=0.89169): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (1007 / 25000 Steps) (loss=0.90525): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (1010 / 25000 Steps) (loss=0.89863): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (1013 / 25000 Steps) (loss=0.89247): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (1016 / 25000 Steps) (loss=0.89490): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (1019 / 25000 Steps) (loss=0.89469): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (1022 / 25000 Steps) (loss=0.90883): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (1025 / 25000 Steps) (loss=0.87445): 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "Training (1028 / 25000 Steps) (loss=0.87739): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (1031 / 25000 Steps) (loss=0.88186): 100%|██████████| 3/3 [00:01<00:00,  1.98it/s]\n",
      "Training (1034 / 25000 Steps) (loss=0.88216): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (1037 / 25000 Steps) (loss=0.89231): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (1040 / 25000 Steps) (loss=0.89817): 100%|██████████| 3/3 [00:01<00:00,  1.98it/s]\n",
      "Training (1043 / 25000 Steps) (loss=0.89267): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (1046 / 25000 Steps) (loss=0.87967): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (1049 / 25000 Steps) (loss=0.87714): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (1052 / 25000 Steps) (loss=0.87328): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (1055 / 25000 Steps) (loss=0.88252): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (1058 / 25000 Steps) (loss=0.86195): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (1061 / 25000 Steps) (loss=0.88560): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (1064 / 25000 Steps) (loss=0.86591): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (1067 / 25000 Steps) (loss=0.83963): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (1070 / 25000 Steps) (loss=0.85723): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (1073 / 25000 Steps) (loss=0.86668): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (1076 / 25000 Steps) (loss=0.86947): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (1079 / 25000 Steps) (loss=0.85029): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (1082 / 25000 Steps) (loss=0.84777): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (1085 / 25000 Steps) (loss=0.86449): 100%|██████████| 3/3 [00:02<00:00,  1.21it/s]\n",
      "Training (1088 / 25000 Steps) (loss=0.86479): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (1091 / 25000 Steps) (loss=0.87129): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (1094 / 25000 Steps) (loss=0.82138): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (1097 / 25000 Steps) (loss=0.85931): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (1100 / 25000 Steps) (loss=0.85681): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (1103 / 25000 Steps) (loss=0.85826): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (1106 / 25000 Steps) (loss=0.84612): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (1109 / 25000 Steps) (loss=0.83784): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (1112 / 25000 Steps) (loss=0.84400): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (1115 / 25000 Steps) (loss=0.83069): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (1118 / 25000 Steps) (loss=0.84505): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (1121 / 25000 Steps) (loss=0.82578): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (1124 / 25000 Steps) (loss=0.83962): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (1127 / 25000 Steps) (loss=0.84422): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (1130 / 25000 Steps) (loss=0.82859): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (1133 / 25000 Steps) (loss=0.83976): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (1136 / 25000 Steps) (loss=0.85366): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (1139 / 25000 Steps) (loss=0.83016): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (1142 / 25000 Steps) (loss=0.82504): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (1145 / 25000 Steps) (loss=0.82156): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (1148 / 25000 Steps) (loss=0.83084): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (1151 / 25000 Steps) (loss=0.84327): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (1154 / 25000 Steps) (loss=0.81497): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (1157 / 25000 Steps) (loss=0.84167): 100%|██████████| 3/3 [00:02<00:00,  1.20it/s]\n",
      "Training (1160 / 25000 Steps) (loss=0.82622): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (1163 / 25000 Steps) (loss=0.83536): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (1166 / 25000 Steps) (loss=0.82513): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (1169 / 25000 Steps) (loss=0.81534): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (1172 / 25000 Steps) (loss=0.82827): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (1175 / 25000 Steps) (loss=0.81317): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (1178 / 25000 Steps) (loss=0.81465): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (1181 / 25000 Steps) (loss=0.82832): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (1184 / 25000 Steps) (loss=0.80635): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (1187 / 25000 Steps) (loss=0.75790): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (1190 / 25000 Steps) (loss=0.80769): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (1193 / 25000 Steps) (loss=0.79608): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (1196 / 25000 Steps) (loss=0.78698): 100%|██████████| 3/3 [00:02<00:00,  1.16it/s]\n",
      "Training (1199 / 25000 Steps) (loss=0.79572): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (1202 / 25000 Steps) (loss=0.80766): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (1205 / 25000 Steps) (loss=0.80641): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (1208 / 25000 Steps) (loss=0.80262): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (1211 / 25000 Steps) (loss=0.77744): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (1214 / 25000 Steps) (loss=0.79191): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (1217 / 25000 Steps) (loss=0.74569): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (1220 / 25000 Steps) (loss=0.77717): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (1223 / 25000 Steps) (loss=0.80751): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (1226 / 25000 Steps) (loss=0.77069): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (1229 / 25000 Steps) (loss=0.78570): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (1232 / 25000 Steps) (loss=0.79728): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (1235 / 25000 Steps) (loss=0.74219): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (1238 / 25000 Steps) (loss=0.78013): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (1241 / 25000 Steps) (loss=0.77212): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (1244 / 25000 Steps) (loss=0.74750): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (1247 / 25000 Steps) (loss=0.75407): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (1250 / 25000 Steps) (loss=0.77190): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (1253 / 25000 Steps) (loss=0.71964): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (1256 / 25000 Steps) (loss=0.75690): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (1259 / 25000 Steps) (loss=0.77394): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (1262 / 25000 Steps) (loss=0.73542): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (1265 / 25000 Steps) (loss=0.78357): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (1268 / 25000 Steps) (loss=0.76475): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (1271 / 25000 Steps) (loss=0.76139): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (1274 / 25000 Steps) (loss=0.71832): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (1277 / 25000 Steps) (loss=0.75076): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (1280 / 25000 Steps) (loss=0.71232): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (1283 / 25000 Steps) (loss=0.72021): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (1286 / 25000 Steps) (loss=0.72330): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (1289 / 25000 Steps) (loss=0.74457): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (1292 / 25000 Steps) (loss=0.72358): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (1295 / 25000 Steps) (loss=0.74283): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (1298 / 25000 Steps) (loss=0.71533): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (1301 / 25000 Steps) (loss=0.75656): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (1304 / 25000 Steps) (loss=0.72138): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (1307 / 25000 Steps) (loss=0.71140): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (1310 / 25000 Steps) (loss=0.72994): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (1313 / 25000 Steps) (loss=0.77224): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (1316 / 25000 Steps) (loss=0.71806): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (1319 / 25000 Steps) (loss=0.71551): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (1322 / 25000 Steps) (loss=0.75236): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (1325 / 25000 Steps) (loss=0.72352): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (1328 / 25000 Steps) (loss=0.73297): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (1331 / 25000 Steps) (loss=0.75007): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (1334 / 25000 Steps) (loss=0.65594): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (1337 / 25000 Steps) (loss=0.72193): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (1340 / 25000 Steps) (loss=0.68164): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (1343 / 25000 Steps) (loss=0.69603): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (1346 / 25000 Steps) (loss=0.69953): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (1349 / 25000 Steps) (loss=0.68396): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (1352 / 25000 Steps) (loss=0.68786): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (1355 / 25000 Steps) (loss=0.67007): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (1358 / 25000 Steps) (loss=0.69007): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (1361 / 25000 Steps) (loss=0.70976): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (1364 / 25000 Steps) (loss=0.70993): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (1367 / 25000 Steps) (loss=0.64556): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (1370 / 25000 Steps) (loss=0.68494): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "Training (1373 / 25000 Steps) (loss=0.66758): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (1376 / 25000 Steps) (loss=0.65012): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (1379 / 25000 Steps) (loss=0.68504): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (1382 / 25000 Steps) (loss=0.67277): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "Training (1385 / 25000 Steps) (loss=0.68348): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (1388 / 25000 Steps) (loss=0.65531): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (1391 / 25000 Steps) (loss=0.65145): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (1394 / 25000 Steps) (loss=0.63001): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (1397 / 25000 Steps) (loss=0.66459): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (1400 / 25000 Steps) (loss=0.67832): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (1403 / 25000 Steps) (loss=0.71616): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (1406 / 25000 Steps) (loss=0.70351): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (1409 / 25000 Steps) (loss=0.68384): 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
      "Training (1412 / 25000 Steps) (loss=0.63888): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (1415 / 25000 Steps) (loss=0.64537): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (1418 / 25000 Steps) (loss=0.68878): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (1421 / 25000 Steps) (loss=0.65705): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (1424 / 25000 Steps) (loss=0.61380): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (1427 / 25000 Steps) (loss=0.61408): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (1430 / 25000 Steps) (loss=0.68539): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (1433 / 25000 Steps) (loss=0.65348): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (1436 / 25000 Steps) (loss=0.61045): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (1439 / 25000 Steps) (loss=0.63925): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (1442 / 25000 Steps) (loss=0.63418): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (1445 / 25000 Steps) (loss=0.64077): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (1448 / 25000 Steps) (loss=0.61349): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (1451 / 25000 Steps) (loss=0.62513): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (1454 / 25000 Steps) (loss=0.60738): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (1457 / 25000 Steps) (loss=0.59294): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (1460 / 25000 Steps) (loss=0.62661): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (1463 / 25000 Steps) (loss=0.62803): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (1466 / 25000 Steps) (loss=0.59616): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (1469 / 25000 Steps) (loss=0.59876): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (1472 / 25000 Steps) (loss=0.60513): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (1475 / 25000 Steps) (loss=0.62049): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (1478 / 25000 Steps) (loss=0.62771): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (1481 / 25000 Steps) (loss=0.64322): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (1484 / 25000 Steps) (loss=0.62728): 100%|██████████| 3/3 [00:02<00:00,  1.15it/s]\n",
      "Training (1487 / 25000 Steps) (loss=0.58588): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (1490 / 25000 Steps) (loss=0.55734): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (1493 / 25000 Steps) (loss=0.55016): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (1496 / 25000 Steps) (loss=0.53633): 100%|██████████| 3/3 [00:02<00:00,  1.32it/s]\n",
      "Training (1499 / 25000 Steps) (loss=0.59756): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Validate (1500 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Training (1502 / 25000 Steps) (loss=0.62507): 100%|██████████| 3/3 [00:02<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (1502 / 25000 Steps) (loss=0.62507): 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
      "Training (1505 / 25000 Steps) (loss=0.56605): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (1508 / 25000 Steps) (loss=0.56844): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (1511 / 25000 Steps) (loss=0.58077): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (1514 / 25000 Steps) (loss=0.56583): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (1517 / 25000 Steps) (loss=0.57374): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (1520 / 25000 Steps) (loss=0.56997): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (1523 / 25000 Steps) (loss=0.60552): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (1526 / 25000 Steps) (loss=0.54759): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (1529 / 25000 Steps) (loss=0.60031): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (1532 / 25000 Steps) (loss=0.52878): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (1535 / 25000 Steps) (loss=0.56596): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (1538 / 25000 Steps) (loss=0.54072): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (1541 / 25000 Steps) (loss=0.59415): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (1544 / 25000 Steps) (loss=0.56219): 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
      "Training (1547 / 25000 Steps) (loss=0.54508): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (1550 / 25000 Steps) (loss=0.57570): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (1553 / 25000 Steps) (loss=0.57300): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (1556 / 25000 Steps) (loss=0.55628): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (1559 / 25000 Steps) (loss=0.49981): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (1562 / 25000 Steps) (loss=0.55552): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (1565 / 25000 Steps) (loss=0.54592): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (1568 / 25000 Steps) (loss=0.58921): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (1571 / 25000 Steps) (loss=0.54361): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (1574 / 25000 Steps) (loss=0.55031): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (1577 / 25000 Steps) (loss=0.57027): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (1580 / 25000 Steps) (loss=0.56205): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (1583 / 25000 Steps) (loss=0.54347): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (1586 / 25000 Steps) (loss=0.53334): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (1589 / 25000 Steps) (loss=0.52539): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (1592 / 25000 Steps) (loss=0.53291): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (1595 / 25000 Steps) (loss=0.55954): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (1598 / 25000 Steps) (loss=0.54115): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (1601 / 25000 Steps) (loss=0.51842): 100%|██████████| 3/3 [00:02<00:00,  1.13it/s]\n",
      "Training (1604 / 25000 Steps) (loss=0.54521): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (1607 / 25000 Steps) (loss=0.51709): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (1610 / 25000 Steps) (loss=0.53516): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (1613 / 25000 Steps) (loss=0.53006): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (1616 / 25000 Steps) (loss=0.53107): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (1619 / 25000 Steps) (loss=0.50320): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (1622 / 25000 Steps) (loss=0.53543): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (1625 / 25000 Steps) (loss=0.52044): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (1628 / 25000 Steps) (loss=0.52176): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (1631 / 25000 Steps) (loss=0.55392): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (1634 / 25000 Steps) (loss=0.47502): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (1637 / 25000 Steps) (loss=0.50653): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (1640 / 25000 Steps) (loss=0.51777): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (1643 / 25000 Steps) (loss=0.49692): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (1646 / 25000 Steps) (loss=0.50244): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (1649 / 25000 Steps) (loss=0.44395): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (1652 / 25000 Steps) (loss=0.51312): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (1655 / 25000 Steps) (loss=0.51660): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (1658 / 25000 Steps) (loss=0.46156): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (1661 / 25000 Steps) (loss=0.50266): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (1664 / 25000 Steps) (loss=0.43490): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (1667 / 25000 Steps) (loss=0.49939): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (1670 / 25000 Steps) (loss=0.47704): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (1673 / 25000 Steps) (loss=0.45498): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (1676 / 25000 Steps) (loss=0.50073): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (1679 / 25000 Steps) (loss=0.46594): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (1682 / 25000 Steps) (loss=0.47819): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (1685 / 25000 Steps) (loss=0.50235): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (1688 / 25000 Steps) (loss=0.43842): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (1691 / 25000 Steps) (loss=0.41196): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (1694 / 25000 Steps) (loss=0.42215): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (1697 / 25000 Steps) (loss=0.46099): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (1700 / 25000 Steps) (loss=0.42940): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (1703 / 25000 Steps) (loss=0.45304): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (1706 / 25000 Steps) (loss=0.44384): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (1709 / 25000 Steps) (loss=0.45211): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (1712 / 25000 Steps) (loss=0.46679): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (1715 / 25000 Steps) (loss=0.52116): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (1718 / 25000 Steps) (loss=0.48018): 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "Training (1721 / 25000 Steps) (loss=0.47546): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (1724 / 25000 Steps) (loss=0.46843): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (1727 / 25000 Steps) (loss=0.47702): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (1730 / 25000 Steps) (loss=0.44552): 100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
      "Training (1733 / 25000 Steps) (loss=0.42366): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (1736 / 25000 Steps) (loss=0.42890): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (1739 / 25000 Steps) (loss=0.46806): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (1742 / 25000 Steps) (loss=0.43661): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (1745 / 25000 Steps) (loss=0.47210): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (1748 / 25000 Steps) (loss=0.47185): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (1751 / 25000 Steps) (loss=0.44776): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (1754 / 25000 Steps) (loss=0.46176): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (1757 / 25000 Steps) (loss=0.44191): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (1760 / 25000 Steps) (loss=0.46338): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (1763 / 25000 Steps) (loss=0.44261): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (1766 / 25000 Steps) (loss=0.38204): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (1769 / 25000 Steps) (loss=0.44595): 100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
      "Training (1772 / 25000 Steps) (loss=0.43139): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (1775 / 25000 Steps) (loss=0.39757): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (1778 / 25000 Steps) (loss=0.43202): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (1781 / 25000 Steps) (loss=0.40479): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (1784 / 25000 Steps) (loss=0.41911): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (1787 / 25000 Steps) (loss=0.44250): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (1790 / 25000 Steps) (loss=0.41239): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (1793 / 25000 Steps) (loss=0.40210): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (1796 / 25000 Steps) (loss=0.46160): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (1799 / 25000 Steps) (loss=0.39419): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (1802 / 25000 Steps) (loss=0.42574): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (1805 / 25000 Steps) (loss=0.44894): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (1808 / 25000 Steps) (loss=0.37988): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (1811 / 25000 Steps) (loss=0.44019): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (1814 / 25000 Steps) (loss=0.41968): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (1817 / 25000 Steps) (loss=0.39033): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (1820 / 25000 Steps) (loss=0.40297): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (1823 / 25000 Steps) (loss=0.33505): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (1826 / 25000 Steps) (loss=0.42125): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (1829 / 25000 Steps) (loss=0.39965): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (1832 / 25000 Steps) (loss=0.39714): 100%|██████████| 3/3 [00:02<00:00,  1.14it/s]\n",
      "Training (1835 / 25000 Steps) (loss=0.43360): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (1838 / 25000 Steps) (loss=0.36270): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (1841 / 25000 Steps) (loss=0.41166): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (1844 / 25000 Steps) (loss=0.42262): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (1847 / 25000 Steps) (loss=0.39608): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (1850 / 25000 Steps) (loss=0.38270): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (1853 / 25000 Steps) (loss=0.39963): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (1856 / 25000 Steps) (loss=0.39362): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (1859 / 25000 Steps) (loss=0.35498): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (1862 / 25000 Steps) (loss=0.38511): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (1865 / 25000 Steps) (loss=0.34267): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (1868 / 25000 Steps) (loss=0.36355): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (1871 / 25000 Steps) (loss=0.36555): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (1874 / 25000 Steps) (loss=0.38861): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (1877 / 25000 Steps) (loss=0.39232): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (1880 / 25000 Steps) (loss=0.36105): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (1883 / 25000 Steps) (loss=0.39995): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (1886 / 25000 Steps) (loss=0.38157): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (1889 / 25000 Steps) (loss=0.36600): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (1892 / 25000 Steps) (loss=0.36536): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (1895 / 25000 Steps) (loss=0.37476): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (1898 / 25000 Steps) (loss=0.35224): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (1901 / 25000 Steps) (loss=0.37712): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (1904 / 25000 Steps) (loss=0.36608): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (1907 / 25000 Steps) (loss=0.35717): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (1910 / 25000 Steps) (loss=0.35048): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (1913 / 25000 Steps) (loss=0.36984): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (1916 / 25000 Steps) (loss=0.35045): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (1919 / 25000 Steps) (loss=0.35862): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (1922 / 25000 Steps) (loss=0.37753): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (1925 / 25000 Steps) (loss=0.31553): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (1928 / 25000 Steps) (loss=0.36096): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (1931 / 25000 Steps) (loss=0.40494): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (1934 / 25000 Steps) (loss=0.40400): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (1937 / 25000 Steps) (loss=0.30050): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (1940 / 25000 Steps) (loss=0.33774): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (1943 / 25000 Steps) (loss=0.34977): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (1946 / 25000 Steps) (loss=0.31498): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (1949 / 25000 Steps) (loss=0.35526): 100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
      "Training (1952 / 25000 Steps) (loss=0.32508): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (1955 / 25000 Steps) (loss=0.33635): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (1958 / 25000 Steps) (loss=0.38056): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (1961 / 25000 Steps) (loss=0.32218): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (1964 / 25000 Steps) (loss=0.34702): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (1967 / 25000 Steps) (loss=0.36097): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (1970 / 25000 Steps) (loss=0.35050): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (1973 / 25000 Steps) (loss=0.32460): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (1976 / 25000 Steps) (loss=0.34034): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (1979 / 25000 Steps) (loss=0.30940): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (1982 / 25000 Steps) (loss=0.33453): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (1985 / 25000 Steps) (loss=0.34927): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (1988 / 25000 Steps) (loss=0.35181): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (1991 / 25000 Steps) (loss=0.38054): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (1994 / 25000 Steps) (loss=0.33843): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (1997 / 25000 Steps) (loss=0.32792): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Validate (1998 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]it]\n",
      "Training (2000 / 25000 Steps) (loss=0.32092): 100%|██████████| 3/3 [00:02<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (2000 / 25000 Steps) (loss=0.32092): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (2003 / 25000 Steps) (loss=0.32368): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (2006 / 25000 Steps) (loss=0.30592): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (2009 / 25000 Steps) (loss=0.30688): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (2012 / 25000 Steps) (loss=0.29422): 100%|██████████| 3/3 [00:01<00:00,  2.00it/s]\n",
      "Training (2015 / 25000 Steps) (loss=0.33631): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (2018 / 25000 Steps) (loss=0.33106): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (2021 / 25000 Steps) (loss=0.29753): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (2024 / 25000 Steps) (loss=0.33261): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (2027 / 25000 Steps) (loss=0.34064): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (2030 / 25000 Steps) (loss=0.30934): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (2033 / 25000 Steps) (loss=0.30839): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (2036 / 25000 Steps) (loss=0.31643): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (2039 / 25000 Steps) (loss=0.29698): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (2042 / 25000 Steps) (loss=0.31814): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (2045 / 25000 Steps) (loss=0.31299): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (2048 / 25000 Steps) (loss=0.34031): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (2051 / 25000 Steps) (loss=0.31760): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (2054 / 25000 Steps) (loss=0.30485): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (2057 / 25000 Steps) (loss=0.32414): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (2060 / 25000 Steps) (loss=0.30590): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (2063 / 25000 Steps) (loss=0.28114): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (2066 / 25000 Steps) (loss=0.28213): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (2069 / 25000 Steps) (loss=0.31743): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (2072 / 25000 Steps) (loss=0.36286): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (2075 / 25000 Steps) (loss=0.33658): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (2078 / 25000 Steps) (loss=0.28642): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (2081 / 25000 Steps) (loss=0.28421): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (2084 / 25000 Steps) (loss=0.31128): 100%|██████████| 3/3 [00:02<00:00,  1.25it/s]\n",
      "Training (2087 / 25000 Steps) (loss=0.28821): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (2090 / 25000 Steps) (loss=0.31962): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (2093 / 25000 Steps) (loss=0.30070): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (2096 / 25000 Steps) (loss=0.30134): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (2099 / 25000 Steps) (loss=0.29875): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (2102 / 25000 Steps) (loss=0.32744): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (2105 / 25000 Steps) (loss=0.31526): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (2108 / 25000 Steps) (loss=0.30146): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (2111 / 25000 Steps) (loss=0.29033): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (2114 / 25000 Steps) (loss=0.27171): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (2117 / 25000 Steps) (loss=0.28326): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (2120 / 25000 Steps) (loss=0.31685): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (2123 / 25000 Steps) (loss=0.30258): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (2126 / 25000 Steps) (loss=0.30592): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (2129 / 25000 Steps) (loss=0.27345): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (2132 / 25000 Steps) (loss=0.26324): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (2135 / 25000 Steps) (loss=0.32120): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (2138 / 25000 Steps) (loss=0.24799): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (2141 / 25000 Steps) (loss=0.30920): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (2144 / 25000 Steps) (loss=0.30136): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (2147 / 25000 Steps) (loss=0.27798): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (2150 / 25000 Steps) (loss=0.28298): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (2153 / 25000 Steps) (loss=0.31152): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (2156 / 25000 Steps) (loss=0.27789): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (2159 / 25000 Steps) (loss=0.29760): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (2162 / 25000 Steps) (loss=0.29131): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (2165 / 25000 Steps) (loss=0.27503): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (2168 / 25000 Steps) (loss=0.28254): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (2171 / 25000 Steps) (loss=0.26404): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (2174 / 25000 Steps) (loss=0.26497): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (2177 / 25000 Steps) (loss=0.29275): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (2180 / 25000 Steps) (loss=0.27103): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (2183 / 25000 Steps) (loss=0.28243): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (2186 / 25000 Steps) (loss=0.24580): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (2189 / 25000 Steps) (loss=0.28611): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (2192 / 25000 Steps) (loss=0.25045): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (2195 / 25000 Steps) (loss=0.26835): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "Training (2198 / 25000 Steps) (loss=0.32940): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (2201 / 25000 Steps) (loss=0.25793): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (2204 / 25000 Steps) (loss=0.27441): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (2207 / 25000 Steps) (loss=0.27678): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (2210 / 25000 Steps) (loss=0.25935): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (2213 / 25000 Steps) (loss=0.28976): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (2216 / 25000 Steps) (loss=0.23691): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (2219 / 25000 Steps) (loss=0.24169): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (2222 / 25000 Steps) (loss=0.28091): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (2225 / 25000 Steps) (loss=0.28463): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (2228 / 25000 Steps) (loss=0.25921): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (2231 / 25000 Steps) (loss=0.26211): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (2234 / 25000 Steps) (loss=0.27285): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (2237 / 25000 Steps) (loss=0.26213): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (2240 / 25000 Steps) (loss=0.26344): 100%|██████████| 3/3 [00:02<00:00,  1.12it/s]\n",
      "Training (2243 / 25000 Steps) (loss=0.26953): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (2246 / 25000 Steps) (loss=0.27835): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (2249 / 25000 Steps) (loss=0.26099): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (2252 / 25000 Steps) (loss=0.22407): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (2255 / 25000 Steps) (loss=0.26042): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (2258 / 25000 Steps) (loss=0.26153): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (2261 / 25000 Steps) (loss=0.25443): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (2264 / 25000 Steps) (loss=0.24183): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (2267 / 25000 Steps) (loss=0.29084): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (2270 / 25000 Steps) (loss=0.29367): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (2273 / 25000 Steps) (loss=0.27027): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (2276 / 25000 Steps) (loss=0.26449): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (2279 / 25000 Steps) (loss=0.26103): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (2282 / 25000 Steps) (loss=0.26759): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (2285 / 25000 Steps) (loss=0.21084): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (2288 / 25000 Steps) (loss=0.24799): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (2291 / 25000 Steps) (loss=0.25123): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (2294 / 25000 Steps) (loss=0.24836): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (2297 / 25000 Steps) (loss=0.24506): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (2300 / 25000 Steps) (loss=0.26467): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (2303 / 25000 Steps) (loss=0.23680): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (2306 / 25000 Steps) (loss=0.24586): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (2309 / 25000 Steps) (loss=0.26950): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (2312 / 25000 Steps) (loss=0.26251): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (2315 / 25000 Steps) (loss=0.28190): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (2318 / 25000 Steps) (loss=0.22394): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (2321 / 25000 Steps) (loss=0.25161): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (2324 / 25000 Steps) (loss=0.26697): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (2327 / 25000 Steps) (loss=0.24762): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (2330 / 25000 Steps) (loss=0.23875): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (2333 / 25000 Steps) (loss=0.25984): 100%|██████████| 3/3 [00:01<00:00,  1.99it/s]\n",
      "Training (2336 / 25000 Steps) (loss=0.26662): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (2339 / 25000 Steps) (loss=0.22839): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (2342 / 25000 Steps) (loss=0.25916): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (2345 / 25000 Steps) (loss=0.22745): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (2348 / 25000 Steps) (loss=0.24203): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (2351 / 25000 Steps) (loss=0.21701): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (2354 / 25000 Steps) (loss=0.23749): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (2357 / 25000 Steps) (loss=0.26560): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (2360 / 25000 Steps) (loss=0.24047): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (2363 / 25000 Steps) (loss=0.23600): 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]\n",
      "Training (2366 / 25000 Steps) (loss=0.24022): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (2369 / 25000 Steps) (loss=0.22543): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (2372 / 25000 Steps) (loss=0.21942): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (2375 / 25000 Steps) (loss=0.23745): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (2378 / 25000 Steps) (loss=0.24279): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (2381 / 25000 Steps) (loss=0.23525): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (2384 / 25000 Steps) (loss=0.21716): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (2387 / 25000 Steps) (loss=0.20237): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (2390 / 25000 Steps) (loss=0.24463): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (2393 / 25000 Steps) (loss=0.25721): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (2396 / 25000 Steps) (loss=0.21129): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (2399 / 25000 Steps) (loss=0.22763): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (2402 / 25000 Steps) (loss=0.22335): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (2405 / 25000 Steps) (loss=0.21313): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (2408 / 25000 Steps) (loss=0.22990): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (2411 / 25000 Steps) (loss=0.24547): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (2414 / 25000 Steps) (loss=0.23090): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (2417 / 25000 Steps) (loss=0.24540): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (2420 / 25000 Steps) (loss=0.22942): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (2423 / 25000 Steps) (loss=0.23314): 100%|██████████| 3/3 [00:02<00:00,  1.19it/s]\n",
      "Training (2426 / 25000 Steps) (loss=0.19242): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (2429 / 25000 Steps) (loss=0.21553): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (2432 / 25000 Steps) (loss=0.22317): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (2435 / 25000 Steps) (loss=0.23699): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (2438 / 25000 Steps) (loss=0.18962): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (2441 / 25000 Steps) (loss=0.22196): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (2444 / 25000 Steps) (loss=0.24555): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (2447 / 25000 Steps) (loss=0.22722): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (2450 / 25000 Steps) (loss=0.19998): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (2453 / 25000 Steps) (loss=0.22947): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (2456 / 25000 Steps) (loss=0.23652): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (2459 / 25000 Steps) (loss=0.24579): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (2462 / 25000 Steps) (loss=0.24414): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (2465 / 25000 Steps) (loss=0.20748): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (2468 / 25000 Steps) (loss=0.23286): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (2471 / 25000 Steps) (loss=0.23484): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (2474 / 25000 Steps) (loss=0.21628): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (2477 / 25000 Steps) (loss=0.25381): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (2480 / 25000 Steps) (loss=0.19967): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (2483 / 25000 Steps) (loss=0.24835): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (2486 / 25000 Steps) (loss=0.20610): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (2489 / 25000 Steps) (loss=0.20448): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (2492 / 25000 Steps) (loss=0.23290): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (2495 / 25000 Steps) (loss=0.24119): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (2498 / 25000 Steps) (loss=0.21805): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Validate (2499 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]it]\n",
      "Training (2501 / 25000 Steps) (loss=0.21237):  67%|██████▋   | 2/3 [00:02<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (2501 / 25000 Steps) (loss=0.21237): 100%|██████████| 3/3 [00:02<00:00,  1.32it/s]\n",
      "Training (2504 / 25000 Steps) (loss=0.21644): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (2507 / 25000 Steps) (loss=0.23699): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (2510 / 25000 Steps) (loss=0.21359): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (2513 / 25000 Steps) (loss=0.21392): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (2516 / 25000 Steps) (loss=0.19034): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (2519 / 25000 Steps) (loss=0.21593): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (2522 / 25000 Steps) (loss=0.17552): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (2525 / 25000 Steps) (loss=0.20009): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (2528 / 25000 Steps) (loss=0.22727): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (2531 / 25000 Steps) (loss=0.24190): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (2534 / 25000 Steps) (loss=0.18242): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (2537 / 25000 Steps) (loss=0.20598): 100%|██████████| 3/3 [00:03<00:00,  1.09s/it]\n",
      "Training (2540 / 25000 Steps) (loss=0.18249): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (2543 / 25000 Steps) (loss=0.19078): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (2546 / 25000 Steps) (loss=0.19215): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (2549 / 25000 Steps) (loss=0.19829): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (2552 / 25000 Steps) (loss=0.19573): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (2555 / 25000 Steps) (loss=0.20554): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (2558 / 25000 Steps) (loss=0.22196): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (2561 / 25000 Steps) (loss=0.21556): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (2564 / 25000 Steps) (loss=0.21045): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (2567 / 25000 Steps) (loss=0.19036): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (2570 / 25000 Steps) (loss=0.20436): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (2573 / 25000 Steps) (loss=0.21439): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (2576 / 25000 Steps) (loss=0.20010): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (2579 / 25000 Steps) (loss=0.21016): 100%|██████████| 3/3 [00:01<00:00,  1.98it/s]\n",
      "Training (2582 / 25000 Steps) (loss=0.19577): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (2585 / 25000 Steps) (loss=0.21808): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (2588 / 25000 Steps) (loss=0.19019): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (2591 / 25000 Steps) (loss=0.21586): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (2594 / 25000 Steps) (loss=0.16474): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (2597 / 25000 Steps) (loss=0.23492): 100%|██████████| 3/3 [00:03<00:00,  1.02s/it]\n",
      "Training (2600 / 25000 Steps) (loss=0.22624): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (2603 / 25000 Steps) (loss=0.19888): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (2606 / 25000 Steps) (loss=0.18701): 100%|██████████| 3/3 [00:02<00:00,  1.20it/s]\n",
      "Training (2609 / 25000 Steps) (loss=0.16500): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (2612 / 25000 Steps) (loss=0.23484): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (2615 / 25000 Steps) (loss=0.22843): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (2618 / 25000 Steps) (loss=0.17262): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (2621 / 25000 Steps) (loss=0.20441): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (2624 / 25000 Steps) (loss=0.20767): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (2627 / 25000 Steps) (loss=0.19410): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (2630 / 25000 Steps) (loss=0.18439): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (2633 / 25000 Steps) (loss=0.18339): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (2636 / 25000 Steps) (loss=0.21900): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (2639 / 25000 Steps) (loss=0.19230): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (2642 / 25000 Steps) (loss=0.20236): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (2645 / 25000 Steps) (loss=0.18965): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (2648 / 25000 Steps) (loss=0.18303): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (2651 / 25000 Steps) (loss=0.20013): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (2654 / 25000 Steps) (loss=0.18344): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (2657 / 25000 Steps) (loss=0.21167): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (2660 / 25000 Steps) (loss=0.18204): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (2663 / 25000 Steps) (loss=0.18862): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (2666 / 25000 Steps) (loss=0.22833): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (2669 / 25000 Steps) (loss=0.18059): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (2672 / 25000 Steps) (loss=0.22211): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (2675 / 25000 Steps) (loss=0.18173): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (2678 / 25000 Steps) (loss=0.18196): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (2681 / 25000 Steps) (loss=0.20648): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (2684 / 25000 Steps) (loss=0.19097): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (2687 / 25000 Steps) (loss=0.17702): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (2690 / 25000 Steps) (loss=0.21697): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (2693 / 25000 Steps) (loss=0.18988): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (2696 / 25000 Steps) (loss=0.18465): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (2699 / 25000 Steps) (loss=0.19634): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (2702 / 25000 Steps) (loss=0.16705): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (2705 / 25000 Steps) (loss=0.19266): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (2708 / 25000 Steps) (loss=0.16859): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (2711 / 25000 Steps) (loss=0.20186): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (2714 / 25000 Steps) (loss=0.17054): 100%|██████████| 3/3 [00:03<00:00,  1.03s/it]\n",
      "Training (2717 / 25000 Steps) (loss=0.18867): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (2720 / 25000 Steps) (loss=0.17461): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (2723 / 25000 Steps) (loss=0.22473): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (2726 / 25000 Steps) (loss=0.19071): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (2729 / 25000 Steps) (loss=0.17949): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (2732 / 25000 Steps) (loss=0.18751): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (2735 / 25000 Steps) (loss=0.18976): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (2738 / 25000 Steps) (loss=0.19155): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (2741 / 25000 Steps) (loss=0.21314): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (2744 / 25000 Steps) (loss=0.17218): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (2747 / 25000 Steps) (loss=0.20536): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (2750 / 25000 Steps) (loss=0.16963): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (2753 / 25000 Steps) (loss=0.17620): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (2756 / 25000 Steps) (loss=0.17492): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (2759 / 25000 Steps) (loss=0.17215): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (2762 / 25000 Steps) (loss=0.20982): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (2765 / 25000 Steps) (loss=0.17694): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (2768 / 25000 Steps) (loss=0.17492): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (2771 / 25000 Steps) (loss=0.17365): 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]\n",
      "Training (2774 / 25000 Steps) (loss=0.16946): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (2777 / 25000 Steps) (loss=0.17903): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (2780 / 25000 Steps) (loss=0.16739): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (2783 / 25000 Steps) (loss=0.17772): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (2786 / 25000 Steps) (loss=0.18583): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (2789 / 25000 Steps) (loss=0.20354): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (2792 / 25000 Steps) (loss=0.17817): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (2795 / 25000 Steps) (loss=0.18219): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (2798 / 25000 Steps) (loss=0.17769): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (2801 / 25000 Steps) (loss=0.16198): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (2804 / 25000 Steps) (loss=0.18410): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (2807 / 25000 Steps) (loss=0.18074): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (2810 / 25000 Steps) (loss=0.18157): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (2813 / 25000 Steps) (loss=0.18047): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (2816 / 25000 Steps) (loss=0.17223): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (2819 / 25000 Steps) (loss=0.15709): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (2822 / 25000 Steps) (loss=0.19551): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (2825 / 25000 Steps) (loss=0.17343): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (2828 / 25000 Steps) (loss=0.16973): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (2831 / 25000 Steps) (loss=0.19666): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (2834 / 25000 Steps) (loss=0.17741): 100%|██████████| 3/3 [00:02<00:00,  1.14it/s]\n",
      "Training (2837 / 25000 Steps) (loss=0.20299): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (2840 / 25000 Steps) (loss=0.20161): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (2843 / 25000 Steps) (loss=0.17944): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (2846 / 25000 Steps) (loss=0.17571): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (2849 / 25000 Steps) (loss=0.17099): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (2852 / 25000 Steps) (loss=0.15777): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (2855 / 25000 Steps) (loss=0.18136): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (2858 / 25000 Steps) (loss=0.15806): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (2861 / 25000 Steps) (loss=0.16667): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (2864 / 25000 Steps) (loss=0.17029): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (2867 / 25000 Steps) (loss=0.16444): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (2870 / 25000 Steps) (loss=0.16347): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (2873 / 25000 Steps) (loss=0.17873): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (2876 / 25000 Steps) (loss=0.16770): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (2879 / 25000 Steps) (loss=0.16750): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (2882 / 25000 Steps) (loss=0.17412): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (2885 / 25000 Steps) (loss=0.16565): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (2888 / 25000 Steps) (loss=0.14358): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (2891 / 25000 Steps) (loss=0.14588): 100%|██████████| 3/3 [00:02<00:00,  1.21it/s]\n",
      "Training (2894 / 25000 Steps) (loss=0.16382): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (2897 / 25000 Steps) (loss=0.14122): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (2900 / 25000 Steps) (loss=0.14827): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (2903 / 25000 Steps) (loss=0.15162): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (2906 / 25000 Steps) (loss=0.15129): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (2909 / 25000 Steps) (loss=0.15928): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (2912 / 25000 Steps) (loss=0.15249): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (2915 / 25000 Steps) (loss=0.16812): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (2918 / 25000 Steps) (loss=0.15469): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (2921 / 25000 Steps) (loss=0.16363): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (2924 / 25000 Steps) (loss=0.15330): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (2927 / 25000 Steps) (loss=0.13736): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (2930 / 25000 Steps) (loss=0.14118): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (2933 / 25000 Steps) (loss=0.15171): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (2936 / 25000 Steps) (loss=0.16740): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (2939 / 25000 Steps) (loss=0.13898): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (2942 / 25000 Steps) (loss=0.14192): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (2945 / 25000 Steps) (loss=0.16366): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (2948 / 25000 Steps) (loss=0.16121): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (2951 / 25000 Steps) (loss=0.15241): 100%|██████████| 3/3 [00:02<00:00,  1.00it/s]\n",
      "Training (2954 / 25000 Steps) (loss=0.15938): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (2957 / 25000 Steps) (loss=0.15561): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (2960 / 25000 Steps) (loss=0.16421): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (2963 / 25000 Steps) (loss=0.15369): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (2966 / 25000 Steps) (loss=0.15902): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (2969 / 25000 Steps) (loss=0.16108): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (2972 / 25000 Steps) (loss=0.14247): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (2975 / 25000 Steps) (loss=0.17159): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (2978 / 25000 Steps) (loss=0.14345): 100%|██████████| 3/3 [00:01<00:00,  1.99it/s]\n",
      "Training (2981 / 25000 Steps) (loss=0.15570): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (2984 / 25000 Steps) (loss=0.14505): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (2987 / 25000 Steps) (loss=0.17164): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (2990 / 25000 Steps) (loss=0.15725): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (2993 / 25000 Steps) (loss=0.13994): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (2996 / 25000 Steps) (loss=0.13595): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (2999 / 25000 Steps) (loss=0.16716): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Validate (3000 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n",
      "Training (3002 / 25000 Steps) (loss=0.17547): 100%|██████████| 3/3 [00:02<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (3002 / 25000 Steps) (loss=0.17547): 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
      "Training (3005 / 25000 Steps) (loss=0.14220): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (3008 / 25000 Steps) (loss=0.16371): 100%|██████████| 3/3 [00:02<00:00,  1.25it/s]\n",
      "Training (3011 / 25000 Steps) (loss=0.14774): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3014 / 25000 Steps) (loss=0.15651): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (3017 / 25000 Steps) (loss=0.15577): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (3020 / 25000 Steps) (loss=0.14000): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (3023 / 25000 Steps) (loss=0.15116): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (3026 / 25000 Steps) (loss=0.15387): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (3029 / 25000 Steps) (loss=0.16845): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3032 / 25000 Steps) (loss=0.15834): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (3035 / 25000 Steps) (loss=0.15291): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (3038 / 25000 Steps) (loss=0.14348): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (3041 / 25000 Steps) (loss=0.15840): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (3044 / 25000 Steps) (loss=0.14619): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (3047 / 25000 Steps) (loss=0.14472): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (3050 / 25000 Steps) (loss=0.14808): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (3053 / 25000 Steps) (loss=0.17207): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (3056 / 25000 Steps) (loss=0.12513): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (3059 / 25000 Steps) (loss=0.14164): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (3062 / 25000 Steps) (loss=0.13873): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (3065 / 25000 Steps) (loss=0.15270): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (3068 / 25000 Steps) (loss=0.16070): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (3071 / 25000 Steps) (loss=0.18300): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (3074 / 25000 Steps) (loss=0.14966): 100%|██████████| 3/3 [00:02<00:00,  1.02it/s]\n",
      "Training (3077 / 25000 Steps) (loss=0.16893): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (3080 / 25000 Steps) (loss=0.14542): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (3083 / 25000 Steps) (loss=0.13926): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (3086 / 25000 Steps) (loss=0.14667): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (3089 / 25000 Steps) (loss=0.13188): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (3092 / 25000 Steps) (loss=0.17091): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (3095 / 25000 Steps) (loss=0.15957): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (3098 / 25000 Steps) (loss=0.12864): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (3101 / 25000 Steps) (loss=0.13977): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (3104 / 25000 Steps) (loss=0.16451): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (3107 / 25000 Steps) (loss=0.16679): 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
      "Training (3110 / 25000 Steps) (loss=0.15320): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (3113 / 25000 Steps) (loss=0.13694): 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
      "Training (3116 / 25000 Steps) (loss=0.14286): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (3119 / 25000 Steps) (loss=0.13779): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3122 / 25000 Steps) (loss=0.13007): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (3125 / 25000 Steps) (loss=0.13296): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (3128 / 25000 Steps) (loss=0.12811): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (3131 / 25000 Steps) (loss=0.14802): 100%|██████████| 3/3 [00:02<00:00,  1.21it/s]\n",
      "Training (3134 / 25000 Steps) (loss=0.15628): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3137 / 25000 Steps) (loss=0.15322): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (3140 / 25000 Steps) (loss=0.12229): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (3143 / 25000 Steps) (loss=0.15705): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (3146 / 25000 Steps) (loss=0.16122): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (3149 / 25000 Steps) (loss=0.14236): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (3152 / 25000 Steps) (loss=0.15695): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3155 / 25000 Steps) (loss=0.12939): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (3158 / 25000 Steps) (loss=0.15799): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (3161 / 25000 Steps) (loss=0.12949): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (3164 / 25000 Steps) (loss=0.11624): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (3167 / 25000 Steps) (loss=0.13009): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (3170 / 25000 Steps) (loss=0.12852): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (3173 / 25000 Steps) (loss=0.13648): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (3176 / 25000 Steps) (loss=0.12947): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (3179 / 25000 Steps) (loss=0.12706): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (3182 / 25000 Steps) (loss=0.14194): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3185 / 25000 Steps) (loss=0.14397): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (3188 / 25000 Steps) (loss=0.12637): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (3191 / 25000 Steps) (loss=0.14128): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (3194 / 25000 Steps) (loss=0.13948): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (3197 / 25000 Steps) (loss=0.14289): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (3200 / 25000 Steps) (loss=0.12457): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (3203 / 25000 Steps) (loss=0.15636): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (3206 / 25000 Steps) (loss=0.12840): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (3209 / 25000 Steps) (loss=0.11636): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (3212 / 25000 Steps) (loss=0.16388): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (3215 / 25000 Steps) (loss=0.13449): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (3218 / 25000 Steps) (loss=0.14013): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (3221 / 25000 Steps) (loss=0.12887): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (3224 / 25000 Steps) (loss=0.14347): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3227 / 25000 Steps) (loss=0.14565): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (3230 / 25000 Steps) (loss=0.15230): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (3233 / 25000 Steps) (loss=0.11748): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (3236 / 25000 Steps) (loss=0.14297): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (3239 / 25000 Steps) (loss=0.14091): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (3242 / 25000 Steps) (loss=0.13759): 100%|██████████| 3/3 [00:02<00:00,  1.20it/s]\n",
      "Training (3245 / 25000 Steps) (loss=0.15365): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3248 / 25000 Steps) (loss=0.12298): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (3251 / 25000 Steps) (loss=0.12972): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (3254 / 25000 Steps) (loss=0.14502): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (3257 / 25000 Steps) (loss=0.16115): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (3260 / 25000 Steps) (loss=0.14560): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (3263 / 25000 Steps) (loss=0.13878): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (3266 / 25000 Steps) (loss=0.13252): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (3269 / 25000 Steps) (loss=0.12798): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (3272 / 25000 Steps) (loss=0.13254): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (3275 / 25000 Steps) (loss=0.12009): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3278 / 25000 Steps) (loss=0.13733): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (3281 / 25000 Steps) (loss=0.14529): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3284 / 25000 Steps) (loss=0.12413): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3287 / 25000 Steps) (loss=0.12714): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (3290 / 25000 Steps) (loss=0.13631): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (3293 / 25000 Steps) (loss=0.14109): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (3296 / 25000 Steps) (loss=0.13468): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (3299 / 25000 Steps) (loss=0.15628): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (3302 / 25000 Steps) (loss=0.13800): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (3305 / 25000 Steps) (loss=0.13575): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (3308 / 25000 Steps) (loss=0.13177): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (3311 / 25000 Steps) (loss=0.12848): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (3314 / 25000 Steps) (loss=0.12330): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (3317 / 25000 Steps) (loss=0.15107): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3320 / 25000 Steps) (loss=0.13869): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (3323 / 25000 Steps) (loss=0.11157): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (3326 / 25000 Steps) (loss=0.12621): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (3329 / 25000 Steps) (loss=0.12639): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (3332 / 25000 Steps) (loss=0.13844): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (3335 / 25000 Steps) (loss=0.10330): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (3338 / 25000 Steps) (loss=0.13443): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (3341 / 25000 Steps) (loss=0.11844): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (3344 / 25000 Steps) (loss=0.10970): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (3347 / 25000 Steps) (loss=0.13518): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3350 / 25000 Steps) (loss=0.12922): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (3353 / 25000 Steps) (loss=0.13294): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (3356 / 25000 Steps) (loss=0.15069): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (3359 / 25000 Steps) (loss=0.12657): 100%|██████████| 3/3 [00:02<00:00,  1.17it/s]\n",
      "Training (3362 / 25000 Steps) (loss=0.11347): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (3365 / 25000 Steps) (loss=0.11469): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (3368 / 25000 Steps) (loss=0.11953): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (3371 / 25000 Steps) (loss=0.11049): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (3374 / 25000 Steps) (loss=0.13177): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (3377 / 25000 Steps) (loss=0.13172): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (3380 / 25000 Steps) (loss=0.10666): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (3383 / 25000 Steps) (loss=0.12128): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (3386 / 25000 Steps) (loss=0.13128): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (3389 / 25000 Steps) (loss=0.11351): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (3392 / 25000 Steps) (loss=0.11561): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (3395 / 25000 Steps) (loss=0.11621): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (3398 / 25000 Steps) (loss=0.11770): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (3401 / 25000 Steps) (loss=0.12971): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (3404 / 25000 Steps) (loss=0.12780): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (3407 / 25000 Steps) (loss=0.13100): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3410 / 25000 Steps) (loss=0.11695): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (3413 / 25000 Steps) (loss=0.12003): 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]\n",
      "Training (3416 / 25000 Steps) (loss=0.12793): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (3419 / 25000 Steps) (loss=0.11876): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (3422 / 25000 Steps) (loss=0.13527): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (3425 / 25000 Steps) (loss=0.11886): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3428 / 25000 Steps) (loss=0.11926): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (3431 / 25000 Steps) (loss=0.11249): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (3434 / 25000 Steps) (loss=0.11111): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (3437 / 25000 Steps) (loss=0.12959): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (3440 / 25000 Steps) (loss=0.12601): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (3443 / 25000 Steps) (loss=0.13071): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (3446 / 25000 Steps) (loss=0.11760): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (3449 / 25000 Steps) (loss=0.13330): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (3452 / 25000 Steps) (loss=0.12465): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (3455 / 25000 Steps) (loss=0.11894): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (3458 / 25000 Steps) (loss=0.12358): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (3461 / 25000 Steps) (loss=0.10912): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (3464 / 25000 Steps) (loss=0.12057): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (3467 / 25000 Steps) (loss=0.12413): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (3470 / 25000 Steps) (loss=0.10044): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (3473 / 25000 Steps) (loss=0.11822): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (3476 / 25000 Steps) (loss=0.10793): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (3479 / 25000 Steps) (loss=0.11492): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (3482 / 25000 Steps) (loss=0.10918): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (3485 / 25000 Steps) (loss=0.13634): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3488 / 25000 Steps) (loss=0.13523): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (3491 / 25000 Steps) (loss=0.11468): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (3494 / 25000 Steps) (loss=0.14150): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (3497 / 25000 Steps) (loss=0.13551): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Validate (3498 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]it]\n",
      "Training (3500 / 25000 Steps) (loss=0.11832): 100%|██████████| 3/3 [00:02<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (3500 / 25000 Steps) (loss=0.11832): 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
      "Training (3503 / 25000 Steps) (loss=0.13925): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (3506 / 25000 Steps) (loss=0.11501): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (3509 / 25000 Steps) (loss=0.10550): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (3512 / 25000 Steps) (loss=0.12450): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (3515 / 25000 Steps) (loss=0.10583): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (3518 / 25000 Steps) (loss=0.12160): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (3521 / 25000 Steps) (loss=0.14009): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (3524 / 25000 Steps) (loss=0.11166): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (3527 / 25000 Steps) (loss=0.12514): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (3530 / 25000 Steps) (loss=0.14012): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (3533 / 25000 Steps) (loss=0.14659): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (3536 / 25000 Steps) (loss=0.12224): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (3539 / 25000 Steps) (loss=0.13055): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (3542 / 25000 Steps) (loss=0.13551): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3545 / 25000 Steps) (loss=0.09979): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (3548 / 25000 Steps) (loss=0.11941): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (3551 / 25000 Steps) (loss=0.10806): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (3554 / 25000 Steps) (loss=0.08569): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (3557 / 25000 Steps) (loss=0.09799): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (3560 / 25000 Steps) (loss=0.10849): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (3563 / 25000 Steps) (loss=0.11855): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (3566 / 25000 Steps) (loss=0.11185): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (3569 / 25000 Steps) (loss=0.12439): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (3572 / 25000 Steps) (loss=0.12976): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (3575 / 25000 Steps) (loss=0.11614): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3578 / 25000 Steps) (loss=0.13313): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (3581 / 25000 Steps) (loss=0.12217): 100%|██████████| 3/3 [00:02<00:00,  1.02it/s]\n",
      "Training (3584 / 25000 Steps) (loss=0.11792): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (3587 / 25000 Steps) (loss=0.11511): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (3590 / 25000 Steps) (loss=0.12044): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (3593 / 25000 Steps) (loss=0.10288): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (3596 / 25000 Steps) (loss=0.13276): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (3599 / 25000 Steps) (loss=0.10176): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (3602 / 25000 Steps) (loss=0.11215): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (3605 / 25000 Steps) (loss=0.09233): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (3608 / 25000 Steps) (loss=0.13154): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (3611 / 25000 Steps) (loss=0.13119): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (3614 / 25000 Steps) (loss=0.11437): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (3617 / 25000 Steps) (loss=0.13801): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (3620 / 25000 Steps) (loss=0.13183): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (3623 / 25000 Steps) (loss=0.11551): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (3626 / 25000 Steps) (loss=0.13000): 100%|██████████| 3/3 [00:02<00:00,  1.25it/s]\n",
      "Training (3629 / 25000 Steps) (loss=0.10758): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (3632 / 25000 Steps) (loss=0.11181): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (3635 / 25000 Steps) (loss=0.12667): 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
      "Training (3638 / 25000 Steps) (loss=0.09840): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (3641 / 25000 Steps) (loss=0.12997): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (3644 / 25000 Steps) (loss=0.10023): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (3647 / 25000 Steps) (loss=0.10344): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (3650 / 25000 Steps) (loss=0.13829): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (3653 / 25000 Steps) (loss=0.11326): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (3656 / 25000 Steps) (loss=0.10018): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (3659 / 25000 Steps) (loss=0.12154): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3662 / 25000 Steps) (loss=0.13976): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (3665 / 25000 Steps) (loss=0.11767): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (3668 / 25000 Steps) (loss=0.10462): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (3671 / 25000 Steps) (loss=0.11074): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (3674 / 25000 Steps) (loss=0.12092): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3677 / 25000 Steps) (loss=0.11615): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (3680 / 25000 Steps) (loss=0.09793): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (3683 / 25000 Steps) (loss=0.10061): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (3686 / 25000 Steps) (loss=0.10886): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (3689 / 25000 Steps) (loss=0.12564): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (3692 / 25000 Steps) (loss=0.09873): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (3695 / 25000 Steps) (loss=0.13728): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (3698 / 25000 Steps) (loss=0.10551): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (3701 / 25000 Steps) (loss=0.12255): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (3704 / 25000 Steps) (loss=0.11030): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (3707 / 25000 Steps) (loss=0.10769): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (3710 / 25000 Steps) (loss=0.11631): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (3713 / 25000 Steps) (loss=0.12204): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (3716 / 25000 Steps) (loss=0.10461): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (3719 / 25000 Steps) (loss=0.10965): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3722 / 25000 Steps) (loss=0.12657): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (3725 / 25000 Steps) (loss=0.10660): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (3728 / 25000 Steps) (loss=0.15052): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (3731 / 25000 Steps) (loss=0.12535): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (3734 / 25000 Steps) (loss=0.09477): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (3737 / 25000 Steps) (loss=0.12953): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (3740 / 25000 Steps) (loss=0.11879): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (3743 / 25000 Steps) (loss=0.10561): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (3746 / 25000 Steps) (loss=0.11328): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (3749 / 25000 Steps) (loss=0.11772): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (3752 / 25000 Steps) (loss=0.11332): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (3755 / 25000 Steps) (loss=0.10446): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (3758 / 25000 Steps) (loss=0.10802): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (3761 / 25000 Steps) (loss=0.09717): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (3764 / 25000 Steps) (loss=0.09989): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (3767 / 25000 Steps) (loss=0.10507): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (3770 / 25000 Steps) (loss=0.10158): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (3773 / 25000 Steps) (loss=0.10399): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (3776 / 25000 Steps) (loss=0.10630): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (3779 / 25000 Steps) (loss=0.11224): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (3782 / 25000 Steps) (loss=0.10878): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (3785 / 25000 Steps) (loss=0.09813): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (3788 / 25000 Steps) (loss=0.09988): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (3791 / 25000 Steps) (loss=0.12948): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (3794 / 25000 Steps) (loss=0.11251): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (3797 / 25000 Steps) (loss=0.10513): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (3800 / 25000 Steps) (loss=0.10856): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (3803 / 25000 Steps) (loss=0.09871): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (3806 / 25000 Steps) (loss=0.12271): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (3809 / 25000 Steps) (loss=0.11093): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (3812 / 25000 Steps) (loss=0.10076): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (3815 / 25000 Steps) (loss=0.11706): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (3818 / 25000 Steps) (loss=0.09930): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3821 / 25000 Steps) (loss=0.13219): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (3824 / 25000 Steps) (loss=0.11909): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (3827 / 25000 Steps) (loss=0.12261): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (3830 / 25000 Steps) (loss=0.12973): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (3833 / 25000 Steps) (loss=0.09626): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (3836 / 25000 Steps) (loss=0.11868): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (3839 / 25000 Steps) (loss=0.08703): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (3842 / 25000 Steps) (loss=0.10782): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3845 / 25000 Steps) (loss=0.10728): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (3848 / 25000 Steps) (loss=0.10019): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3851 / 25000 Steps) (loss=0.08994): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (3854 / 25000 Steps) (loss=0.10311): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (3857 / 25000 Steps) (loss=0.09834): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3860 / 25000 Steps) (loss=0.08094): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (3863 / 25000 Steps) (loss=0.10908): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (3866 / 25000 Steps) (loss=0.09855): 100%|██████████| 3/3 [00:02<00:00,  1.14it/s]\n",
      "Training (3869 / 25000 Steps) (loss=0.09918): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (3872 / 25000 Steps) (loss=0.10411): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (3875 / 25000 Steps) (loss=0.10682): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (3878 / 25000 Steps) (loss=0.09037): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (3881 / 25000 Steps) (loss=0.11865): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (3884 / 25000 Steps) (loss=0.11960): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (3887 / 25000 Steps) (loss=0.10500): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (3890 / 25000 Steps) (loss=0.11093): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (3893 / 25000 Steps) (loss=0.09600): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (3896 / 25000 Steps) (loss=0.09902): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (3899 / 25000 Steps) (loss=0.09843): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (3902 / 25000 Steps) (loss=0.09784): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (3905 / 25000 Steps) (loss=0.10422): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (3908 / 25000 Steps) (loss=0.10822): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3911 / 25000 Steps) (loss=0.10908): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (3914 / 25000 Steps) (loss=0.10584): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (3917 / 25000 Steps) (loss=0.09721): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (3920 / 25000 Steps) (loss=0.10897): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (3923 / 25000 Steps) (loss=0.08503): 100%|██████████| 3/3 [00:03<00:00,  1.05s/it]\n",
      "Training (3926 / 25000 Steps) (loss=0.11376): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (3929 / 25000 Steps) (loss=0.10023): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3932 / 25000 Steps) (loss=0.13178): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (3935 / 25000 Steps) (loss=0.09782): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (3938 / 25000 Steps) (loss=0.10429): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (3941 / 25000 Steps) (loss=0.08710): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (3944 / 25000 Steps) (loss=0.11881): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (3947 / 25000 Steps) (loss=0.12074): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (3950 / 25000 Steps) (loss=0.11464): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (3953 / 25000 Steps) (loss=0.10397): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (3956 / 25000 Steps) (loss=0.10960): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (3959 / 25000 Steps) (loss=0.09757): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (3962 / 25000 Steps) (loss=0.11645): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (3965 / 25000 Steps) (loss=0.09200): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (3968 / 25000 Steps) (loss=0.10051): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (3971 / 25000 Steps) (loss=0.09065): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (3974 / 25000 Steps) (loss=0.10445): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (3977 / 25000 Steps) (loss=0.10307): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (3980 / 25000 Steps) (loss=0.09466): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (3983 / 25000 Steps) (loss=0.10436): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (3986 / 25000 Steps) (loss=0.10958): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (3989 / 25000 Steps) (loss=0.10677): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (3992 / 25000 Steps) (loss=0.10715): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (3995 / 25000 Steps) (loss=0.10179): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (3998 / 25000 Steps) (loss=0.11578): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Validate (3999 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]it]\n",
      "Training (4001 / 25000 Steps) (loss=0.07277):  67%|██████▋   | 2/3 [00:02<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (4001 / 25000 Steps) (loss=0.07277): 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]\n",
      "Training (4004 / 25000 Steps) (loss=0.10766): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (4007 / 25000 Steps) (loss=0.10741): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (4010 / 25000 Steps) (loss=0.11187): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (4013 / 25000 Steps) (loss=0.10631): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (4016 / 25000 Steps) (loss=0.10178): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (4019 / 25000 Steps) (loss=0.10797): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (4022 / 25000 Steps) (loss=0.09330): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (4025 / 25000 Steps) (loss=0.11522): 100%|██████████| 3/3 [00:01<00:00,  2.03it/s]\n",
      "Training (4028 / 25000 Steps) (loss=0.10482): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (4031 / 25000 Steps) (loss=0.08927): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (4034 / 25000 Steps) (loss=0.10554): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (4037 / 25000 Steps) (loss=0.09292): 100%|██████████| 3/3 [00:02<00:00,  1.16it/s]\n",
      "Training (4040 / 25000 Steps) (loss=0.08767): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (4043 / 25000 Steps) (loss=0.10046): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (4046 / 25000 Steps) (loss=0.09521): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (4049 / 25000 Steps) (loss=0.10960): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (4052 / 25000 Steps) (loss=0.10052): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (4055 / 25000 Steps) (loss=0.09356): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (4058 / 25000 Steps) (loss=0.11219): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (4061 / 25000 Steps) (loss=0.10364): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (4064 / 25000 Steps) (loss=0.11918): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (4067 / 25000 Steps) (loss=0.08827): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (4070 / 25000 Steps) (loss=0.10077): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (4073 / 25000 Steps) (loss=0.09737): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (4076 / 25000 Steps) (loss=0.09652): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (4079 / 25000 Steps) (loss=0.09589): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (4082 / 25000 Steps) (loss=0.11119): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (4085 / 25000 Steps) (loss=0.08377): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (4088 / 25000 Steps) (loss=0.09916): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (4091 / 25000 Steps) (loss=0.08339): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (4094 / 25000 Steps) (loss=0.10575): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (4097 / 25000 Steps) (loss=0.09225): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (4100 / 25000 Steps) (loss=0.10311): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (4103 / 25000 Steps) (loss=0.08961): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (4106 / 25000 Steps) (loss=0.08123): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (4109 / 25000 Steps) (loss=0.10475): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (4112 / 25000 Steps) (loss=0.09109): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (4115 / 25000 Steps) (loss=0.08648): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (4118 / 25000 Steps) (loss=0.09385): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (4121 / 25000 Steps) (loss=0.09329): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (4124 / 25000 Steps) (loss=0.09514): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (4127 / 25000 Steps) (loss=0.11329): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (4130 / 25000 Steps) (loss=0.09118): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (4133 / 25000 Steps) (loss=0.10060): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (4136 / 25000 Steps) (loss=0.08567): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (4139 / 25000 Steps) (loss=0.08335): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (4142 / 25000 Steps) (loss=0.08495): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (4145 / 25000 Steps) (loss=0.09476): 100%|██████████| 3/3 [00:02<00:00,  1.07it/s]\n",
      "Training (4148 / 25000 Steps) (loss=0.10766): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (4151 / 25000 Steps) (loss=0.10063): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (4154 / 25000 Steps) (loss=0.09721): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (4157 / 25000 Steps) (loss=0.08946): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (4160 / 25000 Steps) (loss=0.10032): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (4163 / 25000 Steps) (loss=0.09237): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (4166 / 25000 Steps) (loss=0.08764): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (4169 / 25000 Steps) (loss=0.07642): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (4172 / 25000 Steps) (loss=0.09929): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (4175 / 25000 Steps) (loss=0.12043): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (4178 / 25000 Steps) (loss=0.10958): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (4181 / 25000 Steps) (loss=0.09834): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (4184 / 25000 Steps) (loss=0.09082): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (4187 / 25000 Steps) (loss=0.08683): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (4190 / 25000 Steps) (loss=0.10157): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (4193 / 25000 Steps) (loss=0.08825): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (4196 / 25000 Steps) (loss=0.08754): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (4199 / 25000 Steps) (loss=0.09166): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (4202 / 25000 Steps) (loss=0.10560): 100%|██████████| 3/3 [00:02<00:00,  1.14it/s]\n",
      "Training (4205 / 25000 Steps) (loss=0.08735): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (4208 / 25000 Steps) (loss=0.07404): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (4211 / 25000 Steps) (loss=0.11106): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (4214 / 25000 Steps) (loss=0.11394): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (4217 / 25000 Steps) (loss=0.10844): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (4220 / 25000 Steps) (loss=0.08238): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (4223 / 25000 Steps) (loss=0.12945): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (4226 / 25000 Steps) (loss=0.09746): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (4229 / 25000 Steps) (loss=0.08689): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (4232 / 25000 Steps) (loss=0.09314): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (4235 / 25000 Steps) (loss=0.10162): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (4238 / 25000 Steps) (loss=0.10342): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (4241 / 25000 Steps) (loss=0.09509): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (4244 / 25000 Steps) (loss=0.08694): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (4247 / 25000 Steps) (loss=0.09773): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (4250 / 25000 Steps) (loss=0.08939): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (4253 / 25000 Steps) (loss=0.08633): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (4256 / 25000 Steps) (loss=0.08943): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (4259 / 25000 Steps) (loss=0.09369): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (4262 / 25000 Steps) (loss=0.11256): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (4265 / 25000 Steps) (loss=0.07053): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (4268 / 25000 Steps) (loss=0.10499): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (4271 / 25000 Steps) (loss=0.09264): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (4274 / 25000 Steps) (loss=0.10393): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (4277 / 25000 Steps) (loss=0.09731): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (4280 / 25000 Steps) (loss=0.10685): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (4283 / 25000 Steps) (loss=0.11720): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (4286 / 25000 Steps) (loss=0.08937): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (4289 / 25000 Steps) (loss=0.10284): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (4292 / 25000 Steps) (loss=0.09814): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (4295 / 25000 Steps) (loss=0.08058): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (4298 / 25000 Steps) (loss=0.09724): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (4301 / 25000 Steps) (loss=0.09646): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (4304 / 25000 Steps) (loss=0.08331): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (4307 / 25000 Steps) (loss=0.08923): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (4310 / 25000 Steps) (loss=0.11450): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (4313 / 25000 Steps) (loss=0.08503): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (4316 / 25000 Steps) (loss=0.08281): 100%|██████████| 3/3 [00:02<00:00,  1.00it/s]\n",
      "Training (4319 / 25000 Steps) (loss=0.08356): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (4322 / 25000 Steps) (loss=0.09680): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (4325 / 25000 Steps) (loss=0.07851): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (4328 / 25000 Steps) (loss=0.11126): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (4331 / 25000 Steps) (loss=0.07275): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (4334 / 25000 Steps) (loss=0.10233): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (4337 / 25000 Steps) (loss=0.09467): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (4340 / 25000 Steps) (loss=0.08146): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (4343 / 25000 Steps) (loss=0.08839): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (4346 / 25000 Steps) (loss=0.10795): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (4349 / 25000 Steps) (loss=0.07815): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (4352 / 25000 Steps) (loss=0.09410): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (4355 / 25000 Steps) (loss=0.08756): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (4358 / 25000 Steps) (loss=0.07388): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (4361 / 25000 Steps) (loss=0.08758): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (4364 / 25000 Steps) (loss=0.08838): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (4367 / 25000 Steps) (loss=0.07802): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (4370 / 25000 Steps) (loss=0.10763): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (4373 / 25000 Steps) (loss=0.07901): 100%|██████████| 3/3 [00:03<00:00,  1.05s/it]\n",
      "Training (4376 / 25000 Steps) (loss=0.10056): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (4379 / 25000 Steps) (loss=0.10667): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (4382 / 25000 Steps) (loss=0.08737): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (4385 / 25000 Steps) (loss=0.09777): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (4388 / 25000 Steps) (loss=0.09249): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (4391 / 25000 Steps) (loss=0.11115): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (4394 / 25000 Steps) (loss=0.08234): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (4397 / 25000 Steps) (loss=0.07217): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (4400 / 25000 Steps) (loss=0.08713): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (4403 / 25000 Steps) (loss=0.08268): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (4406 / 25000 Steps) (loss=0.08085): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (4409 / 25000 Steps) (loss=0.08019): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (4412 / 25000 Steps) (loss=0.06843): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (4415 / 25000 Steps) (loss=0.06907): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (4418 / 25000 Steps) (loss=0.09014): 100%|██████████| 3/3 [00:01<00:00,  1.98it/s]\n",
      "Training (4421 / 25000 Steps) (loss=0.07864): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (4424 / 25000 Steps) (loss=0.07701): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (4427 / 25000 Steps) (loss=0.08431): 100%|██████████| 3/3 [00:02<00:00,  1.10it/s]\n",
      "Training (4430 / 25000 Steps) (loss=0.07358): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (4433 / 25000 Steps) (loss=0.08844): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (4436 / 25000 Steps) (loss=0.08410): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (4439 / 25000 Steps) (loss=0.08668): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (4442 / 25000 Steps) (loss=0.08974): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (4445 / 25000 Steps) (loss=0.07776): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (4448 / 25000 Steps) (loss=0.11229): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (4451 / 25000 Steps) (loss=0.07219): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (4454 / 25000 Steps) (loss=0.07857): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (4457 / 25000 Steps) (loss=0.08015): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (4460 / 25000 Steps) (loss=0.09419): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (4463 / 25000 Steps) (loss=0.08406): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (4466 / 25000 Steps) (loss=0.08537): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (4469 / 25000 Steps) (loss=0.08038): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (4472 / 25000 Steps) (loss=0.07810): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (4475 / 25000 Steps) (loss=0.09566): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (4478 / 25000 Steps) (loss=0.10287): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (4481 / 25000 Steps) (loss=0.08289): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (4484 / 25000 Steps) (loss=0.07407): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (4487 / 25000 Steps) (loss=0.07919): 100%|██████████| 3/3 [00:02<00:00,  1.08it/s]\n",
      "Training (4490 / 25000 Steps) (loss=0.08157): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (4493 / 25000 Steps) (loss=0.07498): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (4496 / 25000 Steps) (loss=0.08767): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (4499 / 25000 Steps) (loss=0.08037): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Validate (4500 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "Training (4502 / 25000 Steps) (loss=0.07061): 100%|██████████| 3/3 [00:02<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (4502 / 25000 Steps) (loss=0.07061): 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
      "Training (4505 / 25000 Steps) (loss=0.09356): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (4508 / 25000 Steps) (loss=0.08679): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (4511 / 25000 Steps) (loss=0.07504): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (4514 / 25000 Steps) (loss=0.07831): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (4517 / 25000 Steps) (loss=0.08778): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (4520 / 25000 Steps) (loss=0.06879): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (4523 / 25000 Steps) (loss=0.10605): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (4526 / 25000 Steps) (loss=0.07485): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (4529 / 25000 Steps) (loss=0.08134): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (4532 / 25000 Steps) (loss=0.10516): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (4535 / 25000 Steps) (loss=0.08545): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (4538 / 25000 Steps) (loss=0.09009): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (4541 / 25000 Steps) (loss=0.11400): 100%|██████████| 3/3 [00:03<00:00,  1.14s/it]\n",
      "Training (4544 / 25000 Steps) (loss=0.08859): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (4547 / 25000 Steps) (loss=0.08787): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (4550 / 25000 Steps) (loss=0.07518): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (4553 / 25000 Steps) (loss=0.08136): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (4556 / 25000 Steps) (loss=0.06079): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (4559 / 25000 Steps) (loss=0.08565): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (4562 / 25000 Steps) (loss=0.08704): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (4565 / 25000 Steps) (loss=0.07751): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (4568 / 25000 Steps) (loss=0.06672): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (4571 / 25000 Steps) (loss=0.08321): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (4574 / 25000 Steps) (loss=0.07810): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (4577 / 25000 Steps) (loss=0.08102): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (4580 / 25000 Steps) (loss=0.07515): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (4583 / 25000 Steps) (loss=0.08092): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (4586 / 25000 Steps) (loss=0.08441): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (4589 / 25000 Steps) (loss=0.07392): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (4592 / 25000 Steps) (loss=0.07046): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (4595 / 25000 Steps) (loss=0.07880): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (4598 / 25000 Steps) (loss=0.09796): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (4601 / 25000 Steps) (loss=0.09740): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (4604 / 25000 Steps) (loss=0.08187): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (4607 / 25000 Steps) (loss=0.08633): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (4610 / 25000 Steps) (loss=0.09461): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (4613 / 25000 Steps) (loss=0.08472): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (4616 / 25000 Steps) (loss=0.08767): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (4619 / 25000 Steps) (loss=0.08514): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (4622 / 25000 Steps) (loss=0.07894): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (4625 / 25000 Steps) (loss=0.07681): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (4628 / 25000 Steps) (loss=0.08519): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (4631 / 25000 Steps) (loss=0.09623): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (4634 / 25000 Steps) (loss=0.09633): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (4637 / 25000 Steps) (loss=0.07819): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (4640 / 25000 Steps) (loss=0.09585): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (4643 / 25000 Steps) (loss=0.09269): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (4646 / 25000 Steps) (loss=0.07432): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (4649 / 25000 Steps) (loss=0.08188): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (4652 / 25000 Steps) (loss=0.05937): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (4655 / 25000 Steps) (loss=0.10315): 100%|██████████| 3/3 [00:03<00:00,  1.07s/it]\n",
      "Training (4658 / 25000 Steps) (loss=0.06818): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (4661 / 25000 Steps) (loss=0.07063): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (4664 / 25000 Steps) (loss=0.07223): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (4667 / 25000 Steps) (loss=0.08379): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (4670 / 25000 Steps) (loss=0.09100): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (4673 / 25000 Steps) (loss=0.11401): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (4676 / 25000 Steps) (loss=0.06306): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (4679 / 25000 Steps) (loss=0.08470): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (4682 / 25000 Steps) (loss=0.09438): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (4685 / 25000 Steps) (loss=0.07033): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (4688 / 25000 Steps) (loss=0.07529): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (4691 / 25000 Steps) (loss=0.07770): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (4694 / 25000 Steps) (loss=0.07221): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (4697 / 25000 Steps) (loss=0.06803): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (4700 / 25000 Steps) (loss=0.08300): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (4703 / 25000 Steps) (loss=0.08111): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (4706 / 25000 Steps) (loss=0.07279): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (4709 / 25000 Steps) (loss=0.07883): 100%|██████████| 3/3 [00:02<00:00,  1.16it/s]\n",
      "Training (4712 / 25000 Steps) (loss=0.08485): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (4715 / 25000 Steps) (loss=0.08719): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (4718 / 25000 Steps) (loss=0.07539): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (4721 / 25000 Steps) (loss=0.08769): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (4724 / 25000 Steps) (loss=0.06990): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (4727 / 25000 Steps) (loss=0.09516): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (4730 / 25000 Steps) (loss=0.06596): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (4733 / 25000 Steps) (loss=0.07275): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (4736 / 25000 Steps) (loss=0.08885): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (4739 / 25000 Steps) (loss=0.08289): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (4742 / 25000 Steps) (loss=0.06237): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (4745 / 25000 Steps) (loss=0.08835): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (4748 / 25000 Steps) (loss=0.06450): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (4751 / 25000 Steps) (loss=0.06608): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (4754 / 25000 Steps) (loss=0.09003): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (4757 / 25000 Steps) (loss=0.09983): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (4760 / 25000 Steps) (loss=0.09187): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (4763 / 25000 Steps) (loss=0.07220): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (4766 / 25000 Steps) (loss=0.08576): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (4769 / 25000 Steps) (loss=0.08257): 100%|██████████| 3/3 [00:02<00:00,  1.22it/s]\n",
      "Training (4772 / 25000 Steps) (loss=0.07921): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (4775 / 25000 Steps) (loss=0.07721): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (4778 / 25000 Steps) (loss=0.06805): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (4781 / 25000 Steps) (loss=0.07632): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (4784 / 25000 Steps) (loss=0.07173): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (4787 / 25000 Steps) (loss=0.07027): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (4790 / 25000 Steps) (loss=0.07081): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (4793 / 25000 Steps) (loss=0.08907): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (4796 / 25000 Steps) (loss=0.06803): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (4799 / 25000 Steps) (loss=0.08950): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (4802 / 25000 Steps) (loss=0.07882): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (4805 / 25000 Steps) (loss=0.07858): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (4808 / 25000 Steps) (loss=0.08364): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (4811 / 25000 Steps) (loss=0.08113): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (4814 / 25000 Steps) (loss=0.07177): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (4817 / 25000 Steps) (loss=0.07889): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (4820 / 25000 Steps) (loss=0.06998): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (4823 / 25000 Steps) (loss=0.07872): 100%|██████████| 3/3 [00:02<00:00,  1.25it/s]\n",
      "Training (4826 / 25000 Steps) (loss=0.07267): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (4829 / 25000 Steps) (loss=0.07404): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (4832 / 25000 Steps) (loss=0.06752): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (4835 / 25000 Steps) (loss=0.07991): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (4838 / 25000 Steps) (loss=0.07718): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (4841 / 25000 Steps) (loss=0.06972): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (4844 / 25000 Steps) (loss=0.07436): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (4847 / 25000 Steps) (loss=0.06710): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (4850 / 25000 Steps) (loss=0.07983): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (4853 / 25000 Steps) (loss=0.07518): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (4856 / 25000 Steps) (loss=0.07965): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (4859 / 25000 Steps) (loss=0.06804): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (4862 / 25000 Steps) (loss=0.07415): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (4865 / 25000 Steps) (loss=0.09208): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (4868 / 25000 Steps) (loss=0.06914): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (4871 / 25000 Steps) (loss=0.07526): 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "Training (4874 / 25000 Steps) (loss=0.06780): 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "Training (4877 / 25000 Steps) (loss=0.10213): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (4880 / 25000 Steps) (loss=0.08577): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (4883 / 25000 Steps) (loss=0.08218): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (4886 / 25000 Steps) (loss=0.07494): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (4889 / 25000 Steps) (loss=0.06660): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (4892 / 25000 Steps) (loss=0.06768): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (4895 / 25000 Steps) (loss=0.07314): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (4898 / 25000 Steps) (loss=0.07993): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (4901 / 25000 Steps) (loss=0.05533): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (4904 / 25000 Steps) (loss=0.08648): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (4907 / 25000 Steps) (loss=0.07894): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (4910 / 25000 Steps) (loss=0.06527): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (4913 / 25000 Steps) (loss=0.06557): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (4916 / 25000 Steps) (loss=0.06375): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (4919 / 25000 Steps) (loss=0.08541): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (4922 / 25000 Steps) (loss=0.07582): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (4925 / 25000 Steps) (loss=0.08047): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (4928 / 25000 Steps) (loss=0.09362): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (4931 / 25000 Steps) (loss=0.07318): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (4934 / 25000 Steps) (loss=0.07540): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (4937 / 25000 Steps) (loss=0.09231): 100%|██████████| 3/3 [00:02<00:00,  1.21it/s]\n",
      "Training (4940 / 25000 Steps) (loss=0.05289): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "Training (4943 / 25000 Steps) (loss=0.06850): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (4946 / 25000 Steps) (loss=0.08920): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (4949 / 25000 Steps) (loss=0.09956): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (4952 / 25000 Steps) (loss=0.06683): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (4955 / 25000 Steps) (loss=0.07483): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (4958 / 25000 Steps) (loss=0.08156): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (4961 / 25000 Steps) (loss=0.07732): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (4964 / 25000 Steps) (loss=0.07179): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (4967 / 25000 Steps) (loss=0.07362): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (4970 / 25000 Steps) (loss=0.06801): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (4973 / 25000 Steps) (loss=0.06326): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (4976 / 25000 Steps) (loss=0.07761): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (4979 / 25000 Steps) (loss=0.06846): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (4982 / 25000 Steps) (loss=0.08085): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (4985 / 25000 Steps) (loss=0.08024): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (4988 / 25000 Steps) (loss=0.07662): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (4991 / 25000 Steps) (loss=0.06687): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (4994 / 25000 Steps) (loss=0.07775): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (4997 / 25000 Steps) (loss=0.06173): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Validate (4998 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]/s]\n",
      "Training (5000 / 25000 Steps) (loss=0.08585): 100%|██████████| 3/3 [00:02<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (5000 / 25000 Steps) (loss=0.08585): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "Training (5003 / 25000 Steps) (loss=0.10609): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (5006 / 25000 Steps) (loss=0.06732): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (5009 / 25000 Steps) (loss=0.08399): 100%|██████████| 3/3 [00:01<00:00,  2.04it/s]\n",
      "Training (5012 / 25000 Steps) (loss=0.09044): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (5015 / 25000 Steps) (loss=0.07345): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (5018 / 25000 Steps) (loss=0.09173): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (5021 / 25000 Steps) (loss=0.07361): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (5024 / 25000 Steps) (loss=0.07349): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (5027 / 25000 Steps) (loss=0.07008): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (5030 / 25000 Steps) (loss=0.07560): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (5033 / 25000 Steps) (loss=0.10452): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (5036 / 25000 Steps) (loss=0.07717): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (5039 / 25000 Steps) (loss=0.06673): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (5042 / 25000 Steps) (loss=0.07334): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (5045 / 25000 Steps) (loss=0.07193): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (5048 / 25000 Steps) (loss=0.07633): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (5051 / 25000 Steps) (loss=0.07739): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (5054 / 25000 Steps) (loss=0.06646): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (5057 / 25000 Steps) (loss=0.06505): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (5060 / 25000 Steps) (loss=0.07631): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (5063 / 25000 Steps) (loss=0.06576): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (5066 / 25000 Steps) (loss=0.07305): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (5069 / 25000 Steps) (loss=0.06195): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (5072 / 25000 Steps) (loss=0.06617): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (5075 / 25000 Steps) (loss=0.08976): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (5078 / 25000 Steps) (loss=0.07967): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (5081 / 25000 Steps) (loss=0.06946): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (5084 / 25000 Steps) (loss=0.06888): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (5087 / 25000 Steps) (loss=0.06031): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (5090 / 25000 Steps) (loss=0.06832): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (5093 / 25000 Steps) (loss=0.07695): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (5096 / 25000 Steps) (loss=0.09577): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (5099 / 25000 Steps) (loss=0.06701): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (5102 / 25000 Steps) (loss=0.07796): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (5105 / 25000 Steps) (loss=0.08289): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (5108 / 25000 Steps) (loss=0.06959): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (5111 / 25000 Steps) (loss=0.08577): 100%|██████████| 3/3 [00:02<00:00,  1.05it/s]\n",
      "Training (5114 / 25000 Steps) (loss=0.07368): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (5117 / 25000 Steps) (loss=0.07007): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (5120 / 25000 Steps) (loss=0.06528): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (5123 / 25000 Steps) (loss=0.07550): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (5126 / 25000 Steps) (loss=0.07854): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (5129 / 25000 Steps) (loss=0.08040): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (5132 / 25000 Steps) (loss=0.07560): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (5135 / 25000 Steps) (loss=0.06896): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (5138 / 25000 Steps) (loss=0.09543): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (5141 / 25000 Steps) (loss=0.07965): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (5144 / 25000 Steps) (loss=0.06122): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (5147 / 25000 Steps) (loss=0.07183): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (5150 / 25000 Steps) (loss=0.07959): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (5153 / 25000 Steps) (loss=0.05584): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (5156 / 25000 Steps) (loss=0.06772): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (5159 / 25000 Steps) (loss=0.07670): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (5162 / 25000 Steps) (loss=0.05547): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (5165 / 25000 Steps) (loss=0.07851): 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "Training (5168 / 25000 Steps) (loss=0.07034): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (5171 / 25000 Steps) (loss=0.08577): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (5174 / 25000 Steps) (loss=0.06686): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (5177 / 25000 Steps) (loss=0.07517): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (5180 / 25000 Steps) (loss=0.07914): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (5183 / 25000 Steps) (loss=0.08479): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (5186 / 25000 Steps) (loss=0.07901): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (5189 / 25000 Steps) (loss=0.07912): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (5192 / 25000 Steps) (loss=0.06814): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (5195 / 25000 Steps) (loss=0.06200): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (5198 / 25000 Steps) (loss=0.06733): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (5201 / 25000 Steps) (loss=0.05493): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (5204 / 25000 Steps) (loss=0.06756): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (5207 / 25000 Steps) (loss=0.10124): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (5210 / 25000 Steps) (loss=0.06548): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (5213 / 25000 Steps) (loss=0.06074): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (5216 / 25000 Steps) (loss=0.06590): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (5219 / 25000 Steps) (loss=0.07639): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (5222 / 25000 Steps) (loss=0.08973): 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]\n",
      "Training (5225 / 25000 Steps) (loss=0.06259): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (5228 / 25000 Steps) (loss=0.05839): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (5231 / 25000 Steps) (loss=0.06514): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (5234 / 25000 Steps) (loss=0.06679): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (5237 / 25000 Steps) (loss=0.07768): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (5240 / 25000 Steps) (loss=0.05848): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (5243 / 25000 Steps) (loss=0.07819): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (5246 / 25000 Steps) (loss=0.06248): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (5249 / 25000 Steps) (loss=0.08247): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (5252 / 25000 Steps) (loss=0.07751): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (5255 / 25000 Steps) (loss=0.07538): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (5258 / 25000 Steps) (loss=0.07641): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (5261 / 25000 Steps) (loss=0.07287): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (5264 / 25000 Steps) (loss=0.07693): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (5267 / 25000 Steps) (loss=0.08982): 100%|██████████| 3/3 [00:01<00:00,  1.98it/s]\n",
      "Training (5270 / 25000 Steps) (loss=0.06863): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (5273 / 25000 Steps) (loss=0.09045): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (5276 / 25000 Steps) (loss=0.07546): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (5279 / 25000 Steps) (loss=0.07441): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (5282 / 25000 Steps) (loss=0.07277): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (5285 / 25000 Steps) (loss=0.06837): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (5288 / 25000 Steps) (loss=0.07567): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (5291 / 25000 Steps) (loss=0.08661): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (5294 / 25000 Steps) (loss=0.05923): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (5297 / 25000 Steps) (loss=0.06557): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (5300 / 25000 Steps) (loss=0.06166): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (5303 / 25000 Steps) (loss=0.06840): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (5306 / 25000 Steps) (loss=0.06413): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (5309 / 25000 Steps) (loss=0.07378): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (5312 / 25000 Steps) (loss=0.07169): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (5315 / 25000 Steps) (loss=0.06499): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (5318 / 25000 Steps) (loss=0.06410): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (5321 / 25000 Steps) (loss=0.07505): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (5324 / 25000 Steps) (loss=0.05970): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (5327 / 25000 Steps) (loss=0.08735): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (5330 / 25000 Steps) (loss=0.07113): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (5333 / 25000 Steps) (loss=0.07602): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (5336 / 25000 Steps) (loss=0.08020): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (5339 / 25000 Steps) (loss=0.06586): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (5342 / 25000 Steps) (loss=0.05946): 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]\n",
      "Training (5345 / 25000 Steps) (loss=0.05792): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (5348 / 25000 Steps) (loss=0.08359): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (5351 / 25000 Steps) (loss=0.06499): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (5354 / 25000 Steps) (loss=0.08651): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (5357 / 25000 Steps) (loss=0.06018): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (5360 / 25000 Steps) (loss=0.06099): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (5363 / 25000 Steps) (loss=0.07752): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (5366 / 25000 Steps) (loss=0.07641): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (5369 / 25000 Steps) (loss=0.06202): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (5372 / 25000 Steps) (loss=0.10045): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (5375 / 25000 Steps) (loss=0.06576): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (5378 / 25000 Steps) (loss=0.06067): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (5381 / 25000 Steps) (loss=0.08921): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (5384 / 25000 Steps) (loss=0.08721): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (5387 / 25000 Steps) (loss=0.07503): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (5390 / 25000 Steps) (loss=0.07061): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (5393 / 25000 Steps) (loss=0.06091): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (5396 / 25000 Steps) (loss=0.07179): 100%|██████████| 3/3 [00:03<00:00,  1.25s/it]\n",
      "Training (5399 / 25000 Steps) (loss=0.05715): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (5402 / 25000 Steps) (loss=0.05725): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (5405 / 25000 Steps) (loss=0.05791): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (5408 / 25000 Steps) (loss=0.06521): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (5411 / 25000 Steps) (loss=0.05829): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (5414 / 25000 Steps) (loss=0.07411): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (5417 / 25000 Steps) (loss=0.07125): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (5420 / 25000 Steps) (loss=0.05775): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (5423 / 25000 Steps) (loss=0.07422): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (5426 / 25000 Steps) (loss=0.05659): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (5429 / 25000 Steps) (loss=0.09628): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (5432 / 25000 Steps) (loss=0.06287): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "Training (5435 / 25000 Steps) (loss=0.06222): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (5438 / 25000 Steps) (loss=0.05442): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (5441 / 25000 Steps) (loss=0.06819): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (5444 / 25000 Steps) (loss=0.07788): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (5447 / 25000 Steps) (loss=0.08211): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (5450 / 25000 Steps) (loss=0.05731): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (5453 / 25000 Steps) (loss=0.07693): 100%|██████████| 3/3 [00:02<00:00,  1.01it/s]\n",
      "Training (5456 / 25000 Steps) (loss=0.07615): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (5459 / 25000 Steps) (loss=0.07402): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (5462 / 25000 Steps) (loss=0.05917): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (5465 / 25000 Steps) (loss=0.05798): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (5468 / 25000 Steps) (loss=0.06797): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (5471 / 25000 Steps) (loss=0.06726): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (5474 / 25000 Steps) (loss=0.09256): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (5477 / 25000 Steps) (loss=0.05089): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (5480 / 25000 Steps) (loss=0.06406): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (5483 / 25000 Steps) (loss=0.07344): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (5486 / 25000 Steps) (loss=0.06858): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (5489 / 25000 Steps) (loss=0.06259): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (5492 / 25000 Steps) (loss=0.08128): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (5495 / 25000 Steps) (loss=0.05365): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (5498 / 25000 Steps) (loss=0.06162): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Validate (5499 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]it]\n",
      "Training (5501 / 25000 Steps) (loss=0.08137):  67%|██████▋   | 2/3 [00:02<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (5501 / 25000 Steps) (loss=0.08137): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (5504 / 25000 Steps) (loss=0.05181): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (5507 / 25000 Steps) (loss=0.07289): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (5510 / 25000 Steps) (loss=0.06299): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (5513 / 25000 Steps) (loss=0.08401): 100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
      "Training (5516 / 25000 Steps) (loss=0.05946): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (5519 / 25000 Steps) (loss=0.06712): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (5522 / 25000 Steps) (loss=0.06343): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (5525 / 25000 Steps) (loss=0.06486): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (5528 / 25000 Steps) (loss=0.06894): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (5531 / 25000 Steps) (loss=0.07818): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (5534 / 25000 Steps) (loss=0.07342): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (5537 / 25000 Steps) (loss=0.07538): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (5540 / 25000 Steps) (loss=0.08647): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (5543 / 25000 Steps) (loss=0.05793): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (5546 / 25000 Steps) (loss=0.06576): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (5549 / 25000 Steps) (loss=0.09485): 100%|██████████| 3/3 [00:01<00:00,  2.08it/s]\n",
      "Training (5552 / 25000 Steps) (loss=0.07603): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (5555 / 25000 Steps) (loss=0.05570): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (5558 / 25000 Steps) (loss=0.06948): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (5561 / 25000 Steps) (loss=0.05612): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (5564 / 25000 Steps) (loss=0.05367): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (5567 / 25000 Steps) (loss=0.06169): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (5570 / 25000 Steps) (loss=0.07775): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (5573 / 25000 Steps) (loss=0.06575): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (5576 / 25000 Steps) (loss=0.05526): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (5579 / 25000 Steps) (loss=0.07206): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (5582 / 25000 Steps) (loss=0.05961): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (5585 / 25000 Steps) (loss=0.06922): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (5588 / 25000 Steps) (loss=0.06605): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (5591 / 25000 Steps) (loss=0.05356): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (5594 / 25000 Steps) (loss=0.07843): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (5597 / 25000 Steps) (loss=0.08333): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (5600 / 25000 Steps) (loss=0.06829): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (5603 / 25000 Steps) (loss=0.06464): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (5606 / 25000 Steps) (loss=0.05235): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (5609 / 25000 Steps) (loss=0.05763): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (5612 / 25000 Steps) (loss=0.07095): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (5615 / 25000 Steps) (loss=0.06220): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (5618 / 25000 Steps) (loss=0.05620): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (5621 / 25000 Steps) (loss=0.07950): 100%|██████████| 3/3 [00:01<00:00,  1.99it/s]\n",
      "Training (5624 / 25000 Steps) (loss=0.07517): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (5627 / 25000 Steps) (loss=0.05896): 100%|██████████| 3/3 [00:02<00:00,  1.16it/s]\n",
      "Training (5630 / 25000 Steps) (loss=0.06491): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "Training (5633 / 25000 Steps) (loss=0.05726): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (5636 / 25000 Steps) (loss=0.06043): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (5639 / 25000 Steps) (loss=0.06528): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (5642 / 25000 Steps) (loss=0.07668): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (5645 / 25000 Steps) (loss=0.05645): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (5648 / 25000 Steps) (loss=0.06574): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (5651 / 25000 Steps) (loss=0.08635): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (5654 / 25000 Steps) (loss=0.06903): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (5657 / 25000 Steps) (loss=0.06192): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (5660 / 25000 Steps) (loss=0.05088): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (5663 / 25000 Steps) (loss=0.05578): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (5666 / 25000 Steps) (loss=0.06993): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (5669 / 25000 Steps) (loss=0.06769): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (5672 / 25000 Steps) (loss=0.08501): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (5675 / 25000 Steps) (loss=0.06817): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (5678 / 25000 Steps) (loss=0.05790): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (5681 / 25000 Steps) (loss=0.07792): 100%|██████████| 3/3 [00:02<00:00,  1.16it/s]\n",
      "Training (5684 / 25000 Steps) (loss=0.07275): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (5687 / 25000 Steps) (loss=0.06990): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (5690 / 25000 Steps) (loss=0.06607): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (5693 / 25000 Steps) (loss=0.05492): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (5696 / 25000 Steps) (loss=0.06594): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (5699 / 25000 Steps) (loss=0.05434): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (5702 / 25000 Steps) (loss=0.06166): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (5705 / 25000 Steps) (loss=0.05685): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (5708 / 25000 Steps) (loss=0.06333): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (5711 / 25000 Steps) (loss=0.06255): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (5714 / 25000 Steps) (loss=0.08373): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (5717 / 25000 Steps) (loss=0.07694): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (5720 / 25000 Steps) (loss=0.06358): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (5723 / 25000 Steps) (loss=0.05516): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (5726 / 25000 Steps) (loss=0.07012): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (5729 / 25000 Steps) (loss=0.06208): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (5732 / 25000 Steps) (loss=0.05493): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (5735 / 25000 Steps) (loss=0.06373): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (5738 / 25000 Steps) (loss=0.06892): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (5741 / 25000 Steps) (loss=0.06818): 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
      "Training (5744 / 25000 Steps) (loss=0.06577): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (5747 / 25000 Steps) (loss=0.06947): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (5750 / 25000 Steps) (loss=0.06951): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (5753 / 25000 Steps) (loss=0.07165): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (5756 / 25000 Steps) (loss=0.05270): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (5759 / 25000 Steps) (loss=0.05079): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (5762 / 25000 Steps) (loss=0.06974): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (5765 / 25000 Steps) (loss=0.06634): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (5768 / 25000 Steps) (loss=0.06452): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (5771 / 25000 Steps) (loss=0.08115): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (5774 / 25000 Steps) (loss=0.03823): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (5777 / 25000 Steps) (loss=0.06154): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (5780 / 25000 Steps) (loss=0.05675): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (5783 / 25000 Steps) (loss=0.05795): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (5786 / 25000 Steps) (loss=0.07027): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (5789 / 25000 Steps) (loss=0.05137): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (5792 / 25000 Steps) (loss=0.05830): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (5795 / 25000 Steps) (loss=0.05990): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (5798 / 25000 Steps) (loss=0.06981): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (5801 / 25000 Steps) (loss=0.06997): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (5804 / 25000 Steps) (loss=0.06800): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (5807 / 25000 Steps) (loss=0.07025): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (5810 / 25000 Steps) (loss=0.08457): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (5813 / 25000 Steps) (loss=0.06056): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (5816 / 25000 Steps) (loss=0.08466): 100%|██████████| 3/3 [00:02<00:00,  1.19it/s]\n",
      "Training (5819 / 25000 Steps) (loss=0.06078): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (5822 / 25000 Steps) (loss=0.06654): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (5825 / 25000 Steps) (loss=0.06846): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (5828 / 25000 Steps) (loss=0.06561): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (5831 / 25000 Steps) (loss=0.06892): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (5834 / 25000 Steps) (loss=0.07396): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (5837 / 25000 Steps) (loss=0.05197): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (5840 / 25000 Steps) (loss=0.06640): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (5843 / 25000 Steps) (loss=0.07075): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (5846 / 25000 Steps) (loss=0.07591): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (5849 / 25000 Steps) (loss=0.06387): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (5852 / 25000 Steps) (loss=0.04612): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (5855 / 25000 Steps) (loss=0.06379): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (5858 / 25000 Steps) (loss=0.07087): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (5861 / 25000 Steps) (loss=0.05712): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (5864 / 25000 Steps) (loss=0.07863): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (5867 / 25000 Steps) (loss=0.05813): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (5870 / 25000 Steps) (loss=0.06734): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (5873 / 25000 Steps) (loss=0.05776): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (5876 / 25000 Steps) (loss=0.05140): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (5879 / 25000 Steps) (loss=0.05499): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (5882 / 25000 Steps) (loss=0.05703): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (5885 / 25000 Steps) (loss=0.04696): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (5888 / 25000 Steps) (loss=0.06126): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (5891 / 25000 Steps) (loss=0.06295): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (5894 / 25000 Steps) (loss=0.05417): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (5897 / 25000 Steps) (loss=0.07793): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (5900 / 25000 Steps) (loss=0.05990): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (5903 / 25000 Steps) (loss=0.06116): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (5906 / 25000 Steps) (loss=0.06486): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (5909 / 25000 Steps) (loss=0.05743): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (5912 / 25000 Steps) (loss=0.06431): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (5915 / 25000 Steps) (loss=0.04581): 100%|██████████| 3/3 [00:03<00:00,  1.17s/it]\n",
      "Training (5918 / 25000 Steps) (loss=0.07360): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (5921 / 25000 Steps) (loss=0.05284): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (5924 / 25000 Steps) (loss=0.09050): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (5927 / 25000 Steps) (loss=0.05490): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (5930 / 25000 Steps) (loss=0.06061): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (5933 / 25000 Steps) (loss=0.06422): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (5936 / 25000 Steps) (loss=0.05592): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (5939 / 25000 Steps) (loss=0.05869): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (5942 / 25000 Steps) (loss=0.07264): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (5945 / 25000 Steps) (loss=0.04929): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (5948 / 25000 Steps) (loss=0.06357): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (5951 / 25000 Steps) (loss=0.06132): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (5954 / 25000 Steps) (loss=0.07617): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (5957 / 25000 Steps) (loss=0.06736): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (5960 / 25000 Steps) (loss=0.07338): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (5963 / 25000 Steps) (loss=0.06421): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (5966 / 25000 Steps) (loss=0.04634): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (5969 / 25000 Steps) (loss=0.07270): 100%|██████████| 3/3 [00:02<00:00,  1.14it/s]\n",
      "Training (5972 / 25000 Steps) (loss=0.06061): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (5975 / 25000 Steps) (loss=0.08757): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (5978 / 25000 Steps) (loss=0.05737): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (5981 / 25000 Steps) (loss=0.04934): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (5984 / 25000 Steps) (loss=0.06738): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (5987 / 25000 Steps) (loss=0.06767): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (5990 / 25000 Steps) (loss=0.06158): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (5993 / 25000 Steps) (loss=0.05816): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (5996 / 25000 Steps) (loss=0.05081): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (5999 / 25000 Steps) (loss=0.05336): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Validate (6000 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "Training (6002 / 25000 Steps) (loss=0.06214): 100%|██████████| 3/3 [00:02<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (6002 / 25000 Steps) (loss=0.06214): 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
      "Training (6005 / 25000 Steps) (loss=0.05410): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (6008 / 25000 Steps) (loss=0.06990): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (6011 / 25000 Steps) (loss=0.04892): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (6014 / 25000 Steps) (loss=0.06608): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (6017 / 25000 Steps) (loss=0.07563): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (6020 / 25000 Steps) (loss=0.06619): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (6023 / 25000 Steps) (loss=0.06140): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "Training (6026 / 25000 Steps) (loss=0.07184): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (6029 / 25000 Steps) (loss=0.05649): 100%|██████████| 3/3 [00:03<00:00,  1.12s/it]\n",
      "Training (6032 / 25000 Steps) (loss=0.06546): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (6035 / 25000 Steps) (loss=0.04224): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (6038 / 25000 Steps) (loss=0.04751): 100%|██████████| 3/3 [00:01<00:00,  1.98it/s]\n",
      "Training (6041 / 25000 Steps) (loss=0.05502): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (6044 / 25000 Steps) (loss=0.06386): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (6047 / 25000 Steps) (loss=0.05773): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (6050 / 25000 Steps) (loss=0.05193): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (6053 / 25000 Steps) (loss=0.06492): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (6056 / 25000 Steps) (loss=0.08164): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (6059 / 25000 Steps) (loss=0.05136): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (6062 / 25000 Steps) (loss=0.05703): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (6065 / 25000 Steps) (loss=0.05137): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (6068 / 25000 Steps) (loss=0.05996): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (6071 / 25000 Steps) (loss=0.05584): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (6074 / 25000 Steps) (loss=0.05734): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (6077 / 25000 Steps) (loss=0.06973): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (6080 / 25000 Steps) (loss=0.05586): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (6083 / 25000 Steps) (loss=0.06291): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (6086 / 25000 Steps) (loss=0.05314): 100%|██████████| 3/3 [00:03<00:00,  1.18s/it]\n",
      "Training (6089 / 25000 Steps) (loss=0.05429): 100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
      "Training (6092 / 25000 Steps) (loss=0.05334): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "Training (6095 / 25000 Steps) (loss=0.05083): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (6098 / 25000 Steps) (loss=0.04745): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (6101 / 25000 Steps) (loss=0.05977): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (6104 / 25000 Steps) (loss=0.06242): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (6107 / 25000 Steps) (loss=0.07078): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (6110 / 25000 Steps) (loss=0.05578): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (6113 / 25000 Steps) (loss=0.05750): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (6116 / 25000 Steps) (loss=0.05981): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (6119 / 25000 Steps) (loss=0.05804): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (6122 / 25000 Steps) (loss=0.05982): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (6125 / 25000 Steps) (loss=0.06506): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (6128 / 25000 Steps) (loss=0.05336): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (6131 / 25000 Steps) (loss=0.04951): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (6134 / 25000 Steps) (loss=0.04683): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (6137 / 25000 Steps) (loss=0.05784): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (6140 / 25000 Steps) (loss=0.06880): 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]\n",
      "Training (6143 / 25000 Steps) (loss=0.05495): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (6146 / 25000 Steps) (loss=0.07605): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (6149 / 25000 Steps) (loss=0.06774): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (6152 / 25000 Steps) (loss=0.05411): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (6155 / 25000 Steps) (loss=0.06177): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (6158 / 25000 Steps) (loss=0.05464): 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "Training (6161 / 25000 Steps) (loss=0.05114): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (6164 / 25000 Steps) (loss=0.06297): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (6167 / 25000 Steps) (loss=0.04926): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (6170 / 25000 Steps) (loss=0.05065): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (6173 / 25000 Steps) (loss=0.06726): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (6176 / 25000 Steps) (loss=0.05157): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (6179 / 25000 Steps) (loss=0.06076): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (6182 / 25000 Steps) (loss=0.06353): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (6185 / 25000 Steps) (loss=0.07479): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (6188 / 25000 Steps) (loss=0.05720): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (6191 / 25000 Steps) (loss=0.07083): 100%|██████████| 3/3 [00:02<00:00,  1.32it/s]\n",
      "Training (6194 / 25000 Steps) (loss=0.05777): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (6197 / 25000 Steps) (loss=0.05245): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (6200 / 25000 Steps) (loss=0.06580): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (6203 / 25000 Steps) (loss=0.04975): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (6206 / 25000 Steps) (loss=0.05461): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (6209 / 25000 Steps) (loss=0.04889): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (6212 / 25000 Steps) (loss=0.07280): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (6215 / 25000 Steps) (loss=0.04757): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (6218 / 25000 Steps) (loss=0.05555): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (6221 / 25000 Steps) (loss=0.04613): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (6224 / 25000 Steps) (loss=0.05188): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (6227 / 25000 Steps) (loss=0.07229): 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "Training (6230 / 25000 Steps) (loss=0.06375): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (6233 / 25000 Steps) (loss=0.05457): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (6236 / 25000 Steps) (loss=0.07032): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (6239 / 25000 Steps) (loss=0.05284): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (6242 / 25000 Steps) (loss=0.03885): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (6245 / 25000 Steps) (loss=0.06569): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (6248 / 25000 Steps) (loss=0.05948): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (6251 / 25000 Steps) (loss=0.05052): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (6254 / 25000 Steps) (loss=0.08293): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (6257 / 25000 Steps) (loss=0.06197): 100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
      "Training (6260 / 25000 Steps) (loss=0.07015): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (6263 / 25000 Steps) (loss=0.08488): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (6266 / 25000 Steps) (loss=0.05901): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (6269 / 25000 Steps) (loss=0.07466): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (6272 / 25000 Steps) (loss=0.06676): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (6275 / 25000 Steps) (loss=0.05860): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (6278 / 25000 Steps) (loss=0.06089): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (6281 / 25000 Steps) (loss=0.05370): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (6284 / 25000 Steps) (loss=0.05198): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (6287 / 25000 Steps) (loss=0.05444): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (6290 / 25000 Steps) (loss=0.05753): 100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
      "Training (6293 / 25000 Steps) (loss=0.05397): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (6296 / 25000 Steps) (loss=0.05777): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (6299 / 25000 Steps) (loss=0.04690): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (6302 / 25000 Steps) (loss=0.05614): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (6305 / 25000 Steps) (loss=0.06310): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (6308 / 25000 Steps) (loss=0.05728): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (6311 / 25000 Steps) (loss=0.05920): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (6314 / 25000 Steps) (loss=0.07083): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (6317 / 25000 Steps) (loss=0.05860): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (6320 / 25000 Steps) (loss=0.04831): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (6323 / 25000 Steps) (loss=0.06167): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (6326 / 25000 Steps) (loss=0.06365): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (6329 / 25000 Steps) (loss=0.04572): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (6332 / 25000 Steps) (loss=0.05946): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (6335 / 25000 Steps) (loss=0.07148): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (6338 / 25000 Steps) (loss=0.06961): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (6341 / 25000 Steps) (loss=0.05020): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (6344 / 25000 Steps) (loss=0.07315): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (6347 / 25000 Steps) (loss=0.04491): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (6350 / 25000 Steps) (loss=0.05442): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (6353 / 25000 Steps) (loss=0.05491): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (6356 / 25000 Steps) (loss=0.06328): 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "Training (6359 / 25000 Steps) (loss=0.05093): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (6362 / 25000 Steps) (loss=0.05105): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (6365 / 25000 Steps) (loss=0.06525): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (6368 / 25000 Steps) (loss=0.05691): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (6371 / 25000 Steps) (loss=0.06424): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (6374 / 25000 Steps) (loss=0.04327): 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]\n",
      "Training (6377 / 25000 Steps) (loss=0.06540): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (6380 / 25000 Steps) (loss=0.05239): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (6383 / 25000 Steps) (loss=0.05257): 100%|██████████| 3/3 [00:01<00:00,  1.98it/s]\n",
      "Training (6386 / 25000 Steps) (loss=0.06037): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (6389 / 25000 Steps) (loss=0.05123): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (6392 / 25000 Steps) (loss=0.05538): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (6395 / 25000 Steps) (loss=0.04636): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (6398 / 25000 Steps) (loss=0.05272): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (6401 / 25000 Steps) (loss=0.05451): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (6404 / 25000 Steps) (loss=0.06888): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (6407 / 25000 Steps) (loss=0.06733): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (6410 / 25000 Steps) (loss=0.04970): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (6413 / 25000 Steps) (loss=0.04831): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (6416 / 25000 Steps) (loss=0.05134): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (6419 / 25000 Steps) (loss=0.05362): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (6422 / 25000 Steps) (loss=0.06296): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (6425 / 25000 Steps) (loss=0.05969): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (6428 / 25000 Steps) (loss=0.05934): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (6431 / 25000 Steps) (loss=0.05408): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (6434 / 25000 Steps) (loss=0.05315): 100%|██████████| 3/3 [00:02<00:00,  1.14it/s]\n",
      "Training (6437 / 25000 Steps) (loss=0.05794): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (6440 / 25000 Steps) (loss=0.06951): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (6443 / 25000 Steps) (loss=0.05860): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (6446 / 25000 Steps) (loss=0.05344): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (6449 / 25000 Steps) (loss=0.05028): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (6452 / 25000 Steps) (loss=0.05293): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (6455 / 25000 Steps) (loss=0.05295): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (6458 / 25000 Steps) (loss=0.05792): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (6461 / 25000 Steps) (loss=0.06286): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (6464 / 25000 Steps) (loss=0.06770): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (6467 / 25000 Steps) (loss=0.04292): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (6470 / 25000 Steps) (loss=0.05131): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (6473 / 25000 Steps) (loss=0.05623): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (6476 / 25000 Steps) (loss=0.05396): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (6479 / 25000 Steps) (loss=0.05112): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (6482 / 25000 Steps) (loss=0.04845): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (6485 / 25000 Steps) (loss=0.06649): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (6488 / 25000 Steps) (loss=0.05993): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (6491 / 25000 Steps) (loss=0.04602): 100%|██████████| 3/3 [00:02<00:00,  1.20it/s]\n",
      "Training (6494 / 25000 Steps) (loss=0.07298): 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
      "Training (6497 / 25000 Steps) (loss=0.07854): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Validate (6498 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]it]\n",
      "Training (6500 / 25000 Steps) (loss=0.06503): 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (6503 / 25000 Steps) (loss=0.05917): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (6506 / 25000 Steps) (loss=0.05835): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (6509 / 25000 Steps) (loss=0.06081): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (6512 / 25000 Steps) (loss=0.05150): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (6515 / 25000 Steps) (loss=0.05391): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (6518 / 25000 Steps) (loss=0.06965): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (6521 / 25000 Steps) (loss=0.05049): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (6524 / 25000 Steps) (loss=0.05679): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (6527 / 25000 Steps) (loss=0.06691): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (6530 / 25000 Steps) (loss=0.07449): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (6533 / 25000 Steps) (loss=0.04623): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (6536 / 25000 Steps) (loss=0.05360): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (6539 / 25000 Steps) (loss=0.06722): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (6542 / 25000 Steps) (loss=0.04175): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (6545 / 25000 Steps) (loss=0.07776): 100%|██████████| 3/3 [00:02<00:00,  1.11it/s]\n",
      "Training (6548 / 25000 Steps) (loss=0.04376): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (6551 / 25000 Steps) (loss=0.04854): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (6554 / 25000 Steps) (loss=0.05096): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (6557 / 25000 Steps) (loss=0.05085): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (6560 / 25000 Steps) (loss=0.06099): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (6563 / 25000 Steps) (loss=0.06186): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (6566 / 25000 Steps) (loss=0.06242): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (6569 / 25000 Steps) (loss=0.05243): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (6572 / 25000 Steps) (loss=0.06043): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (6575 / 25000 Steps) (loss=0.05533): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (6578 / 25000 Steps) (loss=0.04930): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (6581 / 25000 Steps) (loss=0.05066): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (6584 / 25000 Steps) (loss=0.04050): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (6587 / 25000 Steps) (loss=0.05855): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (6590 / 25000 Steps) (loss=0.04604): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (6593 / 25000 Steps) (loss=0.05142): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (6596 / 25000 Steps) (loss=0.05417): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (6599 / 25000 Steps) (loss=0.05911): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (6602 / 25000 Steps) (loss=0.06123): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (6605 / 25000 Steps) (loss=0.04520): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (6608 / 25000 Steps) (loss=0.05502): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (6611 / 25000 Steps) (loss=0.07750): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (6614 / 25000 Steps) (loss=0.05874): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (6617 / 25000 Steps) (loss=0.04912): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (6620 / 25000 Steps) (loss=0.05368): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (6623 / 25000 Steps) (loss=0.06358): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (6626 / 25000 Steps) (loss=0.06034): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (6629 / 25000 Steps) (loss=0.05657): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (6632 / 25000 Steps) (loss=0.06627): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (6635 / 25000 Steps) (loss=0.06665): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (6638 / 25000 Steps) (loss=0.05264): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (6641 / 25000 Steps) (loss=0.07140): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (6644 / 25000 Steps) (loss=0.04380): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (6647 / 25000 Steps) (loss=0.04381): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (6650 / 25000 Steps) (loss=0.04604): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (6653 / 25000 Steps) (loss=0.06630): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (6656 / 25000 Steps) (loss=0.05009): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (6659 / 25000 Steps) (loss=0.05859): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "Training (6662 / 25000 Steps) (loss=0.04523): 100%|██████████| 3/3 [00:02<00:00,  1.15it/s]\n",
      "Training (6665 / 25000 Steps) (loss=0.05693): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (6668 / 25000 Steps) (loss=0.06340): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (6671 / 25000 Steps) (loss=0.05091): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (6674 / 25000 Steps) (loss=0.05545): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (6677 / 25000 Steps) (loss=0.04775): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (6680 / 25000 Steps) (loss=0.06655): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (6683 / 25000 Steps) (loss=0.06164): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (6686 / 25000 Steps) (loss=0.06837): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (6689 / 25000 Steps) (loss=0.05835): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (6692 / 25000 Steps) (loss=0.05010): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (6695 / 25000 Steps) (loss=0.05092): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (6698 / 25000 Steps) (loss=0.05460): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (6701 / 25000 Steps) (loss=0.05637): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (6704 / 25000 Steps) (loss=0.06909): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (6707 / 25000 Steps) (loss=0.06222): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (6710 / 25000 Steps) (loss=0.07234): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (6713 / 25000 Steps) (loss=0.04844): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (6716 / 25000 Steps) (loss=0.04436): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (6719 / 25000 Steps) (loss=0.05169): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (6722 / 25000 Steps) (loss=0.07784): 100%|██████████| 3/3 [00:03<00:00,  1.18s/it]\n",
      "Training (6725 / 25000 Steps) (loss=0.04339): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (6728 / 25000 Steps) (loss=0.04688): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (6731 / 25000 Steps) (loss=0.06015): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (6734 / 25000 Steps) (loss=0.06407): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (6737 / 25000 Steps) (loss=0.04710): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (6740 / 25000 Steps) (loss=0.06802): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (6743 / 25000 Steps) (loss=0.05500): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (6746 / 25000 Steps) (loss=0.05758): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (6749 / 25000 Steps) (loss=0.05778): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (6752 / 25000 Steps) (loss=0.05856): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (6755 / 25000 Steps) (loss=0.05886): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (6758 / 25000 Steps) (loss=0.04838): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (6761 / 25000 Steps) (loss=0.05244): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (6764 / 25000 Steps) (loss=0.05637): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (6767 / 25000 Steps) (loss=0.04907): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (6770 / 25000 Steps) (loss=0.04592): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (6773 / 25000 Steps) (loss=0.04334): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (6776 / 25000 Steps) (loss=0.05206): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (6779 / 25000 Steps) (loss=0.06854): 100%|██████████| 3/3 [00:03<00:00,  1.22s/it]\n",
      "Training (6782 / 25000 Steps) (loss=0.04921): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (6785 / 25000 Steps) (loss=0.05062): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (6788 / 25000 Steps) (loss=0.05625): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (6791 / 25000 Steps) (loss=0.05310): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (6794 / 25000 Steps) (loss=0.04048): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (6797 / 25000 Steps) (loss=0.06851): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (6800 / 25000 Steps) (loss=0.04868): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (6803 / 25000 Steps) (loss=0.05258): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (6806 / 25000 Steps) (loss=0.06533): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (6809 / 25000 Steps) (loss=0.05787): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (6812 / 25000 Steps) (loss=0.05402): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (6815 / 25000 Steps) (loss=0.05040): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (6818 / 25000 Steps) (loss=0.05356): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (6821 / 25000 Steps) (loss=0.05666): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (6824 / 25000 Steps) (loss=0.06162): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (6827 / 25000 Steps) (loss=0.04102): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (6830 / 25000 Steps) (loss=0.06593): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (6833 / 25000 Steps) (loss=0.05754): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (6836 / 25000 Steps) (loss=0.05371): 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
      "Training (6839 / 25000 Steps) (loss=0.04678): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "Training (6842 / 25000 Steps) (loss=0.05270): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (6845 / 25000 Steps) (loss=0.05336): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (6848 / 25000 Steps) (loss=0.03912): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (6851 / 25000 Steps) (loss=0.06558): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (6854 / 25000 Steps) (loss=0.04783): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (6857 / 25000 Steps) (loss=0.05980): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (6860 / 25000 Steps) (loss=0.05502): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (6863 / 25000 Steps) (loss=0.06358): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (6866 / 25000 Steps) (loss=0.05074): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (6869 / 25000 Steps) (loss=0.04010): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (6872 / 25000 Steps) (loss=0.05552): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (6875 / 25000 Steps) (loss=0.04017): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (6878 / 25000 Steps) (loss=0.04784): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (6881 / 25000 Steps) (loss=0.04384): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (6884 / 25000 Steps) (loss=0.05934): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (6887 / 25000 Steps) (loss=0.04296): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (6890 / 25000 Steps) (loss=0.05013): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (6893 / 25000 Steps) (loss=0.05633): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (6896 / 25000 Steps) (loss=0.04398): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (6899 / 25000 Steps) (loss=0.05653): 100%|██████████| 3/3 [00:02<00:00,  1.02it/s]\n",
      "Training (6902 / 25000 Steps) (loss=0.05275): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (6905 / 25000 Steps) (loss=0.04866): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (6908 / 25000 Steps) (loss=0.06535): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (6911 / 25000 Steps) (loss=0.06215): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (6914 / 25000 Steps) (loss=0.04857): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (6917 / 25000 Steps) (loss=0.05125): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (6920 / 25000 Steps) (loss=0.05868): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (6923 / 25000 Steps) (loss=0.06289): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (6926 / 25000 Steps) (loss=0.03710): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (6929 / 25000 Steps) (loss=0.06658): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (6932 / 25000 Steps) (loss=0.04179): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (6935 / 25000 Steps) (loss=0.05639): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (6938 / 25000 Steps) (loss=0.06640): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (6941 / 25000 Steps) (loss=0.06132): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (6944 / 25000 Steps) (loss=0.05550): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (6947 / 25000 Steps) (loss=0.07218): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (6950 / 25000 Steps) (loss=0.06848): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (6953 / 25000 Steps) (loss=0.05554): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (6956 / 25000 Steps) (loss=0.05969): 100%|██████████| 3/3 [00:02<00:00,  1.15it/s]\n",
      "Training (6959 / 25000 Steps) (loss=0.06669): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (6962 / 25000 Steps) (loss=0.04613): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (6965 / 25000 Steps) (loss=0.07514): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (6968 / 25000 Steps) (loss=0.04897): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (6971 / 25000 Steps) (loss=0.06773): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (6974 / 25000 Steps) (loss=0.04691): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (6977 / 25000 Steps) (loss=0.04550): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (6980 / 25000 Steps) (loss=0.05728): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (6983 / 25000 Steps) (loss=0.05683): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (6986 / 25000 Steps) (loss=0.05506): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (6989 / 25000 Steps) (loss=0.04888): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (6992 / 25000 Steps) (loss=0.04950): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (6995 / 25000 Steps) (loss=0.04745): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (6998 / 25000 Steps) (loss=0.06396): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Validate (6999 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.81it/s]it]\n",
      "Training (7001 / 25000 Steps) (loss=0.03932):  67%|██████▋   | 2/3 [00:02<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (7001 / 25000 Steps) (loss=0.03932): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (7004 / 25000 Steps) (loss=0.05651): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (7007 / 25000 Steps) (loss=0.04462): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (7010 / 25000 Steps) (loss=0.03943): 100%|██████████| 3/3 [00:03<00:00,  1.04s/it]\n",
      "Training (7013 / 25000 Steps) (loss=0.06257): 100%|██████████| 3/3 [00:02<00:00,  1.19it/s]\n",
      "Training (7016 / 25000 Steps) (loss=0.06411): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (7019 / 25000 Steps) (loss=0.04894): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (7022 / 25000 Steps) (loss=0.05216): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (7025 / 25000 Steps) (loss=0.05539): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (7028 / 25000 Steps) (loss=0.05148): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (7031 / 25000 Steps) (loss=0.05401): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (7034 / 25000 Steps) (loss=0.05040): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (7037 / 25000 Steps) (loss=0.04363): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (7040 / 25000 Steps) (loss=0.04234): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (7043 / 25000 Steps) (loss=0.05995): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (7046 / 25000 Steps) (loss=0.04335): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (7049 / 25000 Steps) (loss=0.04981): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (7052 / 25000 Steps) (loss=0.04774): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (7055 / 25000 Steps) (loss=0.04148): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (7058 / 25000 Steps) (loss=0.04674): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (7061 / 25000 Steps) (loss=0.05107): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (7064 / 25000 Steps) (loss=0.05537): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (7067 / 25000 Steps) (loss=0.06555): 100%|██████████| 3/3 [00:02<00:00,  1.12it/s]\n",
      "Training (7070 / 25000 Steps) (loss=0.05885): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (7073 / 25000 Steps) (loss=0.06703): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (7076 / 25000 Steps) (loss=0.04111): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (7079 / 25000 Steps) (loss=0.06111): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (7082 / 25000 Steps) (loss=0.04217): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (7085 / 25000 Steps) (loss=0.05378): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (7088 / 25000 Steps) (loss=0.04458): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (7091 / 25000 Steps) (loss=0.06946): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (7094 / 25000 Steps) (loss=0.04650): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (7097 / 25000 Steps) (loss=0.05850): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (7100 / 25000 Steps) (loss=0.04579): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (7103 / 25000 Steps) (loss=0.05004): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (7106 / 25000 Steps) (loss=0.05326): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (7109 / 25000 Steps) (loss=0.04973): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (7112 / 25000 Steps) (loss=0.06059): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (7115 / 25000 Steps) (loss=0.05412): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (7118 / 25000 Steps) (loss=0.06136): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (7121 / 25000 Steps) (loss=0.05103): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (7124 / 25000 Steps) (loss=0.04415): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (7127 / 25000 Steps) (loss=0.04804): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (7130 / 25000 Steps) (loss=0.05731): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (7133 / 25000 Steps) (loss=0.05638): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (7136 / 25000 Steps) (loss=0.04805): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (7139 / 25000 Steps) (loss=0.05045): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (7142 / 25000 Steps) (loss=0.04448): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (7145 / 25000 Steps) (loss=0.05456): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (7148 / 25000 Steps) (loss=0.04922): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (7151 / 25000 Steps) (loss=0.05967): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (7154 / 25000 Steps) (loss=0.04371): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (7157 / 25000 Steps) (loss=0.04836): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (7160 / 25000 Steps) (loss=0.04276): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (7163 / 25000 Steps) (loss=0.05031): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (7166 / 25000 Steps) (loss=0.05089): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (7169 / 25000 Steps) (loss=0.05919): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (7172 / 25000 Steps) (loss=0.03817): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (7175 / 25000 Steps) (loss=0.04581): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (7178 / 25000 Steps) (loss=0.05887): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (7181 / 25000 Steps) (loss=0.04567): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (7184 / 25000 Steps) (loss=0.05457): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (7187 / 25000 Steps) (loss=0.05461): 100%|██████████| 3/3 [00:02<00:00,  1.35it/s]\n",
      "Training (7190 / 25000 Steps) (loss=0.05185): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (7193 / 25000 Steps) (loss=0.08490): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (7196 / 25000 Steps) (loss=0.04835): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (7199 / 25000 Steps) (loss=0.06074): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (7202 / 25000 Steps) (loss=0.05909): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (7205 / 25000 Steps) (loss=0.05291): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (7208 / 25000 Steps) (loss=0.04622): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (7211 / 25000 Steps) (loss=0.05858): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (7214 / 25000 Steps) (loss=0.05608): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (7217 / 25000 Steps) (loss=0.05369): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (7220 / 25000 Steps) (loss=0.04455): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (7223 / 25000 Steps) (loss=0.05008): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (7226 / 25000 Steps) (loss=0.05831): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (7229 / 25000 Steps) (loss=0.05674): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (7232 / 25000 Steps) (loss=0.04686): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (7235 / 25000 Steps) (loss=0.04866): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (7238 / 25000 Steps) (loss=0.04194): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (7241 / 25000 Steps) (loss=0.05178): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (7244 / 25000 Steps) (loss=0.05092): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (7247 / 25000 Steps) (loss=0.04910): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (7250 / 25000 Steps) (loss=0.04948): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (7253 / 25000 Steps) (loss=0.05112): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (7256 / 25000 Steps) (loss=0.06518): 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "Training (7259 / 25000 Steps) (loss=0.06783): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (7262 / 25000 Steps) (loss=0.05388): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (7265 / 25000 Steps) (loss=0.04686): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (7268 / 25000 Steps) (loss=0.05163): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (7271 / 25000 Steps) (loss=0.05785): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (7274 / 25000 Steps) (loss=0.04519): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (7277 / 25000 Steps) (loss=0.04520): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (7280 / 25000 Steps) (loss=0.06205): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (7283 / 25000 Steps) (loss=0.04721): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (7286 / 25000 Steps) (loss=0.05138): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (7289 / 25000 Steps) (loss=0.04571): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (7292 / 25000 Steps) (loss=0.04952): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (7295 / 25000 Steps) (loss=0.06263): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (7298 / 25000 Steps) (loss=0.04506): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (7301 / 25000 Steps) (loss=0.06089): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (7304 / 25000 Steps) (loss=0.05758): 100%|██████████| 3/3 [00:03<00:00,  1.03s/it]\n",
      "Training (7307 / 25000 Steps) (loss=0.04281): 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "Training (7310 / 25000 Steps) (loss=0.05295): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (7313 / 25000 Steps) (loss=0.04038): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (7316 / 25000 Steps) (loss=0.05087): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (7319 / 25000 Steps) (loss=0.05402): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (7322 / 25000 Steps) (loss=0.04452): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (7325 / 25000 Steps) (loss=0.06388): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (7328 / 25000 Steps) (loss=0.05086): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (7331 / 25000 Steps) (loss=0.04069): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (7334 / 25000 Steps) (loss=0.04785): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (7337 / 25000 Steps) (loss=0.04882): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (7340 / 25000 Steps) (loss=0.05143): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (7343 / 25000 Steps) (loss=0.04407): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (7346 / 25000 Steps) (loss=0.05093): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (7349 / 25000 Steps) (loss=0.06263): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (7352 / 25000 Steps) (loss=0.04789): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (7355 / 25000 Steps) (loss=0.04201): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (7358 / 25000 Steps) (loss=0.03262): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (7361 / 25000 Steps) (loss=0.05372): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (7364 / 25000 Steps) (loss=0.04594): 100%|██████████| 3/3 [00:02<00:00,  1.08it/s]\n",
      "Training (7367 / 25000 Steps) (loss=0.05210): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (7370 / 25000 Steps) (loss=0.05066): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (7373 / 25000 Steps) (loss=0.04274): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (7376 / 25000 Steps) (loss=0.05096): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (7379 / 25000 Steps) (loss=0.03918): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (7382 / 25000 Steps) (loss=0.03854): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (7385 / 25000 Steps) (loss=0.05686): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (7388 / 25000 Steps) (loss=0.05332): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (7391 / 25000 Steps) (loss=0.04476): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (7394 / 25000 Steps) (loss=0.06411): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (7397 / 25000 Steps) (loss=0.04832): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (7400 / 25000 Steps) (loss=0.06421): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (7403 / 25000 Steps) (loss=0.04825): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (7406 / 25000 Steps) (loss=0.04635): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (7409 / 25000 Steps) (loss=0.05863): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (7412 / 25000 Steps) (loss=0.04247): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (7415 / 25000 Steps) (loss=0.03904): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (7418 / 25000 Steps) (loss=0.04270): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (7421 / 25000 Steps) (loss=0.05376): 100%|██████████| 3/3 [00:02<00:00,  1.25it/s]\n",
      "Training (7424 / 25000 Steps) (loss=0.04138): 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]\n",
      "Training (7427 / 25000 Steps) (loss=0.04297): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (7430 / 25000 Steps) (loss=0.05550): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (7433 / 25000 Steps) (loss=0.05495): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (7436 / 25000 Steps) (loss=0.05607): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (7439 / 25000 Steps) (loss=0.04058): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (7442 / 25000 Steps) (loss=0.04746): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (7445 / 25000 Steps) (loss=0.04890): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (7448 / 25000 Steps) (loss=0.06571): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (7451 / 25000 Steps) (loss=0.05653): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (7454 / 25000 Steps) (loss=0.04233): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (7457 / 25000 Steps) (loss=0.04670): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (7460 / 25000 Steps) (loss=0.05843): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (7463 / 25000 Steps) (loss=0.04288): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (7466 / 25000 Steps) (loss=0.04916): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (7469 / 25000 Steps) (loss=0.05501): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (7472 / 25000 Steps) (loss=0.03926): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (7475 / 25000 Steps) (loss=0.05616): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (7478 / 25000 Steps) (loss=0.04644): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (7481 / 25000 Steps) (loss=0.04719): 100%|██████████| 3/3 [00:02<00:00,  1.08it/s]\n",
      "Training (7484 / 25000 Steps) (loss=0.04663): 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]\n",
      "Training (7487 / 25000 Steps) (loss=0.05421): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (7490 / 25000 Steps) (loss=0.04551): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (7493 / 25000 Steps) (loss=0.05251): 100%|██████████| 3/3 [00:02<00:00,  1.22it/s]\n",
      "Training (7496 / 25000 Steps) (loss=0.04249): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (7499 / 25000 Steps) (loss=0.05353): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Validate (7500 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "Training (7502 / 25000 Steps) (loss=0.06458): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (7502 / 25000 Steps) (loss=0.06458): 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "Training (7505 / 25000 Steps) (loss=0.04947): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (7508 / 25000 Steps) (loss=0.05539): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (7511 / 25000 Steps) (loss=0.04547): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (7514 / 25000 Steps) (loss=0.03977): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (7517 / 25000 Steps) (loss=0.04524): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (7520 / 25000 Steps) (loss=0.05140): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (7523 / 25000 Steps) (loss=0.05070): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (7526 / 25000 Steps) (loss=0.05958): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (7529 / 25000 Steps) (loss=0.04274): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (7532 / 25000 Steps) (loss=0.06543): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (7535 / 25000 Steps) (loss=0.05082): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (7538 / 25000 Steps) (loss=0.05120): 100%|██████████| 3/3 [00:02<00:00,  1.16it/s]\n",
      "Training (7541 / 25000 Steps) (loss=0.04372): 100%|██████████| 3/3 [00:02<00:00,  1.09it/s]\n",
      "Training (7544 / 25000 Steps) (loss=0.05350): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (7547 / 25000 Steps) (loss=0.04438): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (7550 / 25000 Steps) (loss=0.03283): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (7553 / 25000 Steps) (loss=0.04696): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (7556 / 25000 Steps) (loss=0.05286): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (7559 / 25000 Steps) (loss=0.04889): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (7562 / 25000 Steps) (loss=0.04359): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (7565 / 25000 Steps) (loss=0.05843): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (7568 / 25000 Steps) (loss=0.05207): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (7571 / 25000 Steps) (loss=0.04478): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (7574 / 25000 Steps) (loss=0.06173): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (7577 / 25000 Steps) (loss=0.04797): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (7580 / 25000 Steps) (loss=0.04400): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (7583 / 25000 Steps) (loss=0.04516): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (7586 / 25000 Steps) (loss=0.04588): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (7589 / 25000 Steps) (loss=0.05655): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (7592 / 25000 Steps) (loss=0.03976): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (7595 / 25000 Steps) (loss=0.05439): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (7598 / 25000 Steps) (loss=0.04109): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (7601 / 25000 Steps) (loss=0.04742): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (7604 / 25000 Steps) (loss=0.04456): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (7607 / 25000 Steps) (loss=0.04469): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (7610 / 25000 Steps) (loss=0.04336): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (7613 / 25000 Steps) (loss=0.05142): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (7616 / 25000 Steps) (loss=0.05149): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (7619 / 25000 Steps) (loss=0.05283): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (7622 / 25000 Steps) (loss=0.05006): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (7625 / 25000 Steps) (loss=0.05556): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (7628 / 25000 Steps) (loss=0.05371): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (7631 / 25000 Steps) (loss=0.04475): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (7634 / 25000 Steps) (loss=0.05596): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (7637 / 25000 Steps) (loss=0.04288): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (7640 / 25000 Steps) (loss=0.04960): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (7643 / 25000 Steps) (loss=0.05156): 100%|██████████| 3/3 [00:02<00:00,  1.17it/s]\n",
      "Training (7646 / 25000 Steps) (loss=0.04664): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (7649 / 25000 Steps) (loss=0.07257): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (7652 / 25000 Steps) (loss=0.04318): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (7655 / 25000 Steps) (loss=0.05509): 100%|██████████| 3/3 [00:02<00:00,  1.08it/s]\n",
      "Training (7658 / 25000 Steps) (loss=0.06171): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (7661 / 25000 Steps) (loss=0.05241): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (7664 / 25000 Steps) (loss=0.03973): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (7667 / 25000 Steps) (loss=0.05245): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (7670 / 25000 Steps) (loss=0.04212): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (7673 / 25000 Steps) (loss=0.05977): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (7676 / 25000 Steps) (loss=0.05136): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (7679 / 25000 Steps) (loss=0.05462): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (7682 / 25000 Steps) (loss=0.05311): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (7685 / 25000 Steps) (loss=0.07396): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (7688 / 25000 Steps) (loss=0.04618): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (7691 / 25000 Steps) (loss=0.04877): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (7694 / 25000 Steps) (loss=0.05988): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (7697 / 25000 Steps) (loss=0.07520): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (7700 / 25000 Steps) (loss=0.04285): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (7703 / 25000 Steps) (loss=0.05632): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (7706 / 25000 Steps) (loss=0.05217): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (7709 / 25000 Steps) (loss=0.05500): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (7712 / 25000 Steps) (loss=0.07241): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (7715 / 25000 Steps) (loss=0.03463): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (7718 / 25000 Steps) (loss=0.05637): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (7721 / 25000 Steps) (loss=0.04873): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (7724 / 25000 Steps) (loss=0.04047): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (7727 / 25000 Steps) (loss=0.04187): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (7730 / 25000 Steps) (loss=0.05647): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (7733 / 25000 Steps) (loss=0.04406): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (7736 / 25000 Steps) (loss=0.04433): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (7739 / 25000 Steps) (loss=0.05109): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (7742 / 25000 Steps) (loss=0.05642): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (7745 / 25000 Steps) (loss=0.06482): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (7748 / 25000 Steps) (loss=0.05250): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (7751 / 25000 Steps) (loss=0.06351): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (7754 / 25000 Steps) (loss=0.04353): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (7757 / 25000 Steps) (loss=0.04740): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (7760 / 25000 Steps) (loss=0.05021): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (7763 / 25000 Steps) (loss=0.06037): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (7766 / 25000 Steps) (loss=0.05663): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (7769 / 25000 Steps) (loss=0.03490): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (7772 / 25000 Steps) (loss=0.04494): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (7775 / 25000 Steps) (loss=0.04640): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (7778 / 25000 Steps) (loss=0.04527): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (7781 / 25000 Steps) (loss=0.04940): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (7784 / 25000 Steps) (loss=0.05270): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (7787 / 25000 Steps) (loss=0.04982): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (7790 / 25000 Steps) (loss=0.04764): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (7793 / 25000 Steps) (loss=0.04989): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (7796 / 25000 Steps) (loss=0.04243): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (7799 / 25000 Steps) (loss=0.04800): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (7802 / 25000 Steps) (loss=0.06681): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (7805 / 25000 Steps) (loss=0.05387): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (7808 / 25000 Steps) (loss=0.04914): 100%|██████████| 3/3 [00:01<00:00,  1.99it/s]\n",
      "Training (7811 / 25000 Steps) (loss=0.04291): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (7814 / 25000 Steps) (loss=0.04497): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (7817 / 25000 Steps) (loss=0.04037): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (7820 / 25000 Steps) (loss=0.03893): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (7823 / 25000 Steps) (loss=0.04984): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (7826 / 25000 Steps) (loss=0.04495): 100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
      "Training (7829 / 25000 Steps) (loss=0.04626): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (7832 / 25000 Steps) (loss=0.04671): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (7835 / 25000 Steps) (loss=0.05352): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (7838 / 25000 Steps) (loss=0.04439): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (7841 / 25000 Steps) (loss=0.04943): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (7844 / 25000 Steps) (loss=0.06013): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (7847 / 25000 Steps) (loss=0.06623): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (7850 / 25000 Steps) (loss=0.05124): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (7853 / 25000 Steps) (loss=0.04024): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (7856 / 25000 Steps) (loss=0.04272): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (7859 / 25000 Steps) (loss=0.03562): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (7862 / 25000 Steps) (loss=0.04467): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (7865 / 25000 Steps) (loss=0.05172): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (7868 / 25000 Steps) (loss=0.05845): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (7871 / 25000 Steps) (loss=0.04960): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (7874 / 25000 Steps) (loss=0.04888): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (7877 / 25000 Steps) (loss=0.04529): 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
      "Training (7880 / 25000 Steps) (loss=0.04878): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (7883 / 25000 Steps) (loss=0.04483): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (7886 / 25000 Steps) (loss=0.05197): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (7889 / 25000 Steps) (loss=0.05824): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (7892 / 25000 Steps) (loss=0.06073): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (7895 / 25000 Steps) (loss=0.03910): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (7898 / 25000 Steps) (loss=0.04836): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (7901 / 25000 Steps) (loss=0.04551): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (7904 / 25000 Steps) (loss=0.04294): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (7907 / 25000 Steps) (loss=0.03988): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (7910 / 25000 Steps) (loss=0.05786): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (7913 / 25000 Steps) (loss=0.06419): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (7916 / 25000 Steps) (loss=0.03893): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (7919 / 25000 Steps) (loss=0.04449): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (7922 / 25000 Steps) (loss=0.03527): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (7925 / 25000 Steps) (loss=0.03359): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (7928 / 25000 Steps) (loss=0.04558): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (7931 / 25000 Steps) (loss=0.04390): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (7934 / 25000 Steps) (loss=0.03545): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (7937 / 25000 Steps) (loss=0.06338): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (7940 / 25000 Steps) (loss=0.04005): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (7943 / 25000 Steps) (loss=0.03696): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (7946 / 25000 Steps) (loss=0.04715): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (7949 / 25000 Steps) (loss=0.05876): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (7952 / 25000 Steps) (loss=0.02874): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (7955 / 25000 Steps) (loss=0.05459): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (7958 / 25000 Steps) (loss=0.04058): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (7961 / 25000 Steps) (loss=0.05256): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (7964 / 25000 Steps) (loss=0.06057): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (7967 / 25000 Steps) (loss=0.04523): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (7970 / 25000 Steps) (loss=0.04106): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (7973 / 25000 Steps) (loss=0.03753): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (7976 / 25000 Steps) (loss=0.05187): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (7979 / 25000 Steps) (loss=0.07115): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (7982 / 25000 Steps) (loss=0.03862): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (7985 / 25000 Steps) (loss=0.05024): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (7988 / 25000 Steps) (loss=0.03428): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (7991 / 25000 Steps) (loss=0.04967): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (7994 / 25000 Steps) (loss=0.07049): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (7997 / 25000 Steps) (loss=0.04516): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Validate (7998 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]/s]\n",
      "Training (8000 / 25000 Steps) (loss=0.05767): 100%|██████████| 3/3 [00:02<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (8000 / 25000 Steps) (loss=0.05767): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (8003 / 25000 Steps) (loss=0.04962): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (8006 / 25000 Steps) (loss=0.04204): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (8009 / 25000 Steps) (loss=0.04349): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (8012 / 25000 Steps) (loss=0.05702): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (8015 / 25000 Steps) (loss=0.05493): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (8018 / 25000 Steps) (loss=0.05051): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (8021 / 25000 Steps) (loss=0.05429): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (8024 / 25000 Steps) (loss=0.04821): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (8027 / 25000 Steps) (loss=0.03974): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (8030 / 25000 Steps) (loss=0.06236): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (8033 / 25000 Steps) (loss=0.04392): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (8036 / 25000 Steps) (loss=0.03403): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (8039 / 25000 Steps) (loss=0.05026): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (8042 / 25000 Steps) (loss=0.04546): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (8045 / 25000 Steps) (loss=0.05462): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (8048 / 25000 Steps) (loss=0.04789): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (8051 / 25000 Steps) (loss=0.05498): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (8054 / 25000 Steps) (loss=0.04518): 100%|██████████| 3/3 [00:01<00:00,  2.01it/s]\n",
      "Training (8057 / 25000 Steps) (loss=0.04096): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (8060 / 25000 Steps) (loss=0.05951): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (8063 / 25000 Steps) (loss=0.05822): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (8066 / 25000 Steps) (loss=0.04322): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (8069 / 25000 Steps) (loss=0.05455): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (8072 / 25000 Steps) (loss=0.05335): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (8075 / 25000 Steps) (loss=0.04048): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (8078 / 25000 Steps) (loss=0.05427): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (8081 / 25000 Steps) (loss=0.06078): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (8084 / 25000 Steps) (loss=0.04749): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (8087 / 25000 Steps) (loss=0.04336): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (8090 / 25000 Steps) (loss=0.04301): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (8093 / 25000 Steps) (loss=0.03706): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (8096 / 25000 Steps) (loss=0.05626): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (8099 / 25000 Steps) (loss=0.03721): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (8102 / 25000 Steps) (loss=0.03427): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (8105 / 25000 Steps) (loss=0.04244): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (8108 / 25000 Steps) (loss=0.05183): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (8111 / 25000 Steps) (loss=0.03766): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (8114 / 25000 Steps) (loss=0.03732): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (8117 / 25000 Steps) (loss=0.06576): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (8120 / 25000 Steps) (loss=0.03808): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (8123 / 25000 Steps) (loss=0.05795): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (8126 / 25000 Steps) (loss=0.04033): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (8129 / 25000 Steps) (loss=0.04770): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (8132 / 25000 Steps) (loss=0.04454): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (8135 / 25000 Steps) (loss=0.05856): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (8138 / 25000 Steps) (loss=0.04407): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (8141 / 25000 Steps) (loss=0.06095): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (8144 / 25000 Steps) (loss=0.04550): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (8147 / 25000 Steps) (loss=0.05164): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (8150 / 25000 Steps) (loss=0.04364): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (8153 / 25000 Steps) (loss=0.04966): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (8156 / 25000 Steps) (loss=0.04697): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (8159 / 25000 Steps) (loss=0.03977): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (8162 / 25000 Steps) (loss=0.03086): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (8165 / 25000 Steps) (loss=0.04323): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (8168 / 25000 Steps) (loss=0.03854): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (8171 / 25000 Steps) (loss=0.03907): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (8174 / 25000 Steps) (loss=0.05564): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (8177 / 25000 Steps) (loss=0.05004): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (8180 / 25000 Steps) (loss=0.04152): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (8183 / 25000 Steps) (loss=0.04263): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (8186 / 25000 Steps) (loss=0.05771): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (8189 / 25000 Steps) (loss=0.04784): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (8192 / 25000 Steps) (loss=0.03665): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (8195 / 25000 Steps) (loss=0.05610): 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "Training (8198 / 25000 Steps) (loss=0.04464): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (8201 / 25000 Steps) (loss=0.04462): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (8204 / 25000 Steps) (loss=0.02895): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (8207 / 25000 Steps) (loss=0.05974): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (8210 / 25000 Steps) (loss=0.04659): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (8213 / 25000 Steps) (loss=0.05354): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (8216 / 25000 Steps) (loss=0.03849): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (8219 / 25000 Steps) (loss=0.04712): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (8222 / 25000 Steps) (loss=0.05681): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (8225 / 25000 Steps) (loss=0.04107): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (8228 / 25000 Steps) (loss=0.04971): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (8231 / 25000 Steps) (loss=0.05101): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (8234 / 25000 Steps) (loss=0.04353): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (8237 / 25000 Steps) (loss=0.04667): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (8240 / 25000 Steps) (loss=0.04253): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (8243 / 25000 Steps) (loss=0.03540): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (8246 / 25000 Steps) (loss=0.05521): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (8249 / 25000 Steps) (loss=0.03213): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (8252 / 25000 Steps) (loss=0.05710): 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]\n",
      "Training (8255 / 25000 Steps) (loss=0.05519): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (8258 / 25000 Steps) (loss=0.06005): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (8261 / 25000 Steps) (loss=0.03728): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (8264 / 25000 Steps) (loss=0.04387): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (8267 / 25000 Steps) (loss=0.06111): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (8270 / 25000 Steps) (loss=0.03908): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (8273 / 25000 Steps) (loss=0.04409): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (8276 / 25000 Steps) (loss=0.03551): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (8279 / 25000 Steps) (loss=0.04422): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (8282 / 25000 Steps) (loss=0.03536): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (8285 / 25000 Steps) (loss=0.04165): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (8288 / 25000 Steps) (loss=0.04273): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (8291 / 25000 Steps) (loss=0.05154): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (8294 / 25000 Steps) (loss=0.05715): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (8297 / 25000 Steps) (loss=0.04259): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (8300 / 25000 Steps) (loss=0.04517): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (8303 / 25000 Steps) (loss=0.03889): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (8306 / 25000 Steps) (loss=0.08689): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (8309 / 25000 Steps) (loss=0.07758): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (8312 / 25000 Steps) (loss=0.05506): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (8315 / 25000 Steps) (loss=0.03754): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (8318 / 25000 Steps) (loss=0.04677): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (8321 / 25000 Steps) (loss=0.04389): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (8324 / 25000 Steps) (loss=0.04862): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (8327 / 25000 Steps) (loss=0.05970): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (8330 / 25000 Steps) (loss=0.06766): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (8333 / 25000 Steps) (loss=0.04359): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (8336 / 25000 Steps) (loss=0.03980): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (8339 / 25000 Steps) (loss=0.04598): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (8342 / 25000 Steps) (loss=0.03843): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (8345 / 25000 Steps) (loss=0.05673): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (8348 / 25000 Steps) (loss=0.03205): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (8351 / 25000 Steps) (loss=0.04218): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (8354 / 25000 Steps) (loss=0.04926): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (8357 / 25000 Steps) (loss=0.04658): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (8360 / 25000 Steps) (loss=0.04849): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (8363 / 25000 Steps) (loss=0.04618): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (8366 / 25000 Steps) (loss=0.04817): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (8369 / 25000 Steps) (loss=0.07450): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (8372 / 25000 Steps) (loss=0.04316): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (8375 / 25000 Steps) (loss=0.03682): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (8378 / 25000 Steps) (loss=0.04477): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (8381 / 25000 Steps) (loss=0.03841): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (8384 / 25000 Steps) (loss=0.05650): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (8387 / 25000 Steps) (loss=0.04852): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (8390 / 25000 Steps) (loss=0.04605): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (8393 / 25000 Steps) (loss=0.04288): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (8396 / 25000 Steps) (loss=0.05762): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (8399 / 25000 Steps) (loss=0.03586): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (8402 / 25000 Steps) (loss=0.05060): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (8405 / 25000 Steps) (loss=0.05021): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (8408 / 25000 Steps) (loss=0.04835): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (8411 / 25000 Steps) (loss=0.04548): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (8414 / 25000 Steps) (loss=0.04145): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (8417 / 25000 Steps) (loss=0.05274): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (8420 / 25000 Steps) (loss=0.04399): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (8423 / 25000 Steps) (loss=0.04215): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (8426 / 25000 Steps) (loss=0.04186): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (8429 / 25000 Steps) (loss=0.03764): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (8432 / 25000 Steps) (loss=0.04516): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (8435 / 25000 Steps) (loss=0.04441): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (8438 / 25000 Steps) (loss=0.03876): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (8441 / 25000 Steps) (loss=0.05273): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (8444 / 25000 Steps) (loss=0.04702): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (8447 / 25000 Steps) (loss=0.04169): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (8450 / 25000 Steps) (loss=0.06025): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (8453 / 25000 Steps) (loss=0.04446): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (8456 / 25000 Steps) (loss=0.04258): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (8459 / 25000 Steps) (loss=0.04437): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (8462 / 25000 Steps) (loss=0.05485): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (8465 / 25000 Steps) (loss=0.04150): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (8468 / 25000 Steps) (loss=0.02908): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (8471 / 25000 Steps) (loss=0.03285): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (8474 / 25000 Steps) (loss=0.03987): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (8477 / 25000 Steps) (loss=0.03778): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (8480 / 25000 Steps) (loss=0.04246): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (8483 / 25000 Steps) (loss=0.03756): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (8486 / 25000 Steps) (loss=0.04852): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (8489 / 25000 Steps) (loss=0.03349): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (8492 / 25000 Steps) (loss=0.04626): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (8495 / 25000 Steps) (loss=0.04644): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (8498 / 25000 Steps) (loss=0.03851): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Validate (8499 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]it]\n",
      "Training (8501 / 25000 Steps) (loss=0.04774):  67%|██████▋   | 2/3 [00:02<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (8501 / 25000 Steps) (loss=0.04774): 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "Training (8504 / 25000 Steps) (loss=0.04004): 100%|██████████| 3/3 [00:01<00:00,  2.02it/s]\n",
      "Training (8507 / 25000 Steps) (loss=0.04729): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (8510 / 25000 Steps) (loss=0.03815): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (8513 / 25000 Steps) (loss=0.05025): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (8516 / 25000 Steps) (loss=0.04369): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (8519 / 25000 Steps) (loss=0.05056): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (8522 / 25000 Steps) (loss=0.04552): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (8525 / 25000 Steps) (loss=0.02961): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (8528 / 25000 Steps) (loss=0.04562): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (8531 / 25000 Steps) (loss=0.04348): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (8534 / 25000 Steps) (loss=0.05134): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (8537 / 25000 Steps) (loss=0.03501): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (8540 / 25000 Steps) (loss=0.04550): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (8543 / 25000 Steps) (loss=0.05651): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (8546 / 25000 Steps) (loss=0.04498): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (8549 / 25000 Steps) (loss=0.05439): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (8552 / 25000 Steps) (loss=0.03995): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (8555 / 25000 Steps) (loss=0.04741): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (8558 / 25000 Steps) (loss=0.03845): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (8561 / 25000 Steps) (loss=0.04510): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (8564 / 25000 Steps) (loss=0.03904): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (8567 / 25000 Steps) (loss=0.03596): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (8570 / 25000 Steps) (loss=0.04208): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (8573 / 25000 Steps) (loss=0.03987): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (8576 / 25000 Steps) (loss=0.04954): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (8579 / 25000 Steps) (loss=0.04029): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (8582 / 25000 Steps) (loss=0.04300): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (8585 / 25000 Steps) (loss=0.03646): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (8588 / 25000 Steps) (loss=0.03092): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (8591 / 25000 Steps) (loss=0.05585): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (8594 / 25000 Steps) (loss=0.03951): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (8597 / 25000 Steps) (loss=0.04396): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (8600 / 25000 Steps) (loss=0.03668): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (8603 / 25000 Steps) (loss=0.04273): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (8606 / 25000 Steps) (loss=0.06058): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (8609 / 25000 Steps) (loss=0.05849): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (8612 / 25000 Steps) (loss=0.05404): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (8615 / 25000 Steps) (loss=0.03845): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (8618 / 25000 Steps) (loss=0.05162): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (8621 / 25000 Steps) (loss=0.04606): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (8624 / 25000 Steps) (loss=0.05028): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (8627 / 25000 Steps) (loss=0.03497): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (8630 / 25000 Steps) (loss=0.04662): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (8633 / 25000 Steps) (loss=0.03647): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (8636 / 25000 Steps) (loss=0.03970): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (8639 / 25000 Steps) (loss=0.04600): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (8642 / 25000 Steps) (loss=0.04295): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (8645 / 25000 Steps) (loss=0.04731): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (8648 / 25000 Steps) (loss=0.04208): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (8651 / 25000 Steps) (loss=0.03928): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (8654 / 25000 Steps) (loss=0.04310): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (8657 / 25000 Steps) (loss=0.04875): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (8660 / 25000 Steps) (loss=0.04157): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (8663 / 25000 Steps) (loss=0.04010): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (8666 / 25000 Steps) (loss=0.04711): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (8669 / 25000 Steps) (loss=0.03367): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (8672 / 25000 Steps) (loss=0.04084): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (8675 / 25000 Steps) (loss=0.03457): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (8678 / 25000 Steps) (loss=0.05682): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (8681 / 25000 Steps) (loss=0.05177): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (8684 / 25000 Steps) (loss=0.03569): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (8687 / 25000 Steps) (loss=0.04463): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (8690 / 25000 Steps) (loss=0.04291): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (8693 / 25000 Steps) (loss=0.04584): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (8696 / 25000 Steps) (loss=0.04239): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (8699 / 25000 Steps) (loss=0.04786): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (8702 / 25000 Steps) (loss=0.05020): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (8705 / 25000 Steps) (loss=0.04412): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (8708 / 25000 Steps) (loss=0.05330): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (8711 / 25000 Steps) (loss=0.03068): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (8714 / 25000 Steps) (loss=0.03782): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (8717 / 25000 Steps) (loss=0.03793): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (8720 / 25000 Steps) (loss=0.03390): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (8723 / 25000 Steps) (loss=0.04957): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (8726 / 25000 Steps) (loss=0.04909): 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
      "Training (8729 / 25000 Steps) (loss=0.04778): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (8732 / 25000 Steps) (loss=0.04158): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (8735 / 25000 Steps) (loss=0.05088): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (8738 / 25000 Steps) (loss=0.04713): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (8741 / 25000 Steps) (loss=0.04049): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (8744 / 25000 Steps) (loss=0.03597): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (8747 / 25000 Steps) (loss=0.04179): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (8750 / 25000 Steps) (loss=0.06260): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (8753 / 25000 Steps) (loss=0.05866): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (8756 / 25000 Steps) (loss=0.04149): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (8759 / 25000 Steps) (loss=0.05205): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (8762 / 25000 Steps) (loss=0.04549): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (8765 / 25000 Steps) (loss=0.03877): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (8768 / 25000 Steps) (loss=0.05477): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (8771 / 25000 Steps) (loss=0.05285): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (8774 / 25000 Steps) (loss=0.03484): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (8777 / 25000 Steps) (loss=0.03225): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (8780 / 25000 Steps) (loss=0.04856): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (8783 / 25000 Steps) (loss=0.06338): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (8786 / 25000 Steps) (loss=0.04666): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (8789 / 25000 Steps) (loss=0.03222): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (8792 / 25000 Steps) (loss=0.03932): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (8795 / 25000 Steps) (loss=0.06672): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (8798 / 25000 Steps) (loss=0.06061): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (8801 / 25000 Steps) (loss=0.04193): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (8804 / 25000 Steps) (loss=0.04055): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (8807 / 25000 Steps) (loss=0.05455): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (8810 / 25000 Steps) (loss=0.04269): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (8813 / 25000 Steps) (loss=0.05393): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (8816 / 25000 Steps) (loss=0.03770): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (8819 / 25000 Steps) (loss=0.04774): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (8822 / 25000 Steps) (loss=0.04886): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (8825 / 25000 Steps) (loss=0.04640): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (8828 / 25000 Steps) (loss=0.06496): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (8831 / 25000 Steps) (loss=0.03300): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (8834 / 25000 Steps) (loss=0.04355): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (8837 / 25000 Steps) (loss=0.03148): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (8840 / 25000 Steps) (loss=0.05006): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (8843 / 25000 Steps) (loss=0.03954): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (8846 / 25000 Steps) (loss=0.03716): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (8849 / 25000 Steps) (loss=0.03536): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (8852 / 25000 Steps) (loss=0.04889): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (8855 / 25000 Steps) (loss=0.03487): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (8858 / 25000 Steps) (loss=0.04289): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (8861 / 25000 Steps) (loss=0.05373): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (8864 / 25000 Steps) (loss=0.04705): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (8867 / 25000 Steps) (loss=0.04430): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (8870 / 25000 Steps) (loss=0.03720): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (8873 / 25000 Steps) (loss=0.03931): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (8876 / 25000 Steps) (loss=0.05390): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (8879 / 25000 Steps) (loss=0.04555): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (8882 / 25000 Steps) (loss=0.04764): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (8885 / 25000 Steps) (loss=0.04996): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (8888 / 25000 Steps) (loss=0.03738): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (8891 / 25000 Steps) (loss=0.05053): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (8894 / 25000 Steps) (loss=0.03785): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (8897 / 25000 Steps) (loss=0.04928): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (8900 / 25000 Steps) (loss=0.04557): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (8903 / 25000 Steps) (loss=0.03611): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (8906 / 25000 Steps) (loss=0.03640): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (8909 / 25000 Steps) (loss=0.04346): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (8912 / 25000 Steps) (loss=0.04551): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (8915 / 25000 Steps) (loss=0.03283): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (8918 / 25000 Steps) (loss=0.03001): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (8921 / 25000 Steps) (loss=0.05632): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (8924 / 25000 Steps) (loss=0.03468): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (8927 / 25000 Steps) (loss=0.03658): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (8930 / 25000 Steps) (loss=0.04649): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (8933 / 25000 Steps) (loss=0.03544): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (8936 / 25000 Steps) (loss=0.06421): 100%|██████████| 3/3 [00:02<00:00,  1.05it/s]\n",
      "Training (8939 / 25000 Steps) (loss=0.04759): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (8942 / 25000 Steps) (loss=0.03273): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (8945 / 25000 Steps) (loss=0.03797): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (8948 / 25000 Steps) (loss=0.04345): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (8951 / 25000 Steps) (loss=0.03678): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (8954 / 25000 Steps) (loss=0.04787): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (8957 / 25000 Steps) (loss=0.03223): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (8960 / 25000 Steps) (loss=0.05373): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (8963 / 25000 Steps) (loss=0.04003): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (8966 / 25000 Steps) (loss=0.04303): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (8969 / 25000 Steps) (loss=0.05421): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (8972 / 25000 Steps) (loss=0.06503): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (8975 / 25000 Steps) (loss=0.03965): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (8978 / 25000 Steps) (loss=0.04160): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (8981 / 25000 Steps) (loss=0.04764): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (8984 / 25000 Steps) (loss=0.03769): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (8987 / 25000 Steps) (loss=0.03426): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (8990 / 25000 Steps) (loss=0.03891): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (8993 / 25000 Steps) (loss=0.05482): 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]\n",
      "Training (8996 / 25000 Steps) (loss=0.03814): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (8999 / 25000 Steps) (loss=0.06176): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Validate (9000 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Training (9002 / 25000 Steps) (loss=0.04826): 100%|██████████| 3/3 [00:02<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (9002 / 25000 Steps) (loss=0.04826): 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
      "Training (9005 / 25000 Steps) (loss=0.03998): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (9008 / 25000 Steps) (loss=0.03356): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (9011 / 25000 Steps) (loss=0.04497): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (9014 / 25000 Steps) (loss=0.05025): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (9017 / 25000 Steps) (loss=0.04613): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (9020 / 25000 Steps) (loss=0.04464): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (9023 / 25000 Steps) (loss=0.04022): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (9026 / 25000 Steps) (loss=0.04500): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (9029 / 25000 Steps) (loss=0.04853): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (9032 / 25000 Steps) (loss=0.03891): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (9035 / 25000 Steps) (loss=0.04175): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (9038 / 25000 Steps) (loss=0.05386): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (9041 / 25000 Steps) (loss=0.04320): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (9044 / 25000 Steps) (loss=0.04905): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (9047 / 25000 Steps) (loss=0.03797): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (9050 / 25000 Steps) (loss=0.03873): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (9053 / 25000 Steps) (loss=0.03770): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (9056 / 25000 Steps) (loss=0.03580): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (9059 / 25000 Steps) (loss=0.06298): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (9062 / 25000 Steps) (loss=0.04150): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (9065 / 25000 Steps) (loss=0.04458): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (9068 / 25000 Steps) (loss=0.03806): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (9071 / 25000 Steps) (loss=0.06829): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (9074 / 25000 Steps) (loss=0.03780): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (9077 / 25000 Steps) (loss=0.04540): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (9080 / 25000 Steps) (loss=0.04639): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (9083 / 25000 Steps) (loss=0.04628): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (9086 / 25000 Steps) (loss=0.04886): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (9089 / 25000 Steps) (loss=0.05879): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (9092 / 25000 Steps) (loss=0.03958): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (9095 / 25000 Steps) (loss=0.04766): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (9098 / 25000 Steps) (loss=0.03825): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (9101 / 25000 Steps) (loss=0.04324): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (9104 / 25000 Steps) (loss=0.05974): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (9107 / 25000 Steps) (loss=0.05358): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (9110 / 25000 Steps) (loss=0.03654): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (9113 / 25000 Steps) (loss=0.03668): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (9116 / 25000 Steps) (loss=0.03417): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (9119 / 25000 Steps) (loss=0.05674): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (9122 / 25000 Steps) (loss=0.03835): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (9125 / 25000 Steps) (loss=0.05033): 100%|██████████| 3/3 [00:02<00:00,  1.14it/s]\n",
      "Training (9128 / 25000 Steps) (loss=0.04572): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (9131 / 25000 Steps) (loss=0.03902): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (9134 / 25000 Steps) (loss=0.04063): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (9137 / 25000 Steps) (loss=0.04631): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (9140 / 25000 Steps) (loss=0.03562): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (9143 / 25000 Steps) (loss=0.04047): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (9146 / 25000 Steps) (loss=0.04093): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (9149 / 25000 Steps) (loss=0.03287): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (9152 / 25000 Steps) (loss=0.03848): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (9155 / 25000 Steps) (loss=0.04822): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (9158 / 25000 Steps) (loss=0.05402): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (9161 / 25000 Steps) (loss=0.04326): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (9164 / 25000 Steps) (loss=0.04872): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (9167 / 25000 Steps) (loss=0.04880): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (9170 / 25000 Steps) (loss=0.04491): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (9173 / 25000 Steps) (loss=0.04330): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (9176 / 25000 Steps) (loss=0.06945): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (9179 / 25000 Steps) (loss=0.04237): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (9182 / 25000 Steps) (loss=0.04690): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (9185 / 25000 Steps) (loss=0.04053): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (9188 / 25000 Steps) (loss=0.04689): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (9191 / 25000 Steps) (loss=0.04942): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (9194 / 25000 Steps) (loss=0.04684): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (9197 / 25000 Steps) (loss=0.04041): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (9200 / 25000 Steps) (loss=0.03271): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (9203 / 25000 Steps) (loss=0.04958): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (9206 / 25000 Steps) (loss=0.03465): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (9209 / 25000 Steps) (loss=0.04237): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (9212 / 25000 Steps) (loss=0.05396): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (9215 / 25000 Steps) (loss=0.04213): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (9218 / 25000 Steps) (loss=0.04220): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (9221 / 25000 Steps) (loss=0.03657): 100%|██████████| 3/3 [00:02<00:00,  1.24it/s]\n",
      "Training (9224 / 25000 Steps) (loss=0.03735): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (9227 / 25000 Steps) (loss=0.04212): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (9230 / 25000 Steps) (loss=0.05084): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (9233 / 25000 Steps) (loss=0.04350): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (9236 / 25000 Steps) (loss=0.04855): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (9239 / 25000 Steps) (loss=0.03372): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (9242 / 25000 Steps) (loss=0.05912): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (9245 / 25000 Steps) (loss=0.03931): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (9248 / 25000 Steps) (loss=0.03660): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (9251 / 25000 Steps) (loss=0.04371): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (9254 / 25000 Steps) (loss=0.04258): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (9257 / 25000 Steps) (loss=0.03983): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (9260 / 25000 Steps) (loss=0.03119): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (9263 / 25000 Steps) (loss=0.05567): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (9266 / 25000 Steps) (loss=0.03490): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (9269 / 25000 Steps) (loss=0.03118): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (9272 / 25000 Steps) (loss=0.04238): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (9275 / 25000 Steps) (loss=0.03889): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "Training (9278 / 25000 Steps) (loss=0.06458): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (9281 / 25000 Steps) (loss=0.03712): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (9284 / 25000 Steps) (loss=0.04503): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (9287 / 25000 Steps) (loss=0.05302): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (9290 / 25000 Steps) (loss=0.04770): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (9293 / 25000 Steps) (loss=0.03633): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (9296 / 25000 Steps) (loss=0.03196): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (9299 / 25000 Steps) (loss=0.05515): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (9302 / 25000 Steps) (loss=0.03595): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (9305 / 25000 Steps) (loss=0.04141): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (9308 / 25000 Steps) (loss=0.04022): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (9311 / 25000 Steps) (loss=0.03188): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (9314 / 25000 Steps) (loss=0.03251): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (9317 / 25000 Steps) (loss=0.03787): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (9320 / 25000 Steps) (loss=0.03262): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (9323 / 25000 Steps) (loss=0.04868): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (9326 / 25000 Steps) (loss=0.03962): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (9329 / 25000 Steps) (loss=0.04690): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (9332 / 25000 Steps) (loss=0.04523): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (9335 / 25000 Steps) (loss=0.03644): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (9338 / 25000 Steps) (loss=0.04137): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (9341 / 25000 Steps) (loss=0.04400): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (9344 / 25000 Steps) (loss=0.03876): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (9347 / 25000 Steps) (loss=0.05217): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (9350 / 25000 Steps) (loss=0.04521): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (9353 / 25000 Steps) (loss=0.04544): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (9356 / 25000 Steps) (loss=0.03716): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (9359 / 25000 Steps) (loss=0.04548): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (9362 / 25000 Steps) (loss=0.03987): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (9365 / 25000 Steps) (loss=0.04253): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (9368 / 25000 Steps) (loss=0.05177): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (9371 / 25000 Steps) (loss=0.03740): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (9374 / 25000 Steps) (loss=0.03625): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (9377 / 25000 Steps) (loss=0.04027): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (9380 / 25000 Steps) (loss=0.04621): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (9383 / 25000 Steps) (loss=0.04639): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (9386 / 25000 Steps) (loss=0.04664): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (9389 / 25000 Steps) (loss=0.03716): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (9392 / 25000 Steps) (loss=0.03749): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (9395 / 25000 Steps) (loss=0.04086): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (9398 / 25000 Steps) (loss=0.03911): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (9401 / 25000 Steps) (loss=0.05505): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (9404 / 25000 Steps) (loss=0.03950): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (9407 / 25000 Steps) (loss=0.04919): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (9410 / 25000 Steps) (loss=0.04461): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (9413 / 25000 Steps) (loss=0.03245): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (9416 / 25000 Steps) (loss=0.04686): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (9419 / 25000 Steps) (loss=0.04507): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (9422 / 25000 Steps) (loss=0.04732): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (9425 / 25000 Steps) (loss=0.03334): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (9428 / 25000 Steps) (loss=0.05372): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (9431 / 25000 Steps) (loss=0.05792): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (9434 / 25000 Steps) (loss=0.05589): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (9437 / 25000 Steps) (loss=0.04937): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (9440 / 25000 Steps) (loss=0.03638): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (9443 / 25000 Steps) (loss=0.04553): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (9446 / 25000 Steps) (loss=0.05236): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (9449 / 25000 Steps) (loss=0.04176): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (9452 / 25000 Steps) (loss=0.04243): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (9455 / 25000 Steps) (loss=0.05224): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (9458 / 25000 Steps) (loss=0.04532): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (9461 / 25000 Steps) (loss=0.03240): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (9464 / 25000 Steps) (loss=0.04492): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (9467 / 25000 Steps) (loss=0.04396): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (9470 / 25000 Steps) (loss=0.05482): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (9473 / 25000 Steps) (loss=0.03815): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (9476 / 25000 Steps) (loss=0.03757): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (9479 / 25000 Steps) (loss=0.04452): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (9482 / 25000 Steps) (loss=0.05168): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (9485 / 25000 Steps) (loss=0.03067): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (9488 / 25000 Steps) (loss=0.04810): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (9491 / 25000 Steps) (loss=0.04188): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (9494 / 25000 Steps) (loss=0.05477): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (9497 / 25000 Steps) (loss=0.06439): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Validate (9498 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]/s]\n",
      "Training (9500 / 25000 Steps) (loss=0.04480): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (9500 / 25000 Steps) (loss=0.04480): 100%|██████████| 3/3 [00:02<00:00,  1.25it/s]\n",
      "Training (9503 / 25000 Steps) (loss=0.04492): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (9506 / 25000 Steps) (loss=0.04304): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (9509 / 25000 Steps) (loss=0.03953): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (9512 / 25000 Steps) (loss=0.04348): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (9515 / 25000 Steps) (loss=0.05129): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (9518 / 25000 Steps) (loss=0.03077): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (9521 / 25000 Steps) (loss=0.04140): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (9524 / 25000 Steps) (loss=0.03126): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (9527 / 25000 Steps) (loss=0.03907): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (9530 / 25000 Steps) (loss=0.03820): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (9533 / 25000 Steps) (loss=0.04988): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (9536 / 25000 Steps) (loss=0.03932): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (9539 / 25000 Steps) (loss=0.03751): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (9542 / 25000 Steps) (loss=0.04000): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (9545 / 25000 Steps) (loss=0.04753): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (9548 / 25000 Steps) (loss=0.03753): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (9551 / 25000 Steps) (loss=0.06260): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (9554 / 25000 Steps) (loss=0.04981): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (9557 / 25000 Steps) (loss=0.02981): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (9560 / 25000 Steps) (loss=0.04656): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (9563 / 25000 Steps) (loss=0.04617): 100%|██████████| 3/3 [00:02<00:00,  1.13it/s]\n",
      "Training (9566 / 25000 Steps) (loss=0.04041): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (9569 / 25000 Steps) (loss=0.03047): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (9572 / 25000 Steps) (loss=0.03591): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (9575 / 25000 Steps) (loss=0.03182): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (9578 / 25000 Steps) (loss=0.04070): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (9581 / 25000 Steps) (loss=0.05478): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (9584 / 25000 Steps) (loss=0.03069): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (9587 / 25000 Steps) (loss=0.03276): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (9590 / 25000 Steps) (loss=0.05294): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (9593 / 25000 Steps) (loss=0.04350): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (9596 / 25000 Steps) (loss=0.04916): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (9599 / 25000 Steps) (loss=0.04780): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (9602 / 25000 Steps) (loss=0.04665): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (9605 / 25000 Steps) (loss=0.03963): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (9608 / 25000 Steps) (loss=0.04821): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (9611 / 25000 Steps) (loss=0.04621): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (9614 / 25000 Steps) (loss=0.03369): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (9617 / 25000 Steps) (loss=0.04413): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (9620 / 25000 Steps) (loss=0.03214): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (9623 / 25000 Steps) (loss=0.04248): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (9626 / 25000 Steps) (loss=0.04669): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (9629 / 25000 Steps) (loss=0.04036): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (9632 / 25000 Steps) (loss=0.03820): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (9635 / 25000 Steps) (loss=0.03095): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (9638 / 25000 Steps) (loss=0.03731): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (9641 / 25000 Steps) (loss=0.03801): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (9644 / 25000 Steps) (loss=0.02916): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (9647 / 25000 Steps) (loss=0.04291): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (9650 / 25000 Steps) (loss=0.03263): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (9653 / 25000 Steps) (loss=0.03294): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (9656 / 25000 Steps) (loss=0.04781): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (9659 / 25000 Steps) (loss=0.04577): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (9662 / 25000 Steps) (loss=0.05130): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (9665 / 25000 Steps) (loss=0.03350): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (9668 / 25000 Steps) (loss=0.03667): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (9671 / 25000 Steps) (loss=0.05145): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (9674 / 25000 Steps) (loss=0.04731): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (9677 / 25000 Steps) (loss=0.03449): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (9680 / 25000 Steps) (loss=0.04982): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (9683 / 25000 Steps) (loss=0.04664): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (9686 / 25000 Steps) (loss=0.04700): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (9689 / 25000 Steps) (loss=0.04530): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (9692 / 25000 Steps) (loss=0.03813): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (9695 / 25000 Steps) (loss=0.03266): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (9698 / 25000 Steps) (loss=0.04740): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (9701 / 25000 Steps) (loss=0.04525): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (9704 / 25000 Steps) (loss=0.04249): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (9707 / 25000 Steps) (loss=0.04610): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (9710 / 25000 Steps) (loss=0.03625): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (9713 / 25000 Steps) (loss=0.03967): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (9716 / 25000 Steps) (loss=0.05684): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (9719 / 25000 Steps) (loss=0.04720): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (9722 / 25000 Steps) (loss=0.03939): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (9725 / 25000 Steps) (loss=0.05656): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (9728 / 25000 Steps) (loss=0.03373): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (9731 / 25000 Steps) (loss=0.03142): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (9734 / 25000 Steps) (loss=0.04025): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (9737 / 25000 Steps) (loss=0.04484): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (9740 / 25000 Steps) (loss=0.04824): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (9743 / 25000 Steps) (loss=0.03502): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (9746 / 25000 Steps) (loss=0.03483): 100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
      "Training (9749 / 25000 Steps) (loss=0.03419): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (9752 / 25000 Steps) (loss=0.05175): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (9755 / 25000 Steps) (loss=0.04276): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (9758 / 25000 Steps) (loss=0.03987): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (9761 / 25000 Steps) (loss=0.04591): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (9764 / 25000 Steps) (loss=0.04377): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (9767 / 25000 Steps) (loss=0.04114): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (9770 / 25000 Steps) (loss=0.04464): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (9773 / 25000 Steps) (loss=0.04693): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (9776 / 25000 Steps) (loss=0.05715): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (9779 / 25000 Steps) (loss=0.04378): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (9782 / 25000 Steps) (loss=0.04864): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (9785 / 25000 Steps) (loss=0.04205): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (9788 / 25000 Steps) (loss=0.04288): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (9791 / 25000 Steps) (loss=0.06255): 100%|██████████| 3/3 [00:02<00:00,  1.19it/s]\n",
      "Training (9794 / 25000 Steps) (loss=0.03958): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (9797 / 25000 Steps) (loss=0.04136): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (9800 / 25000 Steps) (loss=0.05669): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (9803 / 25000 Steps) (loss=0.03966): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (9806 / 25000 Steps) (loss=0.03630): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (9809 / 25000 Steps) (loss=0.03809): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (9812 / 25000 Steps) (loss=0.04560): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (9815 / 25000 Steps) (loss=0.04015): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (9818 / 25000 Steps) (loss=0.06405): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (9821 / 25000 Steps) (loss=0.04428): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (9824 / 25000 Steps) (loss=0.03359): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (9827 / 25000 Steps) (loss=0.03333): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (9830 / 25000 Steps) (loss=0.03865): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (9833 / 25000 Steps) (loss=0.04373): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (9836 / 25000 Steps) (loss=0.04282): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (9839 / 25000 Steps) (loss=0.05340): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (9842 / 25000 Steps) (loss=0.04363): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (9845 / 25000 Steps) (loss=0.04126): 100%|██████████| 3/3 [00:02<00:00,  1.10it/s]\n",
      "Training (9848 / 25000 Steps) (loss=0.06183): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (9851 / 25000 Steps) (loss=0.05613): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (9854 / 25000 Steps) (loss=0.04587): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (9857 / 25000 Steps) (loss=0.04591): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (9860 / 25000 Steps) (loss=0.03328): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (9863 / 25000 Steps) (loss=0.03795): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (9866 / 25000 Steps) (loss=0.04623): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (9869 / 25000 Steps) (loss=0.05920): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (9872 / 25000 Steps) (loss=0.06064): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (9875 / 25000 Steps) (loss=0.02967): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (9878 / 25000 Steps) (loss=0.04437): 100%|██████████| 3/3 [00:01<00:00,  2.00it/s]\n",
      "Training (9881 / 25000 Steps) (loss=0.03986): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (9884 / 25000 Steps) (loss=0.03566): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (9887 / 25000 Steps) (loss=0.04523): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (9890 / 25000 Steps) (loss=0.03522): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (9893 / 25000 Steps) (loss=0.04292): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (9896 / 25000 Steps) (loss=0.04266): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "Training (9899 / 25000 Steps) (loss=0.05408): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (9902 / 25000 Steps) (loss=0.04489): 100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
      "Training (9905 / 25000 Steps) (loss=0.03084): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (9908 / 25000 Steps) (loss=0.03257): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (9911 / 25000 Steps) (loss=0.04389): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (9914 / 25000 Steps) (loss=0.04146): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (9917 / 25000 Steps) (loss=0.03681): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (9920 / 25000 Steps) (loss=0.03347): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (9923 / 25000 Steps) (loss=0.04154): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (9926 / 25000 Steps) (loss=0.04989): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (9929 / 25000 Steps) (loss=0.03302): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (9932 / 25000 Steps) (loss=0.04670): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (9935 / 25000 Steps) (loss=0.04870): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (9938 / 25000 Steps) (loss=0.05346): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (9941 / 25000 Steps) (loss=0.03135): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (9944 / 25000 Steps) (loss=0.05605): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (9947 / 25000 Steps) (loss=0.04079): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (9950 / 25000 Steps) (loss=0.04778): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (9953 / 25000 Steps) (loss=0.03265): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (9956 / 25000 Steps) (loss=0.04146): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (9959 / 25000 Steps) (loss=0.03463): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (9962 / 25000 Steps) (loss=0.05338): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (9965 / 25000 Steps) (loss=0.05465): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (9968 / 25000 Steps) (loss=0.06342): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (9971 / 25000 Steps) (loss=0.05020): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (9974 / 25000 Steps) (loss=0.03223): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (9977 / 25000 Steps) (loss=0.04485): 100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
      "Training (9980 / 25000 Steps) (loss=0.03150): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (9983 / 25000 Steps) (loss=0.03964): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (9986 / 25000 Steps) (loss=0.04216): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (9989 / 25000 Steps) (loss=0.03454): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (9992 / 25000 Steps) (loss=0.04400): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (9995 / 25000 Steps) (loss=0.04550): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (9998 / 25000 Steps) (loss=0.04484): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Validate (9999 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]/it]\n",
      "Training (10001 / 25000 Steps) (loss=0.05601):  67%|██████▋   | 2/3 [00:02<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (10001 / 25000 Steps) (loss=0.05601): 100%|██████████| 3/3 [00:02<00:00,  1.32it/s]\n",
      "Training (10004 / 25000 Steps) (loss=0.03993): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (10007 / 25000 Steps) (loss=0.04001): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (10010 / 25000 Steps) (loss=0.04982): 100%|██████████| 3/3 [00:01<00:00,  1.98it/s]\n",
      "Training (10013 / 25000 Steps) (loss=0.05441): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (10016 / 25000 Steps) (loss=0.03573): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (10019 / 25000 Steps) (loss=0.04776): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "Training (10022 / 25000 Steps) (loss=0.03410): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (10025 / 25000 Steps) (loss=0.02738): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (10028 / 25000 Steps) (loss=0.05361): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (10031 / 25000 Steps) (loss=0.03291): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (10034 / 25000 Steps) (loss=0.03813): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (10037 / 25000 Steps) (loss=0.03336): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (10040 / 25000 Steps) (loss=0.04174): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (10043 / 25000 Steps) (loss=0.05324): 100%|██████████| 3/3 [00:01<00:00,  1.99it/s]\n",
      "Training (10046 / 25000 Steps) (loss=0.03709): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (10049 / 25000 Steps) (loss=0.04466): 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "Training (10052 / 25000 Steps) (loss=0.03999): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (10055 / 25000 Steps) (loss=0.04346): 100%|██████████| 3/3 [00:01<00:00,  1.99it/s]\n",
      "Training (10058 / 25000 Steps) (loss=0.05007): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (10061 / 25000 Steps) (loss=0.03895): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (10064 / 25000 Steps) (loss=0.03813): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (10067 / 25000 Steps) (loss=0.04855): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (10070 / 25000 Steps) (loss=0.03877): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (10073 / 25000 Steps) (loss=0.04819): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (10076 / 25000 Steps) (loss=0.03881): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (10079 / 25000 Steps) (loss=0.03906): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (10082 / 25000 Steps) (loss=0.05365): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (10085 / 25000 Steps) (loss=0.04727): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (10088 / 25000 Steps) (loss=0.03508): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (10091 / 25000 Steps) (loss=0.03673): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (10094 / 25000 Steps) (loss=0.04048): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (10097 / 25000 Steps) (loss=0.04790): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "Training (10100 / 25000 Steps) (loss=0.04853): 100%|██████████| 3/3 [00:01<00:00,  1.98it/s]\n",
      "Training (10103 / 25000 Steps) (loss=0.03178): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (10106 / 25000 Steps) (loss=0.04434): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (10109 / 25000 Steps) (loss=0.03462): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (10112 / 25000 Steps) (loss=0.05650): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (10115 / 25000 Steps) (loss=0.05984): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (10118 / 25000 Steps) (loss=0.06252): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (10121 / 25000 Steps) (loss=0.04276): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (10124 / 25000 Steps) (loss=0.04323): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (10127 / 25000 Steps) (loss=0.05404): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (10130 / 25000 Steps) (loss=0.03703): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (10133 / 25000 Steps) (loss=0.04104): 100%|██████████| 3/3 [00:02<00:00,  1.15it/s]\n",
      "Training (10136 / 25000 Steps) (loss=0.04292): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (10139 / 25000 Steps) (loss=0.04643): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (10142 / 25000 Steps) (loss=0.03531): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (10145 / 25000 Steps) (loss=0.03811): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (10148 / 25000 Steps) (loss=0.05287): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (10151 / 25000 Steps) (loss=0.03376): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (10154 / 25000 Steps) (loss=0.03525): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (10157 / 25000 Steps) (loss=0.04495): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (10160 / 25000 Steps) (loss=0.03969): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (10163 / 25000 Steps) (loss=0.04088): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (10166 / 25000 Steps) (loss=0.04626): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (10169 / 25000 Steps) (loss=0.04707): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (10172 / 25000 Steps) (loss=0.04423): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (10175 / 25000 Steps) (loss=0.04383): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (10178 / 25000 Steps) (loss=0.05387): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (10181 / 25000 Steps) (loss=0.04653): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (10184 / 25000 Steps) (loss=0.05735): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (10187 / 25000 Steps) (loss=0.02934): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (10190 / 25000 Steps) (loss=0.03751): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (10193 / 25000 Steps) (loss=0.04613): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (10196 / 25000 Steps) (loss=0.05806): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (10199 / 25000 Steps) (loss=0.03144): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (10202 / 25000 Steps) (loss=0.03000): 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "Training (10205 / 25000 Steps) (loss=0.03621): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (10208 / 25000 Steps) (loss=0.03515): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (10211 / 25000 Steps) (loss=0.03668): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (10214 / 25000 Steps) (loss=0.05007): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (10217 / 25000 Steps) (loss=0.04645): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (10220 / 25000 Steps) (loss=0.04050): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (10223 / 25000 Steps) (loss=0.03937): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (10226 / 25000 Steps) (loss=0.04352): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (10229 / 25000 Steps) (loss=0.03250): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (10232 / 25000 Steps) (loss=0.03806): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (10235 / 25000 Steps) (loss=0.03256): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (10238 / 25000 Steps) (loss=0.04361): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (10241 / 25000 Steps) (loss=0.03578): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (10244 / 25000 Steps) (loss=0.05082): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (10247 / 25000 Steps) (loss=0.04251): 100%|██████████| 3/3 [00:02<00:00,  1.35it/s]\n",
      "Training (10250 / 25000 Steps) (loss=0.04045): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (10253 / 25000 Steps) (loss=0.03254): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (10256 / 25000 Steps) (loss=0.04425): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (10259 / 25000 Steps) (loss=0.03533): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (10262 / 25000 Steps) (loss=0.04938): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (10265 / 25000 Steps) (loss=0.03857): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (10268 / 25000 Steps) (loss=0.03232): 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "Training (10271 / 25000 Steps) (loss=0.03953): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (10274 / 25000 Steps) (loss=0.03442): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (10277 / 25000 Steps) (loss=0.03702): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (10280 / 25000 Steps) (loss=0.03812): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (10283 / 25000 Steps) (loss=0.03955): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (10286 / 25000 Steps) (loss=0.03087): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (10289 / 25000 Steps) (loss=0.05756): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (10292 / 25000 Steps) (loss=0.04231): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (10295 / 25000 Steps) (loss=0.03898): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (10298 / 25000 Steps) (loss=0.03344): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (10301 / 25000 Steps) (loss=0.03194): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (10304 / 25000 Steps) (loss=0.03802): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (10307 / 25000 Steps) (loss=0.04905): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "Training (10310 / 25000 Steps) (loss=0.04204): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (10313 / 25000 Steps) (loss=0.03571): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (10316 / 25000 Steps) (loss=0.02598): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (10319 / 25000 Steps) (loss=0.03883): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (10322 / 25000 Steps) (loss=0.05453): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (10325 / 25000 Steps) (loss=0.02585): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (10328 / 25000 Steps) (loss=0.04056): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (10331 / 25000 Steps) (loss=0.03673): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (10334 / 25000 Steps) (loss=0.03985): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (10337 / 25000 Steps) (loss=0.03671): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (10340 / 25000 Steps) (loss=0.03710): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (10343 / 25000 Steps) (loss=0.04344): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (10346 / 25000 Steps) (loss=0.03571): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (10349 / 25000 Steps) (loss=0.03813): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (10352 / 25000 Steps) (loss=0.02953): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (10355 / 25000 Steps) (loss=0.04757): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (10358 / 25000 Steps) (loss=0.04861): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (10361 / 25000 Steps) (loss=0.04439): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (10364 / 25000 Steps) (loss=0.02735): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (10367 / 25000 Steps) (loss=0.04057): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (10370 / 25000 Steps) (loss=0.04583): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (10373 / 25000 Steps) (loss=0.05054): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (10376 / 25000 Steps) (loss=0.02713): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (10379 / 25000 Steps) (loss=0.05729): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (10382 / 25000 Steps) (loss=0.03771): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (10385 / 25000 Steps) (loss=0.03943): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (10388 / 25000 Steps) (loss=0.04600): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (10391 / 25000 Steps) (loss=0.04153): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (10394 / 25000 Steps) (loss=0.04084): 100%|██████████| 3/3 [00:01<00:00,  1.99it/s]\n",
      "Training (10397 / 25000 Steps) (loss=0.03730): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (10400 / 25000 Steps) (loss=0.03438): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (10403 / 25000 Steps) (loss=0.04665): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (10406 / 25000 Steps) (loss=0.03754): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (10409 / 25000 Steps) (loss=0.04034): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (10412 / 25000 Steps) (loss=0.03454): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (10415 / 25000 Steps) (loss=0.05438): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (10418 / 25000 Steps) (loss=0.04709): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (10421 / 25000 Steps) (loss=0.03731): 100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
      "Training (10424 / 25000 Steps) (loss=0.04525): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (10427 / 25000 Steps) (loss=0.03934): 100%|██████████| 3/3 [00:01<00:00,  2.06it/s]\n",
      "Training (10430 / 25000 Steps) (loss=0.03958): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (10433 / 25000 Steps) (loss=0.03488): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (10436 / 25000 Steps) (loss=0.03728): 100%|██████████| 3/3 [00:01<00:00,  1.98it/s]\n",
      "Training (10439 / 25000 Steps) (loss=0.03566): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (10442 / 25000 Steps) (loss=0.03845): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (10445 / 25000 Steps) (loss=0.04528): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (10448 / 25000 Steps) (loss=0.02777): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (10451 / 25000 Steps) (loss=0.05402): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (10454 / 25000 Steps) (loss=0.03949): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (10457 / 25000 Steps) (loss=0.05928): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (10460 / 25000 Steps) (loss=0.05157): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (10463 / 25000 Steps) (loss=0.03039): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (10466 / 25000 Steps) (loss=0.03728): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (10469 / 25000 Steps) (loss=0.03304): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (10472 / 25000 Steps) (loss=0.03247): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (10475 / 25000 Steps) (loss=0.04512): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (10478 / 25000 Steps) (loss=0.02967): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (10481 / 25000 Steps) (loss=0.03468): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (10484 / 25000 Steps) (loss=0.03732): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "Training (10487 / 25000 Steps) (loss=0.03304): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (10490 / 25000 Steps) (loss=0.04569): 100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
      "Training (10493 / 25000 Steps) (loss=0.04653): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (10496 / 25000 Steps) (loss=0.03983): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (10499 / 25000 Steps) (loss=0.03220): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Validate (10500 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "Training (10502 / 25000 Steps) (loss=0.03865): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (10502 / 25000 Steps) (loss=0.03865): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (10505 / 25000 Steps) (loss=0.03134): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (10508 / 25000 Steps) (loss=0.04473): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (10511 / 25000 Steps) (loss=0.04446): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (10514 / 25000 Steps) (loss=0.04998): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (10517 / 25000 Steps) (loss=0.04413): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (10520 / 25000 Steps) (loss=0.03469): 100%|██████████| 3/3 [00:01<00:00,  2.00it/s]\n",
      "Training (10523 / 25000 Steps) (loss=0.03254): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (10526 / 25000 Steps) (loss=0.03525): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (10529 / 25000 Steps) (loss=0.03975): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (10532 / 25000 Steps) (loss=0.03929): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (10535 / 25000 Steps) (loss=0.05035): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (10538 / 25000 Steps) (loss=0.05222): 100%|██████████| 3/3 [00:02<00:00,  1.25it/s]\n",
      "Training (10541 / 25000 Steps) (loss=0.04194): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (10544 / 25000 Steps) (loss=0.02985): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (10547 / 25000 Steps) (loss=0.04360): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (10550 / 25000 Steps) (loss=0.03763): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (10553 / 25000 Steps) (loss=0.03944): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (10556 / 25000 Steps) (loss=0.04380): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (10559 / 25000 Steps) (loss=0.03083): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (10562 / 25000 Steps) (loss=0.03827): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (10565 / 25000 Steps) (loss=0.04368): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (10568 / 25000 Steps) (loss=0.04007): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "Training (10571 / 25000 Steps) (loss=0.03452): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (10574 / 25000 Steps) (loss=0.04309): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (10577 / 25000 Steps) (loss=0.04203): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (10580 / 25000 Steps) (loss=0.04442): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (10583 / 25000 Steps) (loss=0.05153): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (10586 / 25000 Steps) (loss=0.03694): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (10589 / 25000 Steps) (loss=0.05741): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (10592 / 25000 Steps) (loss=0.03995): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (10595 / 25000 Steps) (loss=0.05531): 100%|██████████| 3/3 [00:02<00:00,  1.19it/s]\n",
      "Training (10598 / 25000 Steps) (loss=0.03662): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (10601 / 25000 Steps) (loss=0.04080): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (10604 / 25000 Steps) (loss=0.04612): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (10607 / 25000 Steps) (loss=0.02877): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (10610 / 25000 Steps) (loss=0.04236): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (10613 / 25000 Steps) (loss=0.04359): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (10616 / 25000 Steps) (loss=0.04228): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (10619 / 25000 Steps) (loss=0.03905): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (10622 / 25000 Steps) (loss=0.04312): 100%|██████████| 3/3 [00:01<00:00,  1.98it/s]\n",
      "Training (10625 / 25000 Steps) (loss=0.03947): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (10628 / 25000 Steps) (loss=0.04115): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (10631 / 25000 Steps) (loss=0.04332): 100%|██████████| 3/3 [00:01<00:00,  2.00it/s]\n",
      "Training (10634 / 25000 Steps) (loss=0.03215): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (10637 / 25000 Steps) (loss=0.03998): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (10640 / 25000 Steps) (loss=0.04771): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (10643 / 25000 Steps) (loss=0.02915): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (10646 / 25000 Steps) (loss=0.03756): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (10649 / 25000 Steps) (loss=0.04111): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (10652 / 25000 Steps) (loss=0.03440): 100%|██████████| 3/3 [00:02<00:00,  1.05it/s]\n",
      "Training (10655 / 25000 Steps) (loss=0.04359): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (10658 / 25000 Steps) (loss=0.03583): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (10661 / 25000 Steps) (loss=0.04818): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (10664 / 25000 Steps) (loss=0.04510): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (10667 / 25000 Steps) (loss=0.04574): 100%|██████████| 3/3 [00:01<00:00,  1.98it/s]\n",
      "Training (10670 / 25000 Steps) (loss=0.04534): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (10673 / 25000 Steps) (loss=0.04035): 100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
      "Training (10676 / 25000 Steps) (loss=0.03920): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (10679 / 25000 Steps) (loss=0.03495): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (10682 / 25000 Steps) (loss=0.04282): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (10685 / 25000 Steps) (loss=0.03414): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (10688 / 25000 Steps) (loss=0.05870): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (10691 / 25000 Steps) (loss=0.05588): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (10694 / 25000 Steps) (loss=0.05907): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (10697 / 25000 Steps) (loss=0.05157): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (10700 / 25000 Steps) (loss=0.03595): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (10703 / 25000 Steps) (loss=0.04963): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (10706 / 25000 Steps) (loss=0.04385): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (10709 / 25000 Steps) (loss=0.03962): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (10712 / 25000 Steps) (loss=0.04258): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (10715 / 25000 Steps) (loss=0.03240): 100%|██████████| 3/3 [00:02<00:00,  1.19it/s]\n",
      "Training (10718 / 25000 Steps) (loss=0.03653): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (10721 / 25000 Steps) (loss=0.04309): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (10724 / 25000 Steps) (loss=0.05355): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (10727 / 25000 Steps) (loss=0.03808): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (10730 / 25000 Steps) (loss=0.04114): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (10733 / 25000 Steps) (loss=0.03883): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (10736 / 25000 Steps) (loss=0.04139): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (10739 / 25000 Steps) (loss=0.05466): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (10742 / 25000 Steps) (loss=0.04061): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (10745 / 25000 Steps) (loss=0.04069): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (10748 / 25000 Steps) (loss=0.04312): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (10751 / 25000 Steps) (loss=0.05826): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (10754 / 25000 Steps) (loss=0.03450): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (10757 / 25000 Steps) (loss=0.03961): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (10760 / 25000 Steps) (loss=0.03226): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (10763 / 25000 Steps) (loss=0.05027): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (10766 / 25000 Steps) (loss=0.03366): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (10769 / 25000 Steps) (loss=0.02954): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (10772 / 25000 Steps) (loss=0.02418): 100%|██████████| 3/3 [00:01<00:00,  1.98it/s]\n",
      "Training (10775 / 25000 Steps) (loss=0.04797): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (10778 / 25000 Steps) (loss=0.04561): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (10781 / 25000 Steps) (loss=0.04064): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (10784 / 25000 Steps) (loss=0.05180): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (10787 / 25000 Steps) (loss=0.04260): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (10790 / 25000 Steps) (loss=0.03727): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (10793 / 25000 Steps) (loss=0.04006): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (10796 / 25000 Steps) (loss=0.04085): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (10799 / 25000 Steps) (loss=0.03720): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (10802 / 25000 Steps) (loss=0.04650): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (10805 / 25000 Steps) (loss=0.05439): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (10808 / 25000 Steps) (loss=0.03910): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (10811 / 25000 Steps) (loss=0.03714): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (10814 / 25000 Steps) (loss=0.03445): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (10817 / 25000 Steps) (loss=0.02884): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (10820 / 25000 Steps) (loss=0.04209): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (10823 / 25000 Steps) (loss=0.03095): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (10826 / 25000 Steps) (loss=0.04525): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (10829 / 25000 Steps) (loss=0.03745): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (10832 / 25000 Steps) (loss=0.03997): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (10835 / 25000 Steps) (loss=0.03959): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (10838 / 25000 Steps) (loss=0.03320): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (10841 / 25000 Steps) (loss=0.03576): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (10844 / 25000 Steps) (loss=0.04138): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (10847 / 25000 Steps) (loss=0.03742): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (10850 / 25000 Steps) (loss=0.04374): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (10853 / 25000 Steps) (loss=0.03923): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (10856 / 25000 Steps) (loss=0.04904): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (10859 / 25000 Steps) (loss=0.04736): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (10862 / 25000 Steps) (loss=0.05785): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (10865 / 25000 Steps) (loss=0.02943): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (10868 / 25000 Steps) (loss=0.04338): 100%|██████████| 3/3 [00:01<00:00,  2.08it/s]\n",
      "Training (10871 / 25000 Steps) (loss=0.04064): 100%|██████████| 3/3 [00:01<00:00,  2.02it/s]\n",
      "Training (10874 / 25000 Steps) (loss=0.04100): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (10877 / 25000 Steps) (loss=0.04077): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (10880 / 25000 Steps) (loss=0.04963): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (10883 / 25000 Steps) (loss=0.03368): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (10886 / 25000 Steps) (loss=0.05358): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (10889 / 25000 Steps) (loss=0.03300): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (10892 / 25000 Steps) (loss=0.05125): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (10895 / 25000 Steps) (loss=0.04165): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (10898 / 25000 Steps) (loss=0.03555): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (10901 / 25000 Steps) (loss=0.04707): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (10904 / 25000 Steps) (loss=0.04669): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (10907 / 25000 Steps) (loss=0.05675): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (10910 / 25000 Steps) (loss=0.03359): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (10913 / 25000 Steps) (loss=0.03808): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "Training (10916 / 25000 Steps) (loss=0.04021): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (10919 / 25000 Steps) (loss=0.03440): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (10922 / 25000 Steps) (loss=0.03644): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (10925 / 25000 Steps) (loss=0.03895): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (10928 / 25000 Steps) (loss=0.03704): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (10931 / 25000 Steps) (loss=0.02939): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (10934 / 25000 Steps) (loss=0.03029): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (10937 / 25000 Steps) (loss=0.04194): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (10940 / 25000 Steps) (loss=0.03303): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (10943 / 25000 Steps) (loss=0.04678): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (10946 / 25000 Steps) (loss=0.05718): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (10949 / 25000 Steps) (loss=0.05045): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (10952 / 25000 Steps) (loss=0.04841): 100%|██████████| 3/3 [00:02<00:00,  1.32it/s]\n",
      "Training (10955 / 25000 Steps) (loss=0.04570): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (10958 / 25000 Steps) (loss=0.04605): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (10961 / 25000 Steps) (loss=0.04569): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (10964 / 25000 Steps) (loss=0.04048): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (10967 / 25000 Steps) (loss=0.04540): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (10970 / 25000 Steps) (loss=0.04005): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (10973 / 25000 Steps) (loss=0.03841): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (10976 / 25000 Steps) (loss=0.04826): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (10979 / 25000 Steps) (loss=0.04243): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (10982 / 25000 Steps) (loss=0.03291): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (10985 / 25000 Steps) (loss=0.03641): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (10988 / 25000 Steps) (loss=0.03786): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (10991 / 25000 Steps) (loss=0.04538): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (10994 / 25000 Steps) (loss=0.03813): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (10997 / 25000 Steps) (loss=0.03882): 100%|██████████| 3/3 [00:01<00:00,  2.07it/s]\n",
      "Validate (10998 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]it]\n",
      "Training (11000 / 25000 Steps) (loss=0.03251): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training (11003 / 25000 Steps) (loss=0.03292): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (11006 / 25000 Steps) (loss=0.03749): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (11009 / 25000 Steps) (loss=0.03714): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (11012 / 25000 Steps) (loss=0.03644): 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]\n",
      "Training (11015 / 25000 Steps) (loss=0.02994): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (11018 / 25000 Steps) (loss=0.02767): 100%|██████████| 3/3 [00:01<00:00,  1.99it/s]\n",
      "Training (11021 / 25000 Steps) (loss=0.05289): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (11024 / 25000 Steps) (loss=0.04232): 100%|██████████| 3/3 [00:01<00:00,  2.02it/s]\n",
      "Training (11027 / 25000 Steps) (loss=0.04301): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (11030 / 25000 Steps) (loss=0.03114): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (11033 / 25000 Steps) (loss=0.04816): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (11036 / 25000 Steps) (loss=0.05180): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (11039 / 25000 Steps) (loss=0.03709): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (11042 / 25000 Steps) (loss=0.03925): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (11045 / 25000 Steps) (loss=0.03952): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (11048 / 25000 Steps) (loss=0.02963): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (11051 / 25000 Steps) (loss=0.03485): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (11054 / 25000 Steps) (loss=0.03337): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (11057 / 25000 Steps) (loss=0.03027): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (11060 / 25000 Steps) (loss=0.03896): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (11063 / 25000 Steps) (loss=0.03486): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (11066 / 25000 Steps) (loss=0.04875): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (11069 / 25000 Steps) (loss=0.03930): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (11072 / 25000 Steps) (loss=0.02778): 100%|██████████| 3/3 [00:02<00:00,  1.24it/s]\n",
      "Training (11075 / 25000 Steps) (loss=0.04833): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (11078 / 25000 Steps) (loss=0.03387): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (11081 / 25000 Steps) (loss=0.03396): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (11084 / 25000 Steps) (loss=0.03225): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (11087 / 25000 Steps) (loss=0.03519): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (11090 / 25000 Steps) (loss=0.03479): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (11093 / 25000 Steps) (loss=0.03532): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (11096 / 25000 Steps) (loss=0.04595): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (11099 / 25000 Steps) (loss=0.03851): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (11102 / 25000 Steps) (loss=0.03827): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (11105 / 25000 Steps) (loss=0.03327): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (11108 / 25000 Steps) (loss=0.03705): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (11111 / 25000 Steps) (loss=0.04190): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (11114 / 25000 Steps) (loss=0.04438): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (11117 / 25000 Steps) (loss=0.04736): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (11120 / 25000 Steps) (loss=0.04601): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (11123 / 25000 Steps) (loss=0.03149): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (11126 / 25000 Steps) (loss=0.03280): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (11129 / 25000 Steps) (loss=0.04216): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (11132 / 25000 Steps) (loss=0.03462): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (11135 / 25000 Steps) (loss=0.03582): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (11138 / 25000 Steps) (loss=0.04517): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (11141 / 25000 Steps) (loss=0.04417): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (11144 / 25000 Steps) (loss=0.04336): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (11147 / 25000 Steps) (loss=0.04925): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (11150 / 25000 Steps) (loss=0.03554): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (11153 / 25000 Steps) (loss=0.04056): 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "Training (11156 / 25000 Steps) (loss=0.06257): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (11159 / 25000 Steps) (loss=0.03773): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (11162 / 25000 Steps) (loss=0.04244): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (11165 / 25000 Steps) (loss=0.04179): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (11168 / 25000 Steps) (loss=0.03829): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (11171 / 25000 Steps) (loss=0.04078): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (11174 / 25000 Steps) (loss=0.02848): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (11177 / 25000 Steps) (loss=0.04750): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (11180 / 25000 Steps) (loss=0.04949): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (11183 / 25000 Steps) (loss=0.02735): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (11186 / 25000 Steps) (loss=0.05051): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (11189 / 25000 Steps) (loss=0.02610): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (11192 / 25000 Steps) (loss=0.02422): 100%|██████████| 3/3 [00:02<00:00,  1.16it/s]\n",
      "Training (11195 / 25000 Steps) (loss=0.03660): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (11198 / 25000 Steps) (loss=0.03265): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (11201 / 25000 Steps) (loss=0.04775): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (11204 / 25000 Steps) (loss=0.03170): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (11207 / 25000 Steps) (loss=0.03797): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (11210 / 25000 Steps) (loss=0.04323): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (11213 / 25000 Steps) (loss=0.03420): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (11216 / 25000 Steps) (loss=0.03600): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (11219 / 25000 Steps) (loss=0.03158): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (11222 / 25000 Steps) (loss=0.03891): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (11225 / 25000 Steps) (loss=0.04016): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (11228 / 25000 Steps) (loss=0.03912): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (11231 / 25000 Steps) (loss=0.04252): 100%|██████████| 3/3 [00:01<00:00,  1.98it/s]\n",
      "Training (11234 / 25000 Steps) (loss=0.03137): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (11237 / 25000 Steps) (loss=0.06314): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (11240 / 25000 Steps) (loss=0.03807): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (11243 / 25000 Steps) (loss=0.04550): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (11246 / 25000 Steps) (loss=0.03752): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (11249 / 25000 Steps) (loss=0.03268): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (11252 / 25000 Steps) (loss=0.03323): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (11255 / 25000 Steps) (loss=0.03711): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (11258 / 25000 Steps) (loss=0.03426): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (11261 / 25000 Steps) (loss=0.04967): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (11264 / 25000 Steps) (loss=0.03594): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (11267 / 25000 Steps) (loss=0.03175): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (11270 / 25000 Steps) (loss=0.04440): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (11273 / 25000 Steps) (loss=0.04340): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (11276 / 25000 Steps) (loss=0.03263): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (11279 / 25000 Steps) (loss=0.03132): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (11282 / 25000 Steps) (loss=0.05758): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (11285 / 25000 Steps) (loss=0.04552): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (11288 / 25000 Steps) (loss=0.04187): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (11291 / 25000 Steps) (loss=0.04745): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (11294 / 25000 Steps) (loss=0.03911): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (11297 / 25000 Steps) (loss=0.03698): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (11300 / 25000 Steps) (loss=0.03527): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (11303 / 25000 Steps) (loss=0.04078): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (11306 / 25000 Steps) (loss=0.03538): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (11309 / 25000 Steps) (loss=0.04484): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (11312 / 25000 Steps) (loss=0.05411): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (11315 / 25000 Steps) (loss=0.04179): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (11318 / 25000 Steps) (loss=0.04396): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (11321 / 25000 Steps) (loss=0.03886): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (11324 / 25000 Steps) (loss=0.04647): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (11327 / 25000 Steps) (loss=0.04052): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (11330 / 25000 Steps) (loss=0.04974): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (11333 / 25000 Steps) (loss=0.04144): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (11336 / 25000 Steps) (loss=0.04797): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (11339 / 25000 Steps) (loss=0.03369): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (11342 / 25000 Steps) (loss=0.03109): 100%|██████████| 3/3 [00:01<00:00,  1.99it/s]\n",
      "Training (11345 / 25000 Steps) (loss=0.04232): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (11348 / 25000 Steps) (loss=0.03825): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (11351 / 25000 Steps) (loss=0.03297): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (11354 / 25000 Steps) (loss=0.03827): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (11357 / 25000 Steps) (loss=0.06104): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (11360 / 25000 Steps) (loss=0.04678): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (11363 / 25000 Steps) (loss=0.04496): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (11366 / 25000 Steps) (loss=0.04050): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (11369 / 25000 Steps) (loss=0.04317): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (11372 / 25000 Steps) (loss=0.05772): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (11375 / 25000 Steps) (loss=0.04019): 100%|██████████| 3/3 [00:02<00:00,  1.16it/s]\n",
      "Training (11378 / 25000 Steps) (loss=0.03114): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (11381 / 25000 Steps) (loss=0.03209): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (11384 / 25000 Steps) (loss=0.04432): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (11387 / 25000 Steps) (loss=0.03933): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (11390 / 25000 Steps) (loss=0.03159): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (11393 / 25000 Steps) (loss=0.03353): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (11396 / 25000 Steps) (loss=0.03276): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (11399 / 25000 Steps) (loss=0.03430): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (11402 / 25000 Steps) (loss=0.03956): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (11405 / 25000 Steps) (loss=0.03434): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (11408 / 25000 Steps) (loss=0.05082): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (11411 / 25000 Steps) (loss=0.03672): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (11414 / 25000 Steps) (loss=0.02359): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (11417 / 25000 Steps) (loss=0.04465): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (11420 / 25000 Steps) (loss=0.03686): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (11423 / 25000 Steps) (loss=0.04335): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (11426 / 25000 Steps) (loss=0.03883): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (11429 / 25000 Steps) (loss=0.03245): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (11432 / 25000 Steps) (loss=0.03944): 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "Training (11435 / 25000 Steps) (loss=0.04366): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (11438 / 25000 Steps) (loss=0.04031): 100%|██████████| 3/3 [00:02<00:00,  1.24it/s]\n",
      "Training (11441 / 25000 Steps) (loss=0.04000): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (11444 / 25000 Steps) (loss=0.03879): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (11447 / 25000 Steps) (loss=0.03203): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (11450 / 25000 Steps) (loss=0.04813): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (11453 / 25000 Steps) (loss=0.04334): 100%|██████████| 3/3 [00:01<00:00,  2.02it/s]\n",
      "Training (11456 / 25000 Steps) (loss=0.04380): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (11459 / 25000 Steps) (loss=0.04855): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (11462 / 25000 Steps) (loss=0.04401): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (11465 / 25000 Steps) (loss=0.04350): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (11468 / 25000 Steps) (loss=0.03754): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (11471 / 25000 Steps) (loss=0.04028): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (11474 / 25000 Steps) (loss=0.06103): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (11477 / 25000 Steps) (loss=0.03916): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (11480 / 25000 Steps) (loss=0.03595): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (11483 / 25000 Steps) (loss=0.04358): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (11486 / 25000 Steps) (loss=0.04011): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (11489 / 25000 Steps) (loss=0.04703): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (11492 / 25000 Steps) (loss=0.05280): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (11495 / 25000 Steps) (loss=0.02552): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "Training (11498 / 25000 Steps) (loss=0.03449): 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "Validate (11499 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]it]\n",
      "Training (11501 / 25000 Steps) (loss=0.04563):  67%|██████▋   | 2/3 [00:01<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (11501 / 25000 Steps) (loss=0.04563): 100%|██████████| 3/3 [00:02<00:00,  1.35it/s]\n",
      "Training (11504 / 25000 Steps) (loss=0.03759): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (11507 / 25000 Steps) (loss=0.03930): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (11510 / 25000 Steps) (loss=0.03042): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (11513 / 25000 Steps) (loss=0.03497): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (11516 / 25000 Steps) (loss=0.02997): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (11519 / 25000 Steps) (loss=0.03327): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (11522 / 25000 Steps) (loss=0.03970): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (11525 / 25000 Steps) (loss=0.05683): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (11528 / 25000 Steps) (loss=0.03574): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (11531 / 25000 Steps) (loss=0.03546): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (11534 / 25000 Steps) (loss=0.05168): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (11537 / 25000 Steps) (loss=0.04019): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (11540 / 25000 Steps) (loss=0.03919): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (11543 / 25000 Steps) (loss=0.04280): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (11546 / 25000 Steps) (loss=0.03206): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (11549 / 25000 Steps) (loss=0.03515): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (11552 / 25000 Steps) (loss=0.03436): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (11555 / 25000 Steps) (loss=0.03910): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (11558 / 25000 Steps) (loss=0.03393): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (11561 / 25000 Steps) (loss=0.04308): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (11564 / 25000 Steps) (loss=0.04267): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (11567 / 25000 Steps) (loss=0.04747): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (11570 / 25000 Steps) (loss=0.03169): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (11573 / 25000 Steps) (loss=0.03997): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (11576 / 25000 Steps) (loss=0.03894): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (11579 / 25000 Steps) (loss=0.03765): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (11582 / 25000 Steps) (loss=0.03436): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (11585 / 25000 Steps) (loss=0.03665): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (11588 / 25000 Steps) (loss=0.04020): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (11591 / 25000 Steps) (loss=0.03977): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (11594 / 25000 Steps) (loss=0.03476): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (11597 / 25000 Steps) (loss=0.03484): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (11600 / 25000 Steps) (loss=0.05017): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (11603 / 25000 Steps) (loss=0.03817): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (11606 / 25000 Steps) (loss=0.03953): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (11609 / 25000 Steps) (loss=0.03314): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (11612 / 25000 Steps) (loss=0.03531): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (11615 / 25000 Steps) (loss=0.05835): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (11618 / 25000 Steps) (loss=0.03660): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (11621 / 25000 Steps) (loss=0.03876): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (11624 / 25000 Steps) (loss=0.04238): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (11627 / 25000 Steps) (loss=0.03971): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (11630 / 25000 Steps) (loss=0.03680): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (11633 / 25000 Steps) (loss=0.03409): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (11636 / 25000 Steps) (loss=0.03708): 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "Training (11639 / 25000 Steps) (loss=0.03468): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (11642 / 25000 Steps) (loss=0.03941): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (11645 / 25000 Steps) (loss=0.04127): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (11648 / 25000 Steps) (loss=0.03785): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (11651 / 25000 Steps) (loss=0.04433): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (11654 / 25000 Steps) (loss=0.04478): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (11657 / 25000 Steps) (loss=0.03276): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (11660 / 25000 Steps) (loss=0.04351): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (11663 / 25000 Steps) (loss=0.03694): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (11666 / 25000 Steps) (loss=0.02799): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (11669 / 25000 Steps) (loss=0.03941): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (11672 / 25000 Steps) (loss=0.02895): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (11675 / 25000 Steps) (loss=0.03172): 100%|██████████| 3/3 [00:02<00:00,  1.35it/s]\n",
      "Training (11678 / 25000 Steps) (loss=0.03967): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (11681 / 25000 Steps) (loss=0.03904): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (11684 / 25000 Steps) (loss=0.03548): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (11687 / 25000 Steps) (loss=0.02737): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (11690 / 25000 Steps) (loss=0.04232): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (11693 / 25000 Steps) (loss=0.05797): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (11696 / 25000 Steps) (loss=0.03413): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "Training (11699 / 25000 Steps) (loss=0.04926): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (11702 / 25000 Steps) (loss=0.04753): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (11705 / 25000 Steps) (loss=0.04236): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (11708 / 25000 Steps) (loss=0.03728): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (11711 / 25000 Steps) (loss=0.03278): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (11714 / 25000 Steps) (loss=0.05156): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (11717 / 25000 Steps) (loss=0.05445): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (11720 / 25000 Steps) (loss=0.04018): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (11723 / 25000 Steps) (loss=0.04099): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (11726 / 25000 Steps) (loss=0.04697): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (11729 / 25000 Steps) (loss=0.03063): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (11732 / 25000 Steps) (loss=0.03196): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (11735 / 25000 Steps) (loss=0.04238): 100%|██████████| 3/3 [00:02<00:00,  1.14it/s]\n",
      "Training (11738 / 25000 Steps) (loss=0.04929): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (11741 / 25000 Steps) (loss=0.03708): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (11744 / 25000 Steps) (loss=0.03623): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (11747 / 25000 Steps) (loss=0.04821): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (11750 / 25000 Steps) (loss=0.03249): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (11753 / 25000 Steps) (loss=0.05320): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (11756 / 25000 Steps) (loss=0.03805): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (11759 / 25000 Steps) (loss=0.06426): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (11762 / 25000 Steps) (loss=0.05022): 100%|██████████| 3/3 [00:01<00:00,  2.00it/s]\n",
      "Training (11765 / 25000 Steps) (loss=0.04900): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (11768 / 25000 Steps) (loss=0.04312): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (11771 / 25000 Steps) (loss=0.03636): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (11774 / 25000 Steps) (loss=0.04814): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (11777 / 25000 Steps) (loss=0.03667): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (11780 / 25000 Steps) (loss=0.04354): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (11783 / 25000 Steps) (loss=0.03159): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (11786 / 25000 Steps) (loss=0.03349): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (11789 / 25000 Steps) (loss=0.05409): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (11792 / 25000 Steps) (loss=0.04359): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (11795 / 25000 Steps) (loss=0.02330): 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]\n",
      "Training (11798 / 25000 Steps) (loss=0.04167): 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
      "Training (11801 / 25000 Steps) (loss=0.04520): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (11804 / 25000 Steps) (loss=0.03203): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (11807 / 25000 Steps) (loss=0.05310): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (11810 / 25000 Steps) (loss=0.03891): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (11813 / 25000 Steps) (loss=0.03228): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (11816 / 25000 Steps) (loss=0.04043): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (11819 / 25000 Steps) (loss=0.04377): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (11822 / 25000 Steps) (loss=0.05244): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (11825 / 25000 Steps) (loss=0.03699): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (11828 / 25000 Steps) (loss=0.04389): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (11831 / 25000 Steps) (loss=0.04167): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (11834 / 25000 Steps) (loss=0.03571): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (11837 / 25000 Steps) (loss=0.02779): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (11840 / 25000 Steps) (loss=0.03790): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (11843 / 25000 Steps) (loss=0.03988): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (11846 / 25000 Steps) (loss=0.03229): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (11849 / 25000 Steps) (loss=0.03632): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (11852 / 25000 Steps) (loss=0.04233): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (11855 / 25000 Steps) (loss=0.03285): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (11858 / 25000 Steps) (loss=0.03627): 100%|██████████| 3/3 [00:02<00:00,  1.05it/s]\n",
      "Training (11861 / 25000 Steps) (loss=0.03213): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (11864 / 25000 Steps) (loss=0.03468): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (11867 / 25000 Steps) (loss=0.03669): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (11870 / 25000 Steps) (loss=0.03687): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (11873 / 25000 Steps) (loss=0.05614): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (11876 / 25000 Steps) (loss=0.04475): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (11879 / 25000 Steps) (loss=0.04653): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (11882 / 25000 Steps) (loss=0.04055): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (11885 / 25000 Steps) (loss=0.03294): 100%|██████████| 3/3 [00:02<00:00,  1.19it/s]\n",
      "Training (11888 / 25000 Steps) (loss=0.04430): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (11891 / 25000 Steps) (loss=0.03452): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (11894 / 25000 Steps) (loss=0.03101): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (11897 / 25000 Steps) (loss=0.02731): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (11900 / 25000 Steps) (loss=0.03670): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (11903 / 25000 Steps) (loss=0.03817): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (11906 / 25000 Steps) (loss=0.04611): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (11909 / 25000 Steps) (loss=0.02940): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (11912 / 25000 Steps) (loss=0.03113): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (11915 / 25000 Steps) (loss=0.04620): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (11918 / 25000 Steps) (loss=0.03430): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (11921 / 25000 Steps) (loss=0.04570): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (11924 / 25000 Steps) (loss=0.04574): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (11927 / 25000 Steps) (loss=0.03576): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (11930 / 25000 Steps) (loss=0.04349): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (11933 / 25000 Steps) (loss=0.04624): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (11936 / 25000 Steps) (loss=0.04046): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (11939 / 25000 Steps) (loss=0.04297): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (11942 / 25000 Steps) (loss=0.03200): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (11945 / 25000 Steps) (loss=0.04525): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (11948 / 25000 Steps) (loss=0.04592): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (11951 / 25000 Steps) (loss=0.04602): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (11954 / 25000 Steps) (loss=0.04690): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (11957 / 25000 Steps) (loss=0.04252): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (11960 / 25000 Steps) (loss=0.05369): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (11963 / 25000 Steps) (loss=0.04401): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (11966 / 25000 Steps) (loss=0.04733): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (11969 / 25000 Steps) (loss=0.04045): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (11972 / 25000 Steps) (loss=0.05147): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (11975 / 25000 Steps) (loss=0.04372): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (11978 / 25000 Steps) (loss=0.04412): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (11981 / 25000 Steps) (loss=0.06466): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (11984 / 25000 Steps) (loss=0.04269): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (11987 / 25000 Steps) (loss=0.02859): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (11990 / 25000 Steps) (loss=0.03172): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (11993 / 25000 Steps) (loss=0.03751): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (11996 / 25000 Steps) (loss=0.03533): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (11999 / 25000 Steps) (loss=0.02729): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Validate (12000 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.82it/s]\n",
      "Training (12002 / 25000 Steps) (loss=0.05685): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (12002 / 25000 Steps) (loss=0.05685): 100%|██████████| 3/3 [00:02<00:00,  1.10it/s]\n",
      "Training (12005 / 25000 Steps) (loss=0.04223): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (12008 / 25000 Steps) (loss=0.03304): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (12011 / 25000 Steps) (loss=0.03345): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (12014 / 25000 Steps) (loss=0.04282): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (12017 / 25000 Steps) (loss=0.03690): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (12020 / 25000 Steps) (loss=0.03736): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (12023 / 25000 Steps) (loss=0.03565): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (12026 / 25000 Steps) (loss=0.05108): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (12029 / 25000 Steps) (loss=0.03848): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (12032 / 25000 Steps) (loss=0.03830): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (12035 / 25000 Steps) (loss=0.03097): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (12038 / 25000 Steps) (loss=0.04293): 100%|██████████| 3/3 [00:02<00:00,  1.03it/s]\n",
      "Training (12041 / 25000 Steps) (loss=0.03298): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (12044 / 25000 Steps) (loss=0.04597): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (12047 / 25000 Steps) (loss=0.04353): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (12050 / 25000 Steps) (loss=0.04476): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (12053 / 25000 Steps) (loss=0.04193): 100%|██████████| 3/3 [00:01<00:00,  2.03it/s]\n",
      "Training (12056 / 25000 Steps) (loss=0.04121): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (12059 / 25000 Steps) (loss=0.03965): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (12062 / 25000 Steps) (loss=0.05627): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (12065 / 25000 Steps) (loss=0.03358): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (12068 / 25000 Steps) (loss=0.03295): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (12071 / 25000 Steps) (loss=0.03823): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (12074 / 25000 Steps) (loss=0.04285): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (12077 / 25000 Steps) (loss=0.03141): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (12080 / 25000 Steps) (loss=0.04798): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (12083 / 25000 Steps) (loss=0.04482): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (12086 / 25000 Steps) (loss=0.03620): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (12089 / 25000 Steps) (loss=0.05006): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (12092 / 25000 Steps) (loss=0.03883): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (12095 / 25000 Steps) (loss=0.03108): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (12098 / 25000 Steps) (loss=0.04186): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (12101 / 25000 Steps) (loss=0.04353): 100%|██████████| 3/3 [00:02<00:00,  1.04it/s]\n",
      "Training (12104 / 25000 Steps) (loss=0.03883): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (12107 / 25000 Steps) (loss=0.04125): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (12110 / 25000 Steps) (loss=0.05020): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (12113 / 25000 Steps) (loss=0.03017): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (12116 / 25000 Steps) (loss=0.05053): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (12119 / 25000 Steps) (loss=0.03514): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (12122 / 25000 Steps) (loss=0.04112): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (12125 / 25000 Steps) (loss=0.03916): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (12128 / 25000 Steps) (loss=0.02961): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (12131 / 25000 Steps) (loss=0.04529): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (12134 / 25000 Steps) (loss=0.03103): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (12137 / 25000 Steps) (loss=0.02513): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (12140 / 25000 Steps) (loss=0.04422): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (12143 / 25000 Steps) (loss=0.03480): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (12146 / 25000 Steps) (loss=0.05827): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (12149 / 25000 Steps) (loss=0.03417): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (12152 / 25000 Steps) (loss=0.03340): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (12155 / 25000 Steps) (loss=0.04203): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (12158 / 25000 Steps) (loss=0.03742): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (12161 / 25000 Steps) (loss=0.04103): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (12164 / 25000 Steps) (loss=0.03986): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (12167 / 25000 Steps) (loss=0.03554): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (12170 / 25000 Steps) (loss=0.02765): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (12173 / 25000 Steps) (loss=0.03219): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (12176 / 25000 Steps) (loss=0.04074): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (12179 / 25000 Steps) (loss=0.03850): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (12182 / 25000 Steps) (loss=0.03025): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (12185 / 25000 Steps) (loss=0.04324): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (12188 / 25000 Steps) (loss=0.03401): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (12191 / 25000 Steps) (loss=0.04259): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (12194 / 25000 Steps) (loss=0.03453): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (12197 / 25000 Steps) (loss=0.03271): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (12200 / 25000 Steps) (loss=0.02994): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (12203 / 25000 Steps) (loss=0.04296): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (12206 / 25000 Steps) (loss=0.03122): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (12209 / 25000 Steps) (loss=0.05588): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (12212 / 25000 Steps) (loss=0.04428): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "Training (12215 / 25000 Steps) (loss=0.02497): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (12218 / 25000 Steps) (loss=0.04362): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (12221 / 25000 Steps) (loss=0.03136): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (12224 / 25000 Steps) (loss=0.04906): 100%|██████████| 3/3 [00:02<00:00,  1.06it/s]\n",
      "Training (12227 / 25000 Steps) (loss=0.03680): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (12230 / 25000 Steps) (loss=0.03114): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (12233 / 25000 Steps) (loss=0.04558): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (12236 / 25000 Steps) (loss=0.03643): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (12239 / 25000 Steps) (loss=0.04262): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (12242 / 25000 Steps) (loss=0.02654): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (12245 / 25000 Steps) (loss=0.03212): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (12248 / 25000 Steps) (loss=0.04385): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (12251 / 25000 Steps) (loss=0.03125): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (12254 / 25000 Steps) (loss=0.03096): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (12257 / 25000 Steps) (loss=0.03800): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (12260 / 25000 Steps) (loss=0.03327): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (12263 / 25000 Steps) (loss=0.04772): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (12266 / 25000 Steps) (loss=0.03282): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (12269 / 25000 Steps) (loss=0.03249): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (12272 / 25000 Steps) (loss=0.02571): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (12275 / 25000 Steps) (loss=0.04033): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (12278 / 25000 Steps) (loss=0.03699): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (12281 / 25000 Steps) (loss=0.03996): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (12284 / 25000 Steps) (loss=0.05091): 100%|██████████| 3/3 [00:02<00:00,  1.16it/s]\n",
      "Training (12287 / 25000 Steps) (loss=0.03473): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (12290 / 25000 Steps) (loss=0.03869): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (12293 / 25000 Steps) (loss=0.04083): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (12296 / 25000 Steps) (loss=0.03345): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (12299 / 25000 Steps) (loss=0.03084): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (12302 / 25000 Steps) (loss=0.03628): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (12305 / 25000 Steps) (loss=0.04341): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (12308 / 25000 Steps) (loss=0.02458): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (12311 / 25000 Steps) (loss=0.04258): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (12314 / 25000 Steps) (loss=0.05354): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (12317 / 25000 Steps) (loss=0.04672): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (12320 / 25000 Steps) (loss=0.03474): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (12323 / 25000 Steps) (loss=0.02483): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (12326 / 25000 Steps) (loss=0.03670): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (12329 / 25000 Steps) (loss=0.03234): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (12332 / 25000 Steps) (loss=0.03815): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (12335 / 25000 Steps) (loss=0.03659): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (12338 / 25000 Steps) (loss=0.04047): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (12341 / 25000 Steps) (loss=0.03844): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (12344 / 25000 Steps) (loss=0.04464): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (12347 / 25000 Steps) (loss=0.03026): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (12350 / 25000 Steps) (loss=0.03663): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (12353 / 25000 Steps) (loss=0.03646): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (12356 / 25000 Steps) (loss=0.02593): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (12359 / 25000 Steps) (loss=0.03742): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (12362 / 25000 Steps) (loss=0.03790): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (12365 / 25000 Steps) (loss=0.02706): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (12368 / 25000 Steps) (loss=0.02707): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (12371 / 25000 Steps) (loss=0.02820): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (12374 / 25000 Steps) (loss=0.03349): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (12377 / 25000 Steps) (loss=0.03317): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (12380 / 25000 Steps) (loss=0.03549): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (12383 / 25000 Steps) (loss=0.04007): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (12386 / 25000 Steps) (loss=0.03601): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (12389 / 25000 Steps) (loss=0.03818): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (12392 / 25000 Steps) (loss=0.04162): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (12395 / 25000 Steps) (loss=0.04827): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (12398 / 25000 Steps) (loss=0.03777): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (12401 / 25000 Steps) (loss=0.04326): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (12404 / 25000 Steps) (loss=0.04484): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (12407 / 25000 Steps) (loss=0.03628): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (12410 / 25000 Steps) (loss=0.04420): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (12413 / 25000 Steps) (loss=0.02945): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (12416 / 25000 Steps) (loss=0.02307): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (12419 / 25000 Steps) (loss=0.04196): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (12422 / 25000 Steps) (loss=0.04020): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (12425 / 25000 Steps) (loss=0.03456): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (12428 / 25000 Steps) (loss=0.03383): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (12431 / 25000 Steps) (loss=0.03340): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (12434 / 25000 Steps) (loss=0.02614): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (12437 / 25000 Steps) (loss=0.03719): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (12440 / 25000 Steps) (loss=0.03268): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (12443 / 25000 Steps) (loss=0.02916): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (12446 / 25000 Steps) (loss=0.04839): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (12449 / 25000 Steps) (loss=0.04090): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (12452 / 25000 Steps) (loss=0.03733): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (12455 / 25000 Steps) (loss=0.02740): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (12458 / 25000 Steps) (loss=0.02625): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (12461 / 25000 Steps) (loss=0.02570): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (12464 / 25000 Steps) (loss=0.03667): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (12467 / 25000 Steps) (loss=0.05383): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (12470 / 25000 Steps) (loss=0.04743): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (12473 / 25000 Steps) (loss=0.03230): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (12476 / 25000 Steps) (loss=0.03047): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (12479 / 25000 Steps) (loss=0.05056): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (12482 / 25000 Steps) (loss=0.03885): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (12485 / 25000 Steps) (loss=0.03802): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (12488 / 25000 Steps) (loss=0.03642): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (12491 / 25000 Steps) (loss=0.03745): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (12494 / 25000 Steps) (loss=0.03748): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (12497 / 25000 Steps) (loss=0.05344): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Validate (12498 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]it]\n",
      "Training (12500 / 25000 Steps) (loss=0.04006): 100%|██████████| 3/3 [00:02<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (12500 / 25000 Steps) (loss=0.04006): 100%|██████████| 3/3 [00:02<00:00,  1.25it/s]\n",
      "Training (12503 / 25000 Steps) (loss=0.02898): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (12506 / 25000 Steps) (loss=0.02780): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (12509 / 25000 Steps) (loss=0.04155): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (12512 / 25000 Steps) (loss=0.05522): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (12515 / 25000 Steps) (loss=0.04460): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (12518 / 25000 Steps) (loss=0.04503): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (12521 / 25000 Steps) (loss=0.03872): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (12524 / 25000 Steps) (loss=0.03253): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (12527 / 25000 Steps) (loss=0.05061): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (12530 / 25000 Steps) (loss=0.03787): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (12533 / 25000 Steps) (loss=0.04391): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (12536 / 25000 Steps) (loss=0.04641): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (12539 / 25000 Steps) (loss=0.02897): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (12542 / 25000 Steps) (loss=0.02519): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (12545 / 25000 Steps) (loss=0.03205): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (12548 / 25000 Steps) (loss=0.02797): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (12551 / 25000 Steps) (loss=0.02422): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (12554 / 25000 Steps) (loss=0.03201): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (12557 / 25000 Steps) (loss=0.04085): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (12560 / 25000 Steps) (loss=0.02901): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (12563 / 25000 Steps) (loss=0.03570): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (12566 / 25000 Steps) (loss=0.04568): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (12569 / 25000 Steps) (loss=0.02678): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (12572 / 25000 Steps) (loss=0.03704): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (12575 / 25000 Steps) (loss=0.03379): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (12578 / 25000 Steps) (loss=0.03403): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (12581 / 25000 Steps) (loss=0.03627): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (12584 / 25000 Steps) (loss=0.03406): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (12587 / 25000 Steps) (loss=0.03833): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (12590 / 25000 Steps) (loss=0.04728): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (12593 / 25000 Steps) (loss=0.03462): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (12596 / 25000 Steps) (loss=0.04267): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (12599 / 25000 Steps) (loss=0.03785): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (12602 / 25000 Steps) (loss=0.04545): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (12605 / 25000 Steps) (loss=0.03573): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (12608 / 25000 Steps) (loss=0.04088): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (12611 / 25000 Steps) (loss=0.04007): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (12614 / 25000 Steps) (loss=0.03884): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (12617 / 25000 Steps) (loss=0.04177): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (12620 / 25000 Steps) (loss=0.04152): 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
      "Training (12623 / 25000 Steps) (loss=0.03856): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (12626 / 25000 Steps) (loss=0.03885): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (12629 / 25000 Steps) (loss=0.04840): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (12632 / 25000 Steps) (loss=0.04226): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (12635 / 25000 Steps) (loss=0.04169): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (12638 / 25000 Steps) (loss=0.04093): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (12641 / 25000 Steps) (loss=0.03639): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (12644 / 25000 Steps) (loss=0.06295): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (12647 / 25000 Steps) (loss=0.03151): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (12650 / 25000 Steps) (loss=0.02935): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (12653 / 25000 Steps) (loss=0.04057): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (12656 / 25000 Steps) (loss=0.03490): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (12659 / 25000 Steps) (loss=0.03993): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (12662 / 25000 Steps) (loss=0.04370): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (12665 / 25000 Steps) (loss=0.03409): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (12668 / 25000 Steps) (loss=0.04841): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (12671 / 25000 Steps) (loss=0.04044): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (12674 / 25000 Steps) (loss=0.03757): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (12677 / 25000 Steps) (loss=0.03185): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (12680 / 25000 Steps) (loss=0.03067): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (12683 / 25000 Steps) (loss=0.03619): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (12686 / 25000 Steps) (loss=0.02649): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (12689 / 25000 Steps) (loss=0.04162): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (12692 / 25000 Steps) (loss=0.04088): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (12695 / 25000 Steps) (loss=0.03012): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (12698 / 25000 Steps) (loss=0.03061): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (12701 / 25000 Steps) (loss=0.03601): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (12704 / 25000 Steps) (loss=0.06495): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (12707 / 25000 Steps) (loss=0.03198): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (12710 / 25000 Steps) (loss=0.04760): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (12713 / 25000 Steps) (loss=0.04267): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (12716 / 25000 Steps) (loss=0.02757): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (12719 / 25000 Steps) (loss=0.03429): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (12722 / 25000 Steps) (loss=0.04160): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (12725 / 25000 Steps) (loss=0.03883): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (12728 / 25000 Steps) (loss=0.03587): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (12731 / 25000 Steps) (loss=0.03252): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (12734 / 25000 Steps) (loss=0.03279): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (12737 / 25000 Steps) (loss=0.02829): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (12740 / 25000 Steps) (loss=0.03446): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (12743 / 25000 Steps) (loss=0.03984): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (12746 / 25000 Steps) (loss=0.03830): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (12749 / 25000 Steps) (loss=0.03402): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (12752 / 25000 Steps) (loss=0.03800): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (12755 / 25000 Steps) (loss=0.04302): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (12758 / 25000 Steps) (loss=0.03548): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (12761 / 25000 Steps) (loss=0.04275): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (12764 / 25000 Steps) (loss=0.05042): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (12767 / 25000 Steps) (loss=0.05717): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (12770 / 25000 Steps) (loss=0.03495): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (12773 / 25000 Steps) (loss=0.04206): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (12776 / 25000 Steps) (loss=0.03997): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (12779 / 25000 Steps) (loss=0.03032): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (12782 / 25000 Steps) (loss=0.03535): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (12785 / 25000 Steps) (loss=0.04078): 100%|██████████| 3/3 [00:02<00:00,  1.05it/s]\n",
      "Training (12788 / 25000 Steps) (loss=0.04229): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (12791 / 25000 Steps) (loss=0.03245): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (12794 / 25000 Steps) (loss=0.03757): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (12797 / 25000 Steps) (loss=0.03429): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (12800 / 25000 Steps) (loss=0.03010): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (12803 / 25000 Steps) (loss=0.03219): 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "Training (12806 / 25000 Steps) (loss=0.04013): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (12809 / 25000 Steps) (loss=0.03216): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (12812 / 25000 Steps) (loss=0.03302): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (12815 / 25000 Steps) (loss=0.04623): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (12818 / 25000 Steps) (loss=0.03836): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (12821 / 25000 Steps) (loss=0.05247): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (12824 / 25000 Steps) (loss=0.03303): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (12827 / 25000 Steps) (loss=0.05374): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (12830 / 25000 Steps) (loss=0.03038): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (12833 / 25000 Steps) (loss=0.03905): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (12836 / 25000 Steps) (loss=0.03430): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (12839 / 25000 Steps) (loss=0.02472): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (12842 / 25000 Steps) (loss=0.03711): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (12845 / 25000 Steps) (loss=0.05024): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (12848 / 25000 Steps) (loss=0.03226): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (12851 / 25000 Steps) (loss=0.03787): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (12854 / 25000 Steps) (loss=0.03132): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (12857 / 25000 Steps) (loss=0.03615): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (12860 / 25000 Steps) (loss=0.03934): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (12863 / 25000 Steps) (loss=0.03593): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (12866 / 25000 Steps) (loss=0.03885): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (12869 / 25000 Steps) (loss=0.03115): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (12872 / 25000 Steps) (loss=0.04209): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (12875 / 25000 Steps) (loss=0.03114): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (12878 / 25000 Steps) (loss=0.03315): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (12881 / 25000 Steps) (loss=0.03084): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (12884 / 25000 Steps) (loss=0.03209): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (12887 / 25000 Steps) (loss=0.03802): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (12890 / 25000 Steps) (loss=0.03657): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (12893 / 25000 Steps) (loss=0.02842): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (12896 / 25000 Steps) (loss=0.03377): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (12899 / 25000 Steps) (loss=0.03136): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (12902 / 25000 Steps) (loss=0.02654): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (12905 / 25000 Steps) (loss=0.02904): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (12908 / 25000 Steps) (loss=0.04125): 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]\n",
      "Training (12911 / 25000 Steps) (loss=0.03234): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (12914 / 25000 Steps) (loss=0.02648): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (12917 / 25000 Steps) (loss=0.03401): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (12920 / 25000 Steps) (loss=0.02943): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (12923 / 25000 Steps) (loss=0.02393): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (12926 / 25000 Steps) (loss=0.03857): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (12929 / 25000 Steps) (loss=0.03820): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (12932 / 25000 Steps) (loss=0.03130): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (12935 / 25000 Steps) (loss=0.04712): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (12938 / 25000 Steps) (loss=0.03585): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (12941 / 25000 Steps) (loss=0.04115): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (12944 / 25000 Steps) (loss=0.04742): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (12947 / 25000 Steps) (loss=0.03637): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (12950 / 25000 Steps) (loss=0.02835): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (12953 / 25000 Steps) (loss=0.04214): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (12956 / 25000 Steps) (loss=0.04072): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (12959 / 25000 Steps) (loss=0.03122): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (12962 / 25000 Steps) (loss=0.04013): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (12965 / 25000 Steps) (loss=0.02733): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (12968 / 25000 Steps) (loss=0.03886): 100%|██████████| 3/3 [00:02<00:00,  1.35it/s]\n",
      "Training (12971 / 25000 Steps) (loss=0.04431): 100%|██████████| 3/3 [00:01<00:00,  1.98it/s]\n",
      "Training (12974 / 25000 Steps) (loss=0.03626): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (12977 / 25000 Steps) (loss=0.05102): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (12980 / 25000 Steps) (loss=0.03386): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (12983 / 25000 Steps) (loss=0.03170): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (12986 / 25000 Steps) (loss=0.02659): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (12989 / 25000 Steps) (loss=0.03456): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (12992 / 25000 Steps) (loss=0.02623): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (12995 / 25000 Steps) (loss=0.02897): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (12998 / 25000 Steps) (loss=0.03275): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Validate (12999 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]it]\n",
      "Training (13001 / 25000 Steps) (loss=0.03656):  67%|██████▋   | 2/3 [00:02<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (13001 / 25000 Steps) (loss=0.03656): 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
      "Training (13004 / 25000 Steps) (loss=0.03384): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (13007 / 25000 Steps) (loss=0.03257): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (13010 / 25000 Steps) (loss=0.05659): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (13013 / 25000 Steps) (loss=0.03141): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (13016 / 25000 Steps) (loss=0.03152): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (13019 / 25000 Steps) (loss=0.03244): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (13022 / 25000 Steps) (loss=0.04393): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (13025 / 25000 Steps) (loss=0.05586): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (13028 / 25000 Steps) (loss=0.03325): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (13031 / 25000 Steps) (loss=0.04325): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (13034 / 25000 Steps) (loss=0.04374): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (13037 / 25000 Steps) (loss=0.03092): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (13040 / 25000 Steps) (loss=0.04072): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (13043 / 25000 Steps) (loss=0.03659): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (13046 / 25000 Steps) (loss=0.04394): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (13049 / 25000 Steps) (loss=0.04089): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (13052 / 25000 Steps) (loss=0.03867): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (13055 / 25000 Steps) (loss=0.03865): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (13058 / 25000 Steps) (loss=0.04217): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (13061 / 25000 Steps) (loss=0.03839): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (13064 / 25000 Steps) (loss=0.04916): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (13067 / 25000 Steps) (loss=0.03799): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (13070 / 25000 Steps) (loss=0.03507): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (13073 / 25000 Steps) (loss=0.03104): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (13076 / 25000 Steps) (loss=0.03957): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (13079 / 25000 Steps) (loss=0.03188): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (13082 / 25000 Steps) (loss=0.03687): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (13085 / 25000 Steps) (loss=0.03235): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (13088 / 25000 Steps) (loss=0.03336): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (13091 / 25000 Steps) (loss=0.05312): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (13094 / 25000 Steps) (loss=0.03061): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "Training (13097 / 25000 Steps) (loss=0.02857): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (13100 / 25000 Steps) (loss=0.03380): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (13103 / 25000 Steps) (loss=0.03301): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (13106 / 25000 Steps) (loss=0.02182): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (13109 / 25000 Steps) (loss=0.03483): 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]\n",
      "Training (13112 / 25000 Steps) (loss=0.03636): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (13115 / 25000 Steps) (loss=0.02668): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (13118 / 25000 Steps) (loss=0.03317): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (13121 / 25000 Steps) (loss=0.03335): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (13124 / 25000 Steps) (loss=0.04132): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (13127 / 25000 Steps) (loss=0.03739): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (13130 / 25000 Steps) (loss=0.03205): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (13133 / 25000 Steps) (loss=0.03887): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (13136 / 25000 Steps) (loss=0.03908): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (13139 / 25000 Steps) (loss=0.03519): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (13142 / 25000 Steps) (loss=0.03502): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (13145 / 25000 Steps) (loss=0.04529): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (13148 / 25000 Steps) (loss=0.02354): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (13151 / 25000 Steps) (loss=0.03921): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (13154 / 25000 Steps) (loss=0.02498): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (13157 / 25000 Steps) (loss=0.03414): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (13160 / 25000 Steps) (loss=0.03090): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (13163 / 25000 Steps) (loss=0.03719): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (13166 / 25000 Steps) (loss=0.04097): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (13169 / 25000 Steps) (loss=0.03231): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (13172 / 25000 Steps) (loss=0.04390): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (13175 / 25000 Steps) (loss=0.03261): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (13178 / 25000 Steps) (loss=0.03788): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (13181 / 25000 Steps) (loss=0.04703): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (13184 / 25000 Steps) (loss=0.03528): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (13187 / 25000 Steps) (loss=0.03089): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (13190 / 25000 Steps) (loss=0.03007): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (13193 / 25000 Steps) (loss=0.03553): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (13196 / 25000 Steps) (loss=0.04013): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (13199 / 25000 Steps) (loss=0.04121): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (13202 / 25000 Steps) (loss=0.03114): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (13205 / 25000 Steps) (loss=0.03500): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (13208 / 25000 Steps) (loss=0.03819): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (13211 / 25000 Steps) (loss=0.04484): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (13214 / 25000 Steps) (loss=0.03522): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (13217 / 25000 Steps) (loss=0.03576): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (13220 / 25000 Steps) (loss=0.03724): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (13223 / 25000 Steps) (loss=0.04309): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (13226 / 25000 Steps) (loss=0.02965): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (13229 / 25000 Steps) (loss=0.04134): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (13232 / 25000 Steps) (loss=0.04208): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (13235 / 25000 Steps) (loss=0.03886): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (13238 / 25000 Steps) (loss=0.03374): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (13241 / 25000 Steps) (loss=0.03427): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (13244 / 25000 Steps) (loss=0.04166): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (13247 / 25000 Steps) (loss=0.04396): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (13250 / 25000 Steps) (loss=0.03305): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (13253 / 25000 Steps) (loss=0.03287): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (13256 / 25000 Steps) (loss=0.03025): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (13259 / 25000 Steps) (loss=0.03835): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (13262 / 25000 Steps) (loss=0.03560): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (13265 / 25000 Steps) (loss=0.03128): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (13268 / 25000 Steps) (loss=0.02284): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (13271 / 25000 Steps) (loss=0.03444): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (13274 / 25000 Steps) (loss=0.03945): 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "Training (13277 / 25000 Steps) (loss=0.02835): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (13280 / 25000 Steps) (loss=0.04274): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (13283 / 25000 Steps) (loss=0.03233): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (13286 / 25000 Steps) (loss=0.03689): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (13289 / 25000 Steps) (loss=0.03873): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (13292 / 25000 Steps) (loss=0.02718): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (13295 / 25000 Steps) (loss=0.02764): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (13298 / 25000 Steps) (loss=0.03111): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (13301 / 25000 Steps) (loss=0.04466): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (13304 / 25000 Steps) (loss=0.04232): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (13307 / 25000 Steps) (loss=0.02915): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (13310 / 25000 Steps) (loss=0.03019): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (13313 / 25000 Steps) (loss=0.03095): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (13316 / 25000 Steps) (loss=0.02807): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (13319 / 25000 Steps) (loss=0.03479): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (13322 / 25000 Steps) (loss=0.02684): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (13325 / 25000 Steps) (loss=0.03557): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (13328 / 25000 Steps) (loss=0.04073): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (13331 / 25000 Steps) (loss=0.02452): 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
      "Training (13334 / 25000 Steps) (loss=0.04770): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (13337 / 25000 Steps) (loss=0.02922): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (13340 / 25000 Steps) (loss=0.03095): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (13343 / 25000 Steps) (loss=0.03742): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (13346 / 25000 Steps) (loss=0.02861): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (13349 / 25000 Steps) (loss=0.02658): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (13352 / 25000 Steps) (loss=0.05632): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (13355 / 25000 Steps) (loss=0.02842): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (13358 / 25000 Steps) (loss=0.03558): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (13361 / 25000 Steps) (loss=0.03698): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (13364 / 25000 Steps) (loss=0.03113): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (13367 / 25000 Steps) (loss=0.04113): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (13370 / 25000 Steps) (loss=0.03196): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (13373 / 25000 Steps) (loss=0.03382): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (13376 / 25000 Steps) (loss=0.03178): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (13379 / 25000 Steps) (loss=0.03483): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (13382 / 25000 Steps) (loss=0.03421): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (13385 / 25000 Steps) (loss=0.03561): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (13388 / 25000 Steps) (loss=0.03512): 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "Training (13391 / 25000 Steps) (loss=0.02723): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (13394 / 25000 Steps) (loss=0.04078): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (13397 / 25000 Steps) (loss=0.04455): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (13400 / 25000 Steps) (loss=0.04011): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (13403 / 25000 Steps) (loss=0.04200): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (13406 / 25000 Steps) (loss=0.04472): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (13409 / 25000 Steps) (loss=0.03587): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (13412 / 25000 Steps) (loss=0.03416): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (13415 / 25000 Steps) (loss=0.04403): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (13418 / 25000 Steps) (loss=0.02918): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "Training (13421 / 25000 Steps) (loss=0.03513): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (13424 / 25000 Steps) (loss=0.03861): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (13427 / 25000 Steps) (loss=0.03063): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (13430 / 25000 Steps) (loss=0.03711): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (13433 / 25000 Steps) (loss=0.04015): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (13436 / 25000 Steps) (loss=0.03583): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (13439 / 25000 Steps) (loss=0.02990): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (13442 / 25000 Steps) (loss=0.03034): 100%|██████████| 3/3 [00:03<00:00,  1.03s/it]\n",
      "Training (13445 / 25000 Steps) (loss=0.03528): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (13448 / 25000 Steps) (loss=0.02923): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (13451 / 25000 Steps) (loss=0.03288): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (13454 / 25000 Steps) (loss=0.03125): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (13457 / 25000 Steps) (loss=0.03633): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (13460 / 25000 Steps) (loss=0.02507): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (13463 / 25000 Steps) (loss=0.03990): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (13466 / 25000 Steps) (loss=0.03593): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (13469 / 25000 Steps) (loss=0.02742): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (13472 / 25000 Steps) (loss=0.03453): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (13475 / 25000 Steps) (loss=0.03780): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (13478 / 25000 Steps) (loss=0.03987): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (13481 / 25000 Steps) (loss=0.04335): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (13484 / 25000 Steps) (loss=0.03260): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (13487 / 25000 Steps) (loss=0.03578): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (13490 / 25000 Steps) (loss=0.03321): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (13493 / 25000 Steps) (loss=0.03970): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (13496 / 25000 Steps) (loss=0.03123): 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
      "Training (13499 / 25000 Steps) (loss=0.05574): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Validate (13500 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "Training (13502 / 25000 Steps) (loss=0.04669): 100%|██████████| 3/3 [00:02<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (13502 / 25000 Steps) (loss=0.04669): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "Training (13505 / 25000 Steps) (loss=0.03037): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (13508 / 25000 Steps) (loss=0.03345): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (13511 / 25000 Steps) (loss=0.03679): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (13514 / 25000 Steps) (loss=0.03461): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (13517 / 25000 Steps) (loss=0.05299): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (13520 / 25000 Steps) (loss=0.04565): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (13523 / 25000 Steps) (loss=0.04802): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (13526 / 25000 Steps) (loss=0.04603): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (13529 / 25000 Steps) (loss=0.03877): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (13532 / 25000 Steps) (loss=0.03920): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (13535 / 25000 Steps) (loss=0.03211): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (13538 / 25000 Steps) (loss=0.03332): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (13541 / 25000 Steps) (loss=0.03645): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (13544 / 25000 Steps) (loss=0.03273): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (13547 / 25000 Steps) (loss=0.03188): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (13550 / 25000 Steps) (loss=0.04180): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (13553 / 25000 Steps) (loss=0.03386): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (13556 / 25000 Steps) (loss=0.03990): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (13559 / 25000 Steps) (loss=0.04973): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (13562 / 25000 Steps) (loss=0.03332): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (13565 / 25000 Steps) (loss=0.03808): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (13568 / 25000 Steps) (loss=0.04339): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (13571 / 25000 Steps) (loss=0.04279): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (13574 / 25000 Steps) (loss=0.04393): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (13577 / 25000 Steps) (loss=0.03454): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (13580 / 25000 Steps) (loss=0.03926): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (13583 / 25000 Steps) (loss=0.04022): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (13586 / 25000 Steps) (loss=0.02932): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (13589 / 25000 Steps) (loss=0.04387): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (13592 / 25000 Steps) (loss=0.04456): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (13595 / 25000 Steps) (loss=0.04117): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (13598 / 25000 Steps) (loss=0.03137): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (13601 / 25000 Steps) (loss=0.04576): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "Training (13604 / 25000 Steps) (loss=0.03595): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (13607 / 25000 Steps) (loss=0.03911): 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
      "Training (13610 / 25000 Steps) (loss=0.03879): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (13613 / 25000 Steps) (loss=0.03247): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (13616 / 25000 Steps) (loss=0.03314): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (13619 / 25000 Steps) (loss=0.02678): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (13622 / 25000 Steps) (loss=0.03405): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (13625 / 25000 Steps) (loss=0.03695): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (13628 / 25000 Steps) (loss=0.03580): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (13631 / 25000 Steps) (loss=0.03631): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (13634 / 25000 Steps) (loss=0.04351): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (13637 / 25000 Steps) (loss=0.04486): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (13640 / 25000 Steps) (loss=0.04447): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (13643 / 25000 Steps) (loss=0.04006): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (13646 / 25000 Steps) (loss=0.03522): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (13649 / 25000 Steps) (loss=0.03902): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (13652 / 25000 Steps) (loss=0.03775): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (13655 / 25000 Steps) (loss=0.03060): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (13658 / 25000 Steps) (loss=0.02857): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (13661 / 25000 Steps) (loss=0.03777): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (13664 / 25000 Steps) (loss=0.03251): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (13667 / 25000 Steps) (loss=0.03316): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (13670 / 25000 Steps) (loss=0.04041): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (13673 / 25000 Steps) (loss=0.03011): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (13676 / 25000 Steps) (loss=0.04390): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (13679 / 25000 Steps) (loss=0.05686): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (13682 / 25000 Steps) (loss=0.02649): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (13685 / 25000 Steps) (loss=0.04880): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (13688 / 25000 Steps) (loss=0.03812): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (13691 / 25000 Steps) (loss=0.03931): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (13694 / 25000 Steps) (loss=0.05143): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (13697 / 25000 Steps) (loss=0.03703): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (13700 / 25000 Steps) (loss=0.02650): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (13703 / 25000 Steps) (loss=0.02581): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (13706 / 25000 Steps) (loss=0.03312): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (13709 / 25000 Steps) (loss=0.02973): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (13712 / 25000 Steps) (loss=0.04586): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (13715 / 25000 Steps) (loss=0.02723): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (13718 / 25000 Steps) (loss=0.02885): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (13721 / 25000 Steps) (loss=0.03337): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (13724 / 25000 Steps) (loss=0.02641): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (13727 / 25000 Steps) (loss=0.05182): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (13730 / 25000 Steps) (loss=0.03574): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (13733 / 25000 Steps) (loss=0.04357): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (13736 / 25000 Steps) (loss=0.04807): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (13739 / 25000 Steps) (loss=0.03469): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (13742 / 25000 Steps) (loss=0.03914): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (13745 / 25000 Steps) (loss=0.04398): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (13748 / 25000 Steps) (loss=0.03023): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (13751 / 25000 Steps) (loss=0.03052): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (13754 / 25000 Steps) (loss=0.03028): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (13757 / 25000 Steps) (loss=0.02834): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (13760 / 25000 Steps) (loss=0.04122): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (13763 / 25000 Steps) (loss=0.03077): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (13766 / 25000 Steps) (loss=0.04953): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (13769 / 25000 Steps) (loss=0.02781): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (13772 / 25000 Steps) (loss=0.03514): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (13775 / 25000 Steps) (loss=0.03400): 100%|██████████| 3/3 [00:02<00:00,  1.24it/s]\n",
      "Training (13778 / 25000 Steps) (loss=0.02547): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (13781 / 25000 Steps) (loss=0.02745): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (13784 / 25000 Steps) (loss=0.03662): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (13787 / 25000 Steps) (loss=0.02802): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (13790 / 25000 Steps) (loss=0.03855): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (13793 / 25000 Steps) (loss=0.04743): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (13796 / 25000 Steps) (loss=0.03941): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (13799 / 25000 Steps) (loss=0.04128): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (13802 / 25000 Steps) (loss=0.02668): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (13805 / 25000 Steps) (loss=0.02765): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (13808 / 25000 Steps) (loss=0.03278): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (13811 / 25000 Steps) (loss=0.03614): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (13814 / 25000 Steps) (loss=0.03515): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (13817 / 25000 Steps) (loss=0.03311): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (13820 / 25000 Steps) (loss=0.03894): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (13823 / 25000 Steps) (loss=0.04893): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (13826 / 25000 Steps) (loss=0.05304): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (13829 / 25000 Steps) (loss=0.04466): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (13832 / 25000 Steps) (loss=0.05016): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (13835 / 25000 Steps) (loss=0.03474): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (13838 / 25000 Steps) (loss=0.03757): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (13841 / 25000 Steps) (loss=0.03759): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (13844 / 25000 Steps) (loss=0.02971): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (13847 / 25000 Steps) (loss=0.03787): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (13850 / 25000 Steps) (loss=0.03797): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (13853 / 25000 Steps) (loss=0.02652): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (13856 / 25000 Steps) (loss=0.04039): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (13859 / 25000 Steps) (loss=0.03526): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (13862 / 25000 Steps) (loss=0.03433): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (13865 / 25000 Steps) (loss=0.04092): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (13868 / 25000 Steps) (loss=0.03419): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (13871 / 25000 Steps) (loss=0.03837): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (13874 / 25000 Steps) (loss=0.03927): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (13877 / 25000 Steps) (loss=0.05166): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (13880 / 25000 Steps) (loss=0.04515): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (13883 / 25000 Steps) (loss=0.05752): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (13886 / 25000 Steps) (loss=0.04183): 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]\n",
      "Training (13889 / 25000 Steps) (loss=0.04512): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (13892 / 25000 Steps) (loss=0.03099): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (13895 / 25000 Steps) (loss=0.03675): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (13898 / 25000 Steps) (loss=0.03138): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (13901 / 25000 Steps) (loss=0.04019): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (13904 / 25000 Steps) (loss=0.04598): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (13907 / 25000 Steps) (loss=0.04039): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (13910 / 25000 Steps) (loss=0.04634): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (13913 / 25000 Steps) (loss=0.02720): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (13916 / 25000 Steps) (loss=0.03809): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (13919 / 25000 Steps) (loss=0.04066): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (13922 / 25000 Steps) (loss=0.06228): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (13925 / 25000 Steps) (loss=0.04413): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (13928 / 25000 Steps) (loss=0.03755): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (13931 / 25000 Steps) (loss=0.04543): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (13934 / 25000 Steps) (loss=0.03764): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (13937 / 25000 Steps) (loss=0.02355): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (13940 / 25000 Steps) (loss=0.04693): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (13943 / 25000 Steps) (loss=0.03094): 100%|██████████| 3/3 [00:03<00:00,  1.22s/it]\n",
      "Training (13946 / 25000 Steps) (loss=0.03295): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (13949 / 25000 Steps) (loss=0.03361): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (13952 / 25000 Steps) (loss=0.03675): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (13955 / 25000 Steps) (loss=0.04635): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (13958 / 25000 Steps) (loss=0.04453): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (13961 / 25000 Steps) (loss=0.03721): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (13964 / 25000 Steps) (loss=0.02812): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (13967 / 25000 Steps) (loss=0.04416): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (13970 / 25000 Steps) (loss=0.03277): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (13973 / 25000 Steps) (loss=0.04325): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (13976 / 25000 Steps) (loss=0.03481): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (13979 / 25000 Steps) (loss=0.03351): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (13982 / 25000 Steps) (loss=0.04960): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (13985 / 25000 Steps) (loss=0.03610): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (13988 / 25000 Steps) (loss=0.03027): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (13991 / 25000 Steps) (loss=0.03180): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (13994 / 25000 Steps) (loss=0.03593): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (13997 / 25000 Steps) (loss=0.02009): 100%|██████████| 3/3 [00:03<00:00,  1.00s/it]\n",
      "Validate (13998 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]/s]\n",
      "Training (14000 / 25000 Steps) (loss=0.04662): 100%|██████████| 3/3 [00:02<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (14000 / 25000 Steps) (loss=0.04662): 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
      "Training (14003 / 25000 Steps) (loss=0.03996): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (14006 / 25000 Steps) (loss=0.03339): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (14009 / 25000 Steps) (loss=0.03874): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (14012 / 25000 Steps) (loss=0.03185): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (14015 / 25000 Steps) (loss=0.04839): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (14018 / 25000 Steps) (loss=0.02663): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (14021 / 25000 Steps) (loss=0.03432): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (14024 / 25000 Steps) (loss=0.04081): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (14027 / 25000 Steps) (loss=0.02918): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (14030 / 25000 Steps) (loss=0.03631): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (14033 / 25000 Steps) (loss=0.03768): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (14036 / 25000 Steps) (loss=0.03201): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (14039 / 25000 Steps) (loss=0.03367): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (14042 / 25000 Steps) (loss=0.03966): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (14045 / 25000 Steps) (loss=0.03574): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (14048 / 25000 Steps) (loss=0.05021): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (14051 / 25000 Steps) (loss=0.03385): 100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
      "Training (14054 / 25000 Steps) (loss=0.03405): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (14057 / 25000 Steps) (loss=0.03601): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (14060 / 25000 Steps) (loss=0.03269): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (14063 / 25000 Steps) (loss=0.04161): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (14066 / 25000 Steps) (loss=0.03541): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (14069 / 25000 Steps) (loss=0.03835): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (14072 / 25000 Steps) (loss=0.05438): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (14075 / 25000 Steps) (loss=0.03511): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (14078 / 25000 Steps) (loss=0.03093): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (14081 / 25000 Steps) (loss=0.04659): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (14084 / 25000 Steps) (loss=0.03232): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (14087 / 25000 Steps) (loss=0.04203): 100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
      "Training (14090 / 25000 Steps) (loss=0.04078): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (14093 / 25000 Steps) (loss=0.04198): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (14096 / 25000 Steps) (loss=0.05138): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (14099 / 25000 Steps) (loss=0.03043): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (14102 / 25000 Steps) (loss=0.04918): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (14105 / 25000 Steps) (loss=0.03745): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (14108 / 25000 Steps) (loss=0.03344): 100%|██████████| 3/3 [00:03<00:00,  1.08s/it]\n",
      "Training (14111 / 25000 Steps) (loss=0.02538): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (14114 / 25000 Steps) (loss=0.03748): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (14117 / 25000 Steps) (loss=0.02605): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (14120 / 25000 Steps) (loss=0.03902): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (14123 / 25000 Steps) (loss=0.03622): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (14126 / 25000 Steps) (loss=0.03695): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (14129 / 25000 Steps) (loss=0.03330): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (14132 / 25000 Steps) (loss=0.03553): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (14135 / 25000 Steps) (loss=0.03947): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (14138 / 25000 Steps) (loss=0.04723): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (14141 / 25000 Steps) (loss=0.05194): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (14144 / 25000 Steps) (loss=0.03036): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (14147 / 25000 Steps) (loss=0.03839): 100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
      "Training (14150 / 25000 Steps) (loss=0.03696): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (14153 / 25000 Steps) (loss=0.03481): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (14156 / 25000 Steps) (loss=0.05163): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (14159 / 25000 Steps) (loss=0.02792): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (14162 / 25000 Steps) (loss=0.02598): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (14165 / 25000 Steps) (loss=0.03286): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (14168 / 25000 Steps) (loss=0.03454): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (14171 / 25000 Steps) (loss=0.05409): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (14174 / 25000 Steps) (loss=0.03014): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (14177 / 25000 Steps) (loss=0.03305): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (14180 / 25000 Steps) (loss=0.03385): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (14183 / 25000 Steps) (loss=0.02816): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (14186 / 25000 Steps) (loss=0.03385): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (14189 / 25000 Steps) (loss=0.02738): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (14192 / 25000 Steps) (loss=0.03334): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (14195 / 25000 Steps) (loss=0.03500): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (14198 / 25000 Steps) (loss=0.04187): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (14201 / 25000 Steps) (loss=0.02548): 100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
      "Training (14204 / 25000 Steps) (loss=0.03301): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (14207 / 25000 Steps) (loss=0.03945): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (14210 / 25000 Steps) (loss=0.03394): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (14213 / 25000 Steps) (loss=0.03235): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (14216 / 25000 Steps) (loss=0.03220): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (14219 / 25000 Steps) (loss=0.03936): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (14222 / 25000 Steps) (loss=0.04550): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (14225 / 25000 Steps) (loss=0.03499): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (14228 / 25000 Steps) (loss=0.04089): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (14231 / 25000 Steps) (loss=0.03714): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (14234 / 25000 Steps) (loss=0.03243): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (14237 / 25000 Steps) (loss=0.03433): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (14240 / 25000 Steps) (loss=0.02548): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (14243 / 25000 Steps) (loss=0.04592): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (14246 / 25000 Steps) (loss=0.02083): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (14249 / 25000 Steps) (loss=0.03983): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (14252 / 25000 Steps) (loss=0.02788): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (14255 / 25000 Steps) (loss=0.02861): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (14258 / 25000 Steps) (loss=0.02938): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (14261 / 25000 Steps) (loss=0.03049): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (14264 / 25000 Steps) (loss=0.02302): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (14267 / 25000 Steps) (loss=0.04381): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (14270 / 25000 Steps) (loss=0.04686): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (14273 / 25000 Steps) (loss=0.04919): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (14276 / 25000 Steps) (loss=0.04281): 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]\n",
      "Training (14279 / 25000 Steps) (loss=0.04010): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (14282 / 25000 Steps) (loss=0.03406): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (14285 / 25000 Steps) (loss=0.03459): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (14288 / 25000 Steps) (loss=0.05909): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (14291 / 25000 Steps) (loss=0.03971): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (14294 / 25000 Steps) (loss=0.02775): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (14297 / 25000 Steps) (loss=0.03707): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (14300 / 25000 Steps) (loss=0.03180): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (14303 / 25000 Steps) (loss=0.04176): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (14306 / 25000 Steps) (loss=0.02900): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (14309 / 25000 Steps) (loss=0.03769): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (14312 / 25000 Steps) (loss=0.03252): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (14315 / 25000 Steps) (loss=0.05180): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (14318 / 25000 Steps) (loss=0.03827): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (14321 / 25000 Steps) (loss=0.03955): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (14324 / 25000 Steps) (loss=0.03475): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (14327 / 25000 Steps) (loss=0.03295): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (14330 / 25000 Steps) (loss=0.04185): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (14333 / 25000 Steps) (loss=0.02546): 100%|██████████| 3/3 [00:03<00:00,  1.04s/it]\n",
      "Training (14336 / 25000 Steps) (loss=0.03738): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (14339 / 25000 Steps) (loss=0.03252): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (14342 / 25000 Steps) (loss=0.03186): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (14345 / 25000 Steps) (loss=0.04082): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (14348 / 25000 Steps) (loss=0.03191): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (14351 / 25000 Steps) (loss=0.03501): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (14354 / 25000 Steps) (loss=0.04143): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (14357 / 25000 Steps) (loss=0.04198): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (14360 / 25000 Steps) (loss=0.05210): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (14363 / 25000 Steps) (loss=0.02985): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (14366 / 25000 Steps) (loss=0.03446): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (14369 / 25000 Steps) (loss=0.02290): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (14372 / 25000 Steps) (loss=0.04440): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (14375 / 25000 Steps) (loss=0.03627): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (14378 / 25000 Steps) (loss=0.02644): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (14381 / 25000 Steps) (loss=0.03998): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (14384 / 25000 Steps) (loss=0.04483): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (14387 / 25000 Steps) (loss=0.03144): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (14390 / 25000 Steps) (loss=0.02905): 100%|██████████| 3/3 [00:02<00:00,  1.11it/s]\n",
      "Training (14393 / 25000 Steps) (loss=0.02956): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (14396 / 25000 Steps) (loss=0.03454): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (14399 / 25000 Steps) (loss=0.02839): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (14402 / 25000 Steps) (loss=0.04024): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (14405 / 25000 Steps) (loss=0.02645): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (14408 / 25000 Steps) (loss=0.04032): 100%|██████████| 3/3 [00:02<00:00,  1.24it/s]\n",
      "Training (14411 / 25000 Steps) (loss=0.03172): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (14414 / 25000 Steps) (loss=0.03603): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (14417 / 25000 Steps) (loss=0.03413): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (14420 / 25000 Steps) (loss=0.03612): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (14423 / 25000 Steps) (loss=0.04465): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (14426 / 25000 Steps) (loss=0.03025): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (14429 / 25000 Steps) (loss=0.04918): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (14432 / 25000 Steps) (loss=0.03726): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (14435 / 25000 Steps) (loss=0.03712): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (14438 / 25000 Steps) (loss=0.05563): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (14441 / 25000 Steps) (loss=0.05142): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (14444 / 25000 Steps) (loss=0.03146): 100%|██████████| 3/3 [00:02<00:00,  1.13it/s]\n",
      "Training (14447 / 25000 Steps) (loss=0.02427): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (14450 / 25000 Steps) (loss=0.04266): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (14453 / 25000 Steps) (loss=0.02719): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (14456 / 25000 Steps) (loss=0.03187): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (14459 / 25000 Steps) (loss=0.02914): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (14462 / 25000 Steps) (loss=0.03533): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (14465 / 25000 Steps) (loss=0.02812): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (14468 / 25000 Steps) (loss=0.03914): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (14471 / 25000 Steps) (loss=0.02878): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (14474 / 25000 Steps) (loss=0.02574): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (14477 / 25000 Steps) (loss=0.02876): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (14480 / 25000 Steps) (loss=0.02702): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (14483 / 25000 Steps) (loss=0.02729): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (14486 / 25000 Steps) (loss=0.04094): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (14489 / 25000 Steps) (loss=0.04809): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (14492 / 25000 Steps) (loss=0.03922): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (14495 / 25000 Steps) (loss=0.03147): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (14498 / 25000 Steps) (loss=0.04655): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Validate (14499 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:01<00:00,  1.76s/it]it]\n",
      "Training (14501 / 25000 Steps) (loss=0.04155):  67%|██████▋   | 2/3 [00:03<00:01,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (14501 / 25000 Steps) (loss=0.04155): 100%|██████████| 3/3 [00:03<00:00,  1.15s/it]\n",
      "Training (14504 / 25000 Steps) (loss=0.04194): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (14507 / 25000 Steps) (loss=0.02375): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (14510 / 25000 Steps) (loss=0.03948): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (14513 / 25000 Steps) (loss=0.02858): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (14516 / 25000 Steps) (loss=0.04222): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (14519 / 25000 Steps) (loss=0.03692): 100%|██████████| 3/3 [00:02<00:00,  1.35it/s]\n",
      "Training (14522 / 25000 Steps) (loss=0.04156): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (14525 / 25000 Steps) (loss=0.03065): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (14528 / 25000 Steps) (loss=0.03257): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (14531 / 25000 Steps) (loss=0.04717): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (14534 / 25000 Steps) (loss=0.03414): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (14537 / 25000 Steps) (loss=0.03444): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (14540 / 25000 Steps) (loss=0.03981): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (14543 / 25000 Steps) (loss=0.03958): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (14546 / 25000 Steps) (loss=0.03723): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (14549 / 25000 Steps) (loss=0.03959): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (14552 / 25000 Steps) (loss=0.03665): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (14555 / 25000 Steps) (loss=0.04547): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (14558 / 25000 Steps) (loss=0.04015): 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
      "Training (14561 / 25000 Steps) (loss=0.03772): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (14564 / 25000 Steps) (loss=0.03254): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (14567 / 25000 Steps) (loss=0.04716): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (14570 / 25000 Steps) (loss=0.03653): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (14573 / 25000 Steps) (loss=0.03675): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (14576 / 25000 Steps) (loss=0.04922): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (14579 / 25000 Steps) (loss=0.02977): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (14582 / 25000 Steps) (loss=0.03221): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (14585 / 25000 Steps) (loss=0.02604): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (14588 / 25000 Steps) (loss=0.05054): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (14591 / 25000 Steps) (loss=0.03902): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (14594 / 25000 Steps) (loss=0.03479): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (14597 / 25000 Steps) (loss=0.03724): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (14600 / 25000 Steps) (loss=0.03823): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (14603 / 25000 Steps) (loss=0.03548): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (14606 / 25000 Steps) (loss=0.03953): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (14609 / 25000 Steps) (loss=0.03963): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (14612 / 25000 Steps) (loss=0.04541): 100%|██████████| 3/3 [00:02<00:00,  1.22it/s]\n",
      "Training (14615 / 25000 Steps) (loss=0.04979): 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]\n",
      "Training (14618 / 25000 Steps) (loss=0.02789): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (14621 / 25000 Steps) (loss=0.03149): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (14624 / 25000 Steps) (loss=0.04004): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (14627 / 25000 Steps) (loss=0.03281): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (14630 / 25000 Steps) (loss=0.03730): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (14633 / 25000 Steps) (loss=0.04708): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (14636 / 25000 Steps) (loss=0.04448): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (14639 / 25000 Steps) (loss=0.03451): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (14642 / 25000 Steps) (loss=0.04524): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (14645 / 25000 Steps) (loss=0.03543): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (14648 / 25000 Steps) (loss=0.04404): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (14651 / 25000 Steps) (loss=0.03846): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (14654 / 25000 Steps) (loss=0.03526): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (14657 / 25000 Steps) (loss=0.03546): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (14660 / 25000 Steps) (loss=0.03457): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (14663 / 25000 Steps) (loss=0.04088): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (14666 / 25000 Steps) (loss=0.04463): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (14669 / 25000 Steps) (loss=0.04736): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (14672 / 25000 Steps) (loss=0.04336): 100%|██████████| 3/3 [00:02<00:00,  1.04it/s]\n",
      "Training (14675 / 25000 Steps) (loss=0.04712): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (14678 / 25000 Steps) (loss=0.03287): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (14681 / 25000 Steps) (loss=0.03128): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (14684 / 25000 Steps) (loss=0.03586): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (14687 / 25000 Steps) (loss=0.03500): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "Training (14690 / 25000 Steps) (loss=0.03337): 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "Training (14693 / 25000 Steps) (loss=0.03120): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (14696 / 25000 Steps) (loss=0.03388): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (14699 / 25000 Steps) (loss=0.02931): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (14702 / 25000 Steps) (loss=0.04387): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (14705 / 25000 Steps) (loss=0.02891): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (14708 / 25000 Steps) (loss=0.03548): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (14711 / 25000 Steps) (loss=0.02482): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (14714 / 25000 Steps) (loss=0.04371): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (14717 / 25000 Steps) (loss=0.03029): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (14720 / 25000 Steps) (loss=0.03167): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (14723 / 25000 Steps) (loss=0.02956): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (14726 / 25000 Steps) (loss=0.04615): 100%|██████████| 3/3 [00:03<00:00,  1.14s/it]\n",
      "Training (14729 / 25000 Steps) (loss=0.02785): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (14732 / 25000 Steps) (loss=0.03415): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (14735 / 25000 Steps) (loss=0.02710): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (14738 / 25000 Steps) (loss=0.03957): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (14741 / 25000 Steps) (loss=0.02841): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (14744 / 25000 Steps) (loss=0.04223): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (14747 / 25000 Steps) (loss=0.03317): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (14750 / 25000 Steps) (loss=0.04076): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (14753 / 25000 Steps) (loss=0.04943): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (14756 / 25000 Steps) (loss=0.04104): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (14759 / 25000 Steps) (loss=0.03109): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (14762 / 25000 Steps) (loss=0.02928): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (14765 / 25000 Steps) (loss=0.04067): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (14768 / 25000 Steps) (loss=0.04421): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (14771 / 25000 Steps) (loss=0.03217): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (14774 / 25000 Steps) (loss=0.03323): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (14777 / 25000 Steps) (loss=0.03257): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (14780 / 25000 Steps) (loss=0.02964): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (14783 / 25000 Steps) (loss=0.03713): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (14786 / 25000 Steps) (loss=0.04938): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (14789 / 25000 Steps) (loss=0.04198): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (14792 / 25000 Steps) (loss=0.04908): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (14795 / 25000 Steps) (loss=0.04453): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (14798 / 25000 Steps) (loss=0.03841): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (14801 / 25000 Steps) (loss=0.03392): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (14804 / 25000 Steps) (loss=0.06169): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (14807 / 25000 Steps) (loss=0.03459): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (14810 / 25000 Steps) (loss=0.04000): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (14813 / 25000 Steps) (loss=0.04085): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (14816 / 25000 Steps) (loss=0.03962): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (14819 / 25000 Steps) (loss=0.04166): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (14822 / 25000 Steps) (loss=0.02451): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (14825 / 25000 Steps) (loss=0.03489): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (14828 / 25000 Steps) (loss=0.03493): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (14831 / 25000 Steps) (loss=0.03603): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (14834 / 25000 Steps) (loss=0.03574): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (14837 / 25000 Steps) (loss=0.04024): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (14840 / 25000 Steps) (loss=0.03176): 100%|██████████| 3/3 [00:02<00:00,  1.06it/s]\n",
      "Training (14843 / 25000 Steps) (loss=0.04354): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (14846 / 25000 Steps) (loss=0.03707): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (14849 / 25000 Steps) (loss=0.03689): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (14852 / 25000 Steps) (loss=0.04704): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (14855 / 25000 Steps) (loss=0.03585): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (14858 / 25000 Steps) (loss=0.02843): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (14861 / 25000 Steps) (loss=0.04571): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (14864 / 25000 Steps) (loss=0.03238): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (14867 / 25000 Steps) (loss=0.03060): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (14870 / 25000 Steps) (loss=0.04028): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (14873 / 25000 Steps) (loss=0.05204): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (14876 / 25000 Steps) (loss=0.04740): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (14879 / 25000 Steps) (loss=0.03890): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (14882 / 25000 Steps) (loss=0.03836): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (14885 / 25000 Steps) (loss=0.03866): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (14888 / 25000 Steps) (loss=0.02507): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (14891 / 25000 Steps) (loss=0.04914): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (14894 / 25000 Steps) (loss=0.03507): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (14897 / 25000 Steps) (loss=0.05267): 100%|██████████| 3/3 [00:02<00:00,  1.14it/s]\n",
      "Training (14900 / 25000 Steps) (loss=0.03047): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (14903 / 25000 Steps) (loss=0.03480): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (14906 / 25000 Steps) (loss=0.03974): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (14909 / 25000 Steps) (loss=0.04388): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (14912 / 25000 Steps) (loss=0.02810): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (14915 / 25000 Steps) (loss=0.04313): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (14918 / 25000 Steps) (loss=0.02890): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (14921 / 25000 Steps) (loss=0.04420): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (14924 / 25000 Steps) (loss=0.04462): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (14927 / 25000 Steps) (loss=0.04128): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (14930 / 25000 Steps) (loss=0.04134): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (14933 / 25000 Steps) (loss=0.02510): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (14936 / 25000 Steps) (loss=0.03744): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (14939 / 25000 Steps) (loss=0.04248): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (14942 / 25000 Steps) (loss=0.03761): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (14945 / 25000 Steps) (loss=0.03199): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (14948 / 25000 Steps) (loss=0.03094): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (14951 / 25000 Steps) (loss=0.02981): 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]\n",
      "Training (14954 / 25000 Steps) (loss=0.02765): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (14957 / 25000 Steps) (loss=0.03112): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (14960 / 25000 Steps) (loss=0.04264): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (14963 / 25000 Steps) (loss=0.03801): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (14966 / 25000 Steps) (loss=0.03928): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (14969 / 25000 Steps) (loss=0.03723): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (14972 / 25000 Steps) (loss=0.03991): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (14975 / 25000 Steps) (loss=0.03771): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (14978 / 25000 Steps) (loss=0.03196): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (14981 / 25000 Steps) (loss=0.03594): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (14984 / 25000 Steps) (loss=0.02544): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (14987 / 25000 Steps) (loss=0.03707): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (14990 / 25000 Steps) (loss=0.04284): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (14993 / 25000 Steps) (loss=0.04172): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (14996 / 25000 Steps) (loss=0.02854): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (14999 / 25000 Steps) (loss=0.03003): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Validate (15000 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "Training (15002 / 25000 Steps) (loss=0.03012): 100%|██████████| 3/3 [00:02<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (15002 / 25000 Steps) (loss=0.03012): 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]\n",
      "Training (15005 / 25000 Steps) (loss=0.03100): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (15008 / 25000 Steps) (loss=0.02557): 100%|██████████| 3/3 [00:02<00:00,  1.20it/s]\n",
      "Training (15011 / 25000 Steps) (loss=0.05024): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (15014 / 25000 Steps) (loss=0.04355): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (15017 / 25000 Steps) (loss=0.03937): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (15020 / 25000 Steps) (loss=0.03196): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (15023 / 25000 Steps) (loss=0.02265): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (15026 / 25000 Steps) (loss=0.03383): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (15029 / 25000 Steps) (loss=0.03482): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (15032 / 25000 Steps) (loss=0.03827): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (15035 / 25000 Steps) (loss=0.03813): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (15038 / 25000 Steps) (loss=0.04483): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (15041 / 25000 Steps) (loss=0.03475): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (15044 / 25000 Steps) (loss=0.03810): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (15047 / 25000 Steps) (loss=0.02775): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (15050 / 25000 Steps) (loss=0.02759): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (15053 / 25000 Steps) (loss=0.03273): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (15056 / 25000 Steps) (loss=0.03483): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (15059 / 25000 Steps) (loss=0.04448): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (15062 / 25000 Steps) (loss=0.02569): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (15065 / 25000 Steps) (loss=0.03323): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (15068 / 25000 Steps) (loss=0.03434): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (15071 / 25000 Steps) (loss=0.03414): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (15074 / 25000 Steps) (loss=0.04282): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (15077 / 25000 Steps) (loss=0.03294): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (15080 / 25000 Steps) (loss=0.03072): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (15083 / 25000 Steps) (loss=0.04653): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (15086 / 25000 Steps) (loss=0.03245): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (15089 / 25000 Steps) (loss=0.04883): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (15092 / 25000 Steps) (loss=0.03154): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (15095 / 25000 Steps) (loss=0.03567): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (15098 / 25000 Steps) (loss=0.02676): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (15101 / 25000 Steps) (loss=0.03251): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (15104 / 25000 Steps) (loss=0.03292): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (15107 / 25000 Steps) (loss=0.03925): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (15110 / 25000 Steps) (loss=0.03230): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (15113 / 25000 Steps) (loss=0.03551): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (15116 / 25000 Steps) (loss=0.03344): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (15119 / 25000 Steps) (loss=0.03915): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (15122 / 25000 Steps) (loss=0.03039): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (15125 / 25000 Steps) (loss=0.04387): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (15128 / 25000 Steps) (loss=0.03402): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (15131 / 25000 Steps) (loss=0.02691): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (15134 / 25000 Steps) (loss=0.02458): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (15137 / 25000 Steps) (loss=0.03416): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (15140 / 25000 Steps) (loss=0.02956): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (15143 / 25000 Steps) (loss=0.03369): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (15146 / 25000 Steps) (loss=0.03127): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (15149 / 25000 Steps) (loss=0.04160): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (15152 / 25000 Steps) (loss=0.03000): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (15155 / 25000 Steps) (loss=0.03398): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (15158 / 25000 Steps) (loss=0.03033): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (15161 / 25000 Steps) (loss=0.03961): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (15164 / 25000 Steps) (loss=0.03238): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (15167 / 25000 Steps) (loss=0.02842): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (15170 / 25000 Steps) (loss=0.03459): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (15173 / 25000 Steps) (loss=0.03138): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (15176 / 25000 Steps) (loss=0.02710): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (15179 / 25000 Steps) (loss=0.03823): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (15182 / 25000 Steps) (loss=0.03595): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (15185 / 25000 Steps) (loss=0.03531): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (15188 / 25000 Steps) (loss=0.03008): 100%|██████████| 3/3 [00:02<00:00,  1.14it/s]\n",
      "Training (15191 / 25000 Steps) (loss=0.03365): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (15194 / 25000 Steps) (loss=0.02861): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (15197 / 25000 Steps) (loss=0.03606): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (15200 / 25000 Steps) (loss=0.03132): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (15203 / 25000 Steps) (loss=0.03134): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (15206 / 25000 Steps) (loss=0.04263): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (15209 / 25000 Steps) (loss=0.02560): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (15212 / 25000 Steps) (loss=0.04007): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (15215 / 25000 Steps) (loss=0.02769): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (15218 / 25000 Steps) (loss=0.05346): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (15221 / 25000 Steps) (loss=0.03712): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (15224 / 25000 Steps) (loss=0.04339): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (15227 / 25000 Steps) (loss=0.04778): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (15230 / 25000 Steps) (loss=0.03298): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (15233 / 25000 Steps) (loss=0.03054): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (15236 / 25000 Steps) (loss=0.04142): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (15239 / 25000 Steps) (loss=0.04001): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (15242 / 25000 Steps) (loss=0.02720): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (15245 / 25000 Steps) (loss=0.03388): 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
      "Training (15248 / 25000 Steps) (loss=0.03594): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (15251 / 25000 Steps) (loss=0.03249): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (15254 / 25000 Steps) (loss=0.03752): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (15257 / 25000 Steps) (loss=0.04306): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (15260 / 25000 Steps) (loss=0.03358): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (15263 / 25000 Steps) (loss=0.03016): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (15266 / 25000 Steps) (loss=0.03165): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (15269 / 25000 Steps) (loss=0.04332): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (15272 / 25000 Steps) (loss=0.04107): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (15275 / 25000 Steps) (loss=0.03261): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (15278 / 25000 Steps) (loss=0.04437): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (15281 / 25000 Steps) (loss=0.02983): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (15284 / 25000 Steps) (loss=0.03221): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (15287 / 25000 Steps) (loss=0.03534): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (15290 / 25000 Steps) (loss=0.03398): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (15293 / 25000 Steps) (loss=0.04070): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (15296 / 25000 Steps) (loss=0.03515): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (15299 / 25000 Steps) (loss=0.04314): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (15302 / 25000 Steps) (loss=0.03746): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (15305 / 25000 Steps) (loss=0.02828): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (15308 / 25000 Steps) (loss=0.03070): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (15311 / 25000 Steps) (loss=0.02762): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (15314 / 25000 Steps) (loss=0.03298): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (15317 / 25000 Steps) (loss=0.03061): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (15320 / 25000 Steps) (loss=0.02906): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (15323 / 25000 Steps) (loss=0.03340): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (15326 / 25000 Steps) (loss=0.03839): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (15329 / 25000 Steps) (loss=0.03389): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (15332 / 25000 Steps) (loss=0.02602): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (15335 / 25000 Steps) (loss=0.02932): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (15338 / 25000 Steps) (loss=0.04884): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (15341 / 25000 Steps) (loss=0.03204): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (15344 / 25000 Steps) (loss=0.02917): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (15347 / 25000 Steps) (loss=0.03130): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (15350 / 25000 Steps) (loss=0.03308): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (15353 / 25000 Steps) (loss=0.03187): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (15356 / 25000 Steps) (loss=0.02652): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (15359 / 25000 Steps) (loss=0.04276): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (15362 / 25000 Steps) (loss=0.03718): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (15365 / 25000 Steps) (loss=0.02557): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (15368 / 25000 Steps) (loss=0.04740): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (15371 / 25000 Steps) (loss=0.02852): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (15374 / 25000 Steps) (loss=0.03362): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (15377 / 25000 Steps) (loss=0.02394): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (15380 / 25000 Steps) (loss=0.03572): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (15383 / 25000 Steps) (loss=0.02780): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (15386 / 25000 Steps) (loss=0.03342): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (15389 / 25000 Steps) (loss=0.05136): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (15392 / 25000 Steps) (loss=0.04532): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (15395 / 25000 Steps) (loss=0.04598): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (15398 / 25000 Steps) (loss=0.04187): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (15401 / 25000 Steps) (loss=0.02578): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (15404 / 25000 Steps) (loss=0.03630): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (15407 / 25000 Steps) (loss=0.03208): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (15410 / 25000 Steps) (loss=0.05466): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (15413 / 25000 Steps) (loss=0.02795): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (15416 / 25000 Steps) (loss=0.02966): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (15419 / 25000 Steps) (loss=0.02705): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (15422 / 25000 Steps) (loss=0.02813): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (15425 / 25000 Steps) (loss=0.04945): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "Training (15428 / 25000 Steps) (loss=0.03370): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (15431 / 25000 Steps) (loss=0.03558): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (15434 / 25000 Steps) (loss=0.03603): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (15437 / 25000 Steps) (loss=0.03044): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (15440 / 25000 Steps) (loss=0.03802): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (15443 / 25000 Steps) (loss=0.03731): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (15446 / 25000 Steps) (loss=0.03485): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (15449 / 25000 Steps) (loss=0.03430): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (15452 / 25000 Steps) (loss=0.04945): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (15455 / 25000 Steps) (loss=0.02386): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (15458 / 25000 Steps) (loss=0.03098): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (15461 / 25000 Steps) (loss=0.03236): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (15464 / 25000 Steps) (loss=0.03413): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (15467 / 25000 Steps) (loss=0.03153): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (15470 / 25000 Steps) (loss=0.04139): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (15473 / 25000 Steps) (loss=0.03339): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (15476 / 25000 Steps) (loss=0.03570): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (15479 / 25000 Steps) (loss=0.04473): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (15482 / 25000 Steps) (loss=0.03682): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (15485 / 25000 Steps) (loss=0.03476): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (15488 / 25000 Steps) (loss=0.03961): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (15491 / 25000 Steps) (loss=0.02794): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (15494 / 25000 Steps) (loss=0.03131): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (15497 / 25000 Steps) (loss=0.04286): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Validate (15498 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]/s]\n",
      "Training (15500 / 25000 Steps) (loss=0.03021): 100%|██████████| 3/3 [00:02<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (15500 / 25000 Steps) (loss=0.03021): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (15503 / 25000 Steps) (loss=0.03921): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (15506 / 25000 Steps) (loss=0.03359): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (15509 / 25000 Steps) (loss=0.03902): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (15512 / 25000 Steps) (loss=0.02890): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (15515 / 25000 Steps) (loss=0.03937): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (15518 / 25000 Steps) (loss=0.04530): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (15521 / 25000 Steps) (loss=0.02494): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (15524 / 25000 Steps) (loss=0.03899): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (15527 / 25000 Steps) (loss=0.03070): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (15530 / 25000 Steps) (loss=0.03976): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (15533 / 25000 Steps) (loss=0.02639): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (15536 / 25000 Steps) (loss=0.03891): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (15539 / 25000 Steps) (loss=0.03971): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (15542 / 25000 Steps) (loss=0.02687): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (15545 / 25000 Steps) (loss=0.03286): 100%|██████████| 3/3 [00:02<00:00,  1.16it/s]\n",
      "Training (15548 / 25000 Steps) (loss=0.03582): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (15551 / 25000 Steps) (loss=0.03458): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (15554 / 25000 Steps) (loss=0.03838): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (15557 / 25000 Steps) (loss=0.03347): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (15560 / 25000 Steps) (loss=0.03619): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (15563 / 25000 Steps) (loss=0.05259): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (15566 / 25000 Steps) (loss=0.03832): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (15569 / 25000 Steps) (loss=0.04019): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (15572 / 25000 Steps) (loss=0.02921): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (15575 / 25000 Steps) (loss=0.03800): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (15578 / 25000 Steps) (loss=0.03037): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (15581 / 25000 Steps) (loss=0.04007): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (15584 / 25000 Steps) (loss=0.03728): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (15587 / 25000 Steps) (loss=0.03328): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (15590 / 25000 Steps) (loss=0.04272): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (15593 / 25000 Steps) (loss=0.03711): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (15596 / 25000 Steps) (loss=0.02647): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (15599 / 25000 Steps) (loss=0.02528): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (15602 / 25000 Steps) (loss=0.02638): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (15605 / 25000 Steps) (loss=0.03774): 100%|██████████| 3/3 [00:02<00:00,  1.24it/s]\n",
      "Training (15608 / 25000 Steps) (loss=0.03564): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (15611 / 25000 Steps) (loss=0.04136): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (15614 / 25000 Steps) (loss=0.04361): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (15617 / 25000 Steps) (loss=0.02798): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (15620 / 25000 Steps) (loss=0.03471): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (15623 / 25000 Steps) (loss=0.04324): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (15626 / 25000 Steps) (loss=0.04601): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (15629 / 25000 Steps) (loss=0.04664): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (15632 / 25000 Steps) (loss=0.02865): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (15635 / 25000 Steps) (loss=0.03137): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (15638 / 25000 Steps) (loss=0.03700): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (15641 / 25000 Steps) (loss=0.03642): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (15644 / 25000 Steps) (loss=0.03966): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (15647 / 25000 Steps) (loss=0.03695): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (15650 / 25000 Steps) (loss=0.03719): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (15653 / 25000 Steps) (loss=0.03733): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (15656 / 25000 Steps) (loss=0.03619): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (15659 / 25000 Steps) (loss=0.03237): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (15662 / 25000 Steps) (loss=0.04261): 100%|██████████| 3/3 [00:02<00:00,  1.03it/s]\n",
      "Training (15665 / 25000 Steps) (loss=0.03174): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (15668 / 25000 Steps) (loss=0.02810): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (15671 / 25000 Steps) (loss=0.04551): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (15674 / 25000 Steps) (loss=0.03688): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (15677 / 25000 Steps) (loss=0.04199): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (15680 / 25000 Steps) (loss=0.04241): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (15683 / 25000 Steps) (loss=0.03428): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (15686 / 25000 Steps) (loss=0.03844): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (15689 / 25000 Steps) (loss=0.03032): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (15692 / 25000 Steps) (loss=0.03096): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (15695 / 25000 Steps) (loss=0.03078): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (15698 / 25000 Steps) (loss=0.03797): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (15701 / 25000 Steps) (loss=0.03973): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (15704 / 25000 Steps) (loss=0.02898): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (15707 / 25000 Steps) (loss=0.03544): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (15710 / 25000 Steps) (loss=0.03352): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (15713 / 25000 Steps) (loss=0.03599): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (15716 / 25000 Steps) (loss=0.03655): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (15719 / 25000 Steps) (loss=0.04104): 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]\n",
      "Training (15722 / 25000 Steps) (loss=0.03113): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (15725 / 25000 Steps) (loss=0.03565): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (15728 / 25000 Steps) (loss=0.03817): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (15731 / 25000 Steps) (loss=0.03074): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (15734 / 25000 Steps) (loss=0.03444): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (15737 / 25000 Steps) (loss=0.03020): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (15740 / 25000 Steps) (loss=0.03397): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (15743 / 25000 Steps) (loss=0.03352): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (15746 / 25000 Steps) (loss=0.03904): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (15749 / 25000 Steps) (loss=0.03119): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (15752 / 25000 Steps) (loss=0.02763): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (15755 / 25000 Steps) (loss=0.03554): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (15758 / 25000 Steps) (loss=0.04216): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (15761 / 25000 Steps) (loss=0.02983): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (15764 / 25000 Steps) (loss=0.04175): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (15767 / 25000 Steps) (loss=0.03826): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (15770 / 25000 Steps) (loss=0.03771): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (15773 / 25000 Steps) (loss=0.03079): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (15776 / 25000 Steps) (loss=0.03215): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (15779 / 25000 Steps) (loss=0.02927): 100%|██████████| 3/3 [00:02<00:00,  1.11it/s]\n",
      "Training (15782 / 25000 Steps) (loss=0.04107): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (15785 / 25000 Steps) (loss=0.04273): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (15788 / 25000 Steps) (loss=0.04908): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (15791 / 25000 Steps) (loss=0.03922): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (15794 / 25000 Steps) (loss=0.02743): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (15797 / 25000 Steps) (loss=0.02569): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (15800 / 25000 Steps) (loss=0.03519): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (15803 / 25000 Steps) (loss=0.02811): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (15806 / 25000 Steps) (loss=0.03897): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (15809 / 25000 Steps) (loss=0.03771): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (15812 / 25000 Steps) (loss=0.02547): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (15815 / 25000 Steps) (loss=0.02885): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (15818 / 25000 Steps) (loss=0.02810): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (15821 / 25000 Steps) (loss=0.03179): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (15824 / 25000 Steps) (loss=0.03890): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (15827 / 25000 Steps) (loss=0.04568): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (15830 / 25000 Steps) (loss=0.03570): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (15833 / 25000 Steps) (loss=0.03508): 100%|██████████| 3/3 [00:03<00:00,  1.21s/it]\n",
      "Training (15836 / 25000 Steps) (loss=0.03246): 100%|██████████| 3/3 [00:02<00:00,  1.19it/s]\n",
      "Training (15839 / 25000 Steps) (loss=0.02775): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (15842 / 25000 Steps) (loss=0.03204): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (15845 / 25000 Steps) (loss=0.04308): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (15848 / 25000 Steps) (loss=0.05095): 100%|██████████| 3/3 [00:01<00:00,  2.03it/s]\n",
      "Training (15851 / 25000 Steps) (loss=0.02950): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (15854 / 25000 Steps) (loss=0.03439): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (15857 / 25000 Steps) (loss=0.03200): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (15860 / 25000 Steps) (loss=0.03712): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (15863 / 25000 Steps) (loss=0.05127): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (15866 / 25000 Steps) (loss=0.03222): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (15869 / 25000 Steps) (loss=0.02850): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (15872 / 25000 Steps) (loss=0.03339): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (15875 / 25000 Steps) (loss=0.03205): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (15878 / 25000 Steps) (loss=0.02426): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (15881 / 25000 Steps) (loss=0.03943): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (15884 / 25000 Steps) (loss=0.05863): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (15887 / 25000 Steps) (loss=0.03991): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (15890 / 25000 Steps) (loss=0.03653): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (15893 / 25000 Steps) (loss=0.02847): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (15896 / 25000 Steps) (loss=0.02989): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (15899 / 25000 Steps) (loss=0.03178): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (15902 / 25000 Steps) (loss=0.03293): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (15905 / 25000 Steps) (loss=0.04307): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (15908 / 25000 Steps) (loss=0.04226): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (15911 / 25000 Steps) (loss=0.03267): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (15914 / 25000 Steps) (loss=0.02964): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (15917 / 25000 Steps) (loss=0.02818): 100%|██████████| 3/3 [00:02<00:00,  1.25it/s]\n",
      "Training (15920 / 25000 Steps) (loss=0.03552): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (15923 / 25000 Steps) (loss=0.02871): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (15926 / 25000 Steps) (loss=0.02976): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (15929 / 25000 Steps) (loss=0.03871): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (15932 / 25000 Steps) (loss=0.02745): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (15935 / 25000 Steps) (loss=0.03620): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (15938 / 25000 Steps) (loss=0.03441): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (15941 / 25000 Steps) (loss=0.03218): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (15944 / 25000 Steps) (loss=0.02990): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (15947 / 25000 Steps) (loss=0.02701): 100%|██████████| 3/3 [00:02<00:00,  1.22it/s]\n",
      "Training (15950 / 25000 Steps) (loss=0.03370): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (15953 / 25000 Steps) (loss=0.02767): 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "Training (15956 / 25000 Steps) (loss=0.03004): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (15959 / 25000 Steps) (loss=0.04061): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (15962 / 25000 Steps) (loss=0.03055): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (15965 / 25000 Steps) (loss=0.02646): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (15968 / 25000 Steps) (loss=0.03899): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (15971 / 25000 Steps) (loss=0.03046): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (15974 / 25000 Steps) (loss=0.03415): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (15977 / 25000 Steps) (loss=0.04515): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (15980 / 25000 Steps) (loss=0.03516): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (15983 / 25000 Steps) (loss=0.02932): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (15986 / 25000 Steps) (loss=0.03415): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (15989 / 25000 Steps) (loss=0.03504): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (15992 / 25000 Steps) (loss=0.03958): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (15995 / 25000 Steps) (loss=0.04961): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (15998 / 25000 Steps) (loss=0.03285): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Validate (15999 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]it]\n",
      "Training (16001 / 25000 Steps) (loss=0.04231):  67%|██████▋   | 2/3 [00:02<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (16001 / 25000 Steps) (loss=0.04231): 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
      "Training (16004 / 25000 Steps) (loss=0.03246): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (16007 / 25000 Steps) (loss=0.04258): 100%|██████████| 3/3 [00:03<00:00,  1.01s/it]\n",
      "Training (16010 / 25000 Steps) (loss=0.05118): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (16013 / 25000 Steps) (loss=0.03296): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (16016 / 25000 Steps) (loss=0.03564): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (16019 / 25000 Steps) (loss=0.02881): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (16022 / 25000 Steps) (loss=0.04591): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (16025 / 25000 Steps) (loss=0.04142): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (16028 / 25000 Steps) (loss=0.02760): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (16031 / 25000 Steps) (loss=0.02992): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (16034 / 25000 Steps) (loss=0.03926): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (16037 / 25000 Steps) (loss=0.04114): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (16040 / 25000 Steps) (loss=0.03186): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (16043 / 25000 Steps) (loss=0.03702): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (16046 / 25000 Steps) (loss=0.03377): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (16049 / 25000 Steps) (loss=0.04296): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (16052 / 25000 Steps) (loss=0.04687): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (16055 / 25000 Steps) (loss=0.03561): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (16058 / 25000 Steps) (loss=0.02881): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (16061 / 25000 Steps) (loss=0.03348): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (16064 / 25000 Steps) (loss=0.03682): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (16067 / 25000 Steps) (loss=0.02565): 100%|██████████| 3/3 [00:02<00:00,  1.16it/s]\n",
      "Training (16070 / 25000 Steps) (loss=0.02543): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (16073 / 25000 Steps) (loss=0.03027): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (16076 / 25000 Steps) (loss=0.02779): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (16079 / 25000 Steps) (loss=0.03017): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (16082 / 25000 Steps) (loss=0.04300): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (16085 / 25000 Steps) (loss=0.02819): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (16088 / 25000 Steps) (loss=0.02730): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (16091 / 25000 Steps) (loss=0.02853): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (16094 / 25000 Steps) (loss=0.03711): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (16097 / 25000 Steps) (loss=0.03218): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (16100 / 25000 Steps) (loss=0.03358): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (16103 / 25000 Steps) (loss=0.04471): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (16106 / 25000 Steps) (loss=0.02847): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (16109 / 25000 Steps) (loss=0.03287): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (16112 / 25000 Steps) (loss=0.03481): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (16115 / 25000 Steps) (loss=0.03936): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (16118 / 25000 Steps) (loss=0.03522): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (16121 / 25000 Steps) (loss=0.04088): 100%|██████████| 3/3 [00:02<00:00,  1.21it/s]\n",
      "Training (16124 / 25000 Steps) (loss=0.03593): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (16127 / 25000 Steps) (loss=0.02776): 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
      "Training (16130 / 25000 Steps) (loss=0.03141): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (16133 / 25000 Steps) (loss=0.03260): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (16136 / 25000 Steps) (loss=0.03017): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (16139 / 25000 Steps) (loss=0.05316): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (16142 / 25000 Steps) (loss=0.03657): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (16145 / 25000 Steps) (loss=0.03519): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (16148 / 25000 Steps) (loss=0.04168): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (16151 / 25000 Steps) (loss=0.03174): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (16154 / 25000 Steps) (loss=0.03502): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (16157 / 25000 Steps) (loss=0.03165): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (16160 / 25000 Steps) (loss=0.03846): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (16163 / 25000 Steps) (loss=0.03881): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (16166 / 25000 Steps) (loss=0.03775): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (16169 / 25000 Steps) (loss=0.03307): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (16172 / 25000 Steps) (loss=0.06074): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (16175 / 25000 Steps) (loss=0.03839): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (16178 / 25000 Steps) (loss=0.04140): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (16181 / 25000 Steps) (loss=0.03082): 100%|██████████| 3/3 [00:02<00:00,  1.01it/s]\n",
      "Training (16184 / 25000 Steps) (loss=0.02349): 100%|██████████| 3/3 [00:02<00:00,  1.08it/s]\n",
      "Training (16187 / 25000 Steps) (loss=0.02682): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (16190 / 25000 Steps) (loss=0.02594): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (16193 / 25000 Steps) (loss=0.03434): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (16196 / 25000 Steps) (loss=0.03700): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (16199 / 25000 Steps) (loss=0.04666): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (16202 / 25000 Steps) (loss=0.03068): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (16205 / 25000 Steps) (loss=0.04255): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (16208 / 25000 Steps) (loss=0.02904): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (16211 / 25000 Steps) (loss=0.03165): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (16214 / 25000 Steps) (loss=0.03736): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (16217 / 25000 Steps) (loss=0.02854): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (16220 / 25000 Steps) (loss=0.02542): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (16223 / 25000 Steps) (loss=0.03784): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (16226 / 25000 Steps) (loss=0.03085): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (16229 / 25000 Steps) (loss=0.02798): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (16232 / 25000 Steps) (loss=0.03629): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (16235 / 25000 Steps) (loss=0.03002): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (16238 / 25000 Steps) (loss=0.03756): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (16241 / 25000 Steps) (loss=0.03095): 100%|██████████| 3/3 [00:02<00:00,  1.08it/s]\n",
      "Training (16244 / 25000 Steps) (loss=0.03784): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (16247 / 25000 Steps) (loss=0.03313): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (16250 / 25000 Steps) (loss=0.03265): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (16253 / 25000 Steps) (loss=0.03196): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (16256 / 25000 Steps) (loss=0.04460): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (16259 / 25000 Steps) (loss=0.03103): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (16262 / 25000 Steps) (loss=0.03599): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (16265 / 25000 Steps) (loss=0.03170): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (16268 / 25000 Steps) (loss=0.03432): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (16271 / 25000 Steps) (loss=0.03272): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (16274 / 25000 Steps) (loss=0.03654): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (16277 / 25000 Steps) (loss=0.04067): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (16280 / 25000 Steps) (loss=0.03580): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (16283 / 25000 Steps) (loss=0.02690): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (16286 / 25000 Steps) (loss=0.04316): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (16289 / 25000 Steps) (loss=0.03398): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (16292 / 25000 Steps) (loss=0.03315): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (16295 / 25000 Steps) (loss=0.03999): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (16298 / 25000 Steps) (loss=0.02900): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (16301 / 25000 Steps) (loss=0.03632): 100%|██████████| 3/3 [00:02<00:00,  1.32it/s]\n",
      "Training (16304 / 25000 Steps) (loss=0.04031): 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
      "Training (16307 / 25000 Steps) (loss=0.05291): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (16310 / 25000 Steps) (loss=0.03244): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (16313 / 25000 Steps) (loss=0.03071): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (16316 / 25000 Steps) (loss=0.02610): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (16319 / 25000 Steps) (loss=0.03756): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (16322 / 25000 Steps) (loss=0.03751): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (16325 / 25000 Steps) (loss=0.04157): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (16328 / 25000 Steps) (loss=0.03923): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (16331 / 25000 Steps) (loss=0.03402): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (16334 / 25000 Steps) (loss=0.03373): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (16337 / 25000 Steps) (loss=0.03425): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (16340 / 25000 Steps) (loss=0.02797): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (16343 / 25000 Steps) (loss=0.03966): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (16346 / 25000 Steps) (loss=0.03176): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (16349 / 25000 Steps) (loss=0.04002): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (16352 / 25000 Steps) (loss=0.03028): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (16355 / 25000 Steps) (loss=0.02992): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (16358 / 25000 Steps) (loss=0.04298): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (16361 / 25000 Steps) (loss=0.03082): 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]\n",
      "Training (16364 / 25000 Steps) (loss=0.03295): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (16367 / 25000 Steps) (loss=0.04043): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (16370 / 25000 Steps) (loss=0.03515): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (16373 / 25000 Steps) (loss=0.02385): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (16376 / 25000 Steps) (loss=0.03333): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (16379 / 25000 Steps) (loss=0.03262): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (16382 / 25000 Steps) (loss=0.03586): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (16385 / 25000 Steps) (loss=0.02296): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (16388 / 25000 Steps) (loss=0.03041): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (16391 / 25000 Steps) (loss=0.02491): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (16394 / 25000 Steps) (loss=0.03141): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (16397 / 25000 Steps) (loss=0.03501): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (16400 / 25000 Steps) (loss=0.03550): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (16403 / 25000 Steps) (loss=0.02982): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (16406 / 25000 Steps) (loss=0.03381): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (16409 / 25000 Steps) (loss=0.03959): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (16412 / 25000 Steps) (loss=0.02722): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (16415 / 25000 Steps) (loss=0.02676): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (16418 / 25000 Steps) (loss=0.03284): 100%|██████████| 3/3 [00:03<00:00,  1.22s/it]\n",
      "Training (16421 / 25000 Steps) (loss=0.03581): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (16424 / 25000 Steps) (loss=0.03583): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (16427 / 25000 Steps) (loss=0.02684): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (16430 / 25000 Steps) (loss=0.03438): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (16433 / 25000 Steps) (loss=0.05155): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (16436 / 25000 Steps) (loss=0.03355): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (16439 / 25000 Steps) (loss=0.02534): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (16442 / 25000 Steps) (loss=0.03527): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (16445 / 25000 Steps) (loss=0.02663): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (16448 / 25000 Steps) (loss=0.03444): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (16451 / 25000 Steps) (loss=0.03639): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (16454 / 25000 Steps) (loss=0.03736): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (16457 / 25000 Steps) (loss=0.02953): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (16460 / 25000 Steps) (loss=0.04382): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "Training (16463 / 25000 Steps) (loss=0.03136): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (16466 / 25000 Steps) (loss=0.03685): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (16469 / 25000 Steps) (loss=0.03010): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (16472 / 25000 Steps) (loss=0.04746): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (16475 / 25000 Steps) (loss=0.04570): 100%|██████████| 3/3 [00:02<00:00,  1.04it/s]\n",
      "Training (16478 / 25000 Steps) (loss=0.03786): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (16481 / 25000 Steps) (loss=0.02942): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (16484 / 25000 Steps) (loss=0.02414): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (16487 / 25000 Steps) (loss=0.03810): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (16490 / 25000 Steps) (loss=0.03245): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (16493 / 25000 Steps) (loss=0.04613): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (16496 / 25000 Steps) (loss=0.03632): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (16499 / 25000 Steps) (loss=0.03292): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Validate (16500 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "Training (16502 / 25000 Steps) (loss=0.02760): 100%|██████████| 3/3 [00:02<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (16502 / 25000 Steps) (loss=0.02760): 100%|██████████| 3/3 [00:02<00:00,  1.25it/s]\n",
      "Training (16505 / 25000 Steps) (loss=0.04810): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (16508 / 25000 Steps) (loss=0.02398): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (16511 / 25000 Steps) (loss=0.03296): 100%|██████████| 3/3 [00:02<00:00,  1.12it/s]\n",
      "Training (16514 / 25000 Steps) (loss=0.02481): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (16517 / 25000 Steps) (loss=0.03316): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (16520 / 25000 Steps) (loss=0.03025): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (16523 / 25000 Steps) (loss=0.03422): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (16526 / 25000 Steps) (loss=0.04304): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (16529 / 25000 Steps) (loss=0.03551): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (16532 / 25000 Steps) (loss=0.03257): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (16535 / 25000 Steps) (loss=0.02870): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (16538 / 25000 Steps) (loss=0.03597): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (16541 / 25000 Steps) (loss=0.03294): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (16544 / 25000 Steps) (loss=0.03899): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (16547 / 25000 Steps) (loss=0.03537): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (16550 / 25000 Steps) (loss=0.03995): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (16553 / 25000 Steps) (loss=0.03650): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (16556 / 25000 Steps) (loss=0.02473): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (16559 / 25000 Steps) (loss=0.02307): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (16562 / 25000 Steps) (loss=0.04789): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (16565 / 25000 Steps) (loss=0.03058): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (16568 / 25000 Steps) (loss=0.04652): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (16571 / 25000 Steps) (loss=0.03715): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (16574 / 25000 Steps) (loss=0.05561): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (16577 / 25000 Steps) (loss=0.03723): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (16580 / 25000 Steps) (loss=0.03524): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (16583 / 25000 Steps) (loss=0.02759): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (16586 / 25000 Steps) (loss=0.04486): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (16589 / 25000 Steps) (loss=0.04255): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (16592 / 25000 Steps) (loss=0.03311): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (16595 / 25000 Steps) (loss=0.03853): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (16598 / 25000 Steps) (loss=0.03674): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (16601 / 25000 Steps) (loss=0.03483): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (16604 / 25000 Steps) (loss=0.02933): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (16607 / 25000 Steps) (loss=0.03080): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (16610 / 25000 Steps) (loss=0.04123): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (16613 / 25000 Steps) (loss=0.02325): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (16616 / 25000 Steps) (loss=0.02760): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (16619 / 25000 Steps) (loss=0.03007): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (16622 / 25000 Steps) (loss=0.02677): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (16625 / 25000 Steps) (loss=0.04133): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (16628 / 25000 Steps) (loss=0.03017): 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "Training (16631 / 25000 Steps) (loss=0.02715): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (16634 / 25000 Steps) (loss=0.05039): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (16637 / 25000 Steps) (loss=0.03282): 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
      "Training (16640 / 25000 Steps) (loss=0.02606): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (16643 / 25000 Steps) (loss=0.02990): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (16646 / 25000 Steps) (loss=0.02810): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (16649 / 25000 Steps) (loss=0.03165): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "Training (16652 / 25000 Steps) (loss=0.04012): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (16655 / 25000 Steps) (loss=0.03327): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (16658 / 25000 Steps) (loss=0.05162): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (16661 / 25000 Steps) (loss=0.04032): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (16664 / 25000 Steps) (loss=0.03483): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (16667 / 25000 Steps) (loss=0.02568): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (16670 / 25000 Steps) (loss=0.03600): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (16673 / 25000 Steps) (loss=0.02630): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (16676 / 25000 Steps) (loss=0.02864): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (16679 / 25000 Steps) (loss=0.03619): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (16682 / 25000 Steps) (loss=0.03042): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (16685 / 25000 Steps) (loss=0.03773): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (16688 / 25000 Steps) (loss=0.04161): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (16691 / 25000 Steps) (loss=0.02819): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (16694 / 25000 Steps) (loss=0.02947): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (16697 / 25000 Steps) (loss=0.04207): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (16700 / 25000 Steps) (loss=0.02570): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (16703 / 25000 Steps) (loss=0.03137): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (16706 / 25000 Steps) (loss=0.02782): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (16709 / 25000 Steps) (loss=0.02498): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (16712 / 25000 Steps) (loss=0.03063): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (16715 / 25000 Steps) (loss=0.03046): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (16718 / 25000 Steps) (loss=0.05395): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (16721 / 25000 Steps) (loss=0.03581): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (16724 / 25000 Steps) (loss=0.04774): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (16727 / 25000 Steps) (loss=0.02973): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (16730 / 25000 Steps) (loss=0.03372): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (16733 / 25000 Steps) (loss=0.03255): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (16736 / 25000 Steps) (loss=0.03301): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (16739 / 25000 Steps) (loss=0.03458): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (16742 / 25000 Steps) (loss=0.03941): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (16745 / 25000 Steps) (loss=0.03234): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (16748 / 25000 Steps) (loss=0.03084): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (16751 / 25000 Steps) (loss=0.04351): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (16754 / 25000 Steps) (loss=0.03160): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (16757 / 25000 Steps) (loss=0.03985): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (16760 / 25000 Steps) (loss=0.03561): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (16763 / 25000 Steps) (loss=0.03364): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (16766 / 25000 Steps) (loss=0.03176): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (16769 / 25000 Steps) (loss=0.04215): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (16772 / 25000 Steps) (loss=0.03176): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (16775 / 25000 Steps) (loss=0.03530): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (16778 / 25000 Steps) (loss=0.03554): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (16781 / 25000 Steps) (loss=0.02597): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (16784 / 25000 Steps) (loss=0.03691): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (16787 / 25000 Steps) (loss=0.04058): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (16790 / 25000 Steps) (loss=0.04130): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (16793 / 25000 Steps) (loss=0.02782): 100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
      "Training (16796 / 25000 Steps) (loss=0.03509): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (16799 / 25000 Steps) (loss=0.03112): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (16802 / 25000 Steps) (loss=0.03512): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (16805 / 25000 Steps) (loss=0.03331): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (16808 / 25000 Steps) (loss=0.03778): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (16811 / 25000 Steps) (loss=0.03242): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (16814 / 25000 Steps) (loss=0.02493): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (16817 / 25000 Steps) (loss=0.02552): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (16820 / 25000 Steps) (loss=0.03264): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (16823 / 25000 Steps) (loss=0.04125): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (16826 / 25000 Steps) (loss=0.02992): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (16829 / 25000 Steps) (loss=0.02985): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (16832 / 25000 Steps) (loss=0.04553): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (16835 / 25000 Steps) (loss=0.03473): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (16838 / 25000 Steps) (loss=0.03027): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (16841 / 25000 Steps) (loss=0.03228): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (16844 / 25000 Steps) (loss=0.03107): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (16847 / 25000 Steps) (loss=0.03053): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (16850 / 25000 Steps) (loss=0.03083): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (16853 / 25000 Steps) (loss=0.02829): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (16856 / 25000 Steps) (loss=0.04223): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (16859 / 25000 Steps) (loss=0.02865): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (16862 / 25000 Steps) (loss=0.03188): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (16865 / 25000 Steps) (loss=0.04271): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (16868 / 25000 Steps) (loss=0.05697): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (16871 / 25000 Steps) (loss=0.02914): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (16874 / 25000 Steps) (loss=0.02285): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (16877 / 25000 Steps) (loss=0.02897): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (16880 / 25000 Steps) (loss=0.02373): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (16883 / 25000 Steps) (loss=0.03055): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (16886 / 25000 Steps) (loss=0.06002): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (16889 / 25000 Steps) (loss=0.03731): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (16892 / 25000 Steps) (loss=0.03232): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (16895 / 25000 Steps) (loss=0.03516): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (16898 / 25000 Steps) (loss=0.03389): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (16901 / 25000 Steps) (loss=0.03257): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (16904 / 25000 Steps) (loss=0.03677): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "Training (16907 / 25000 Steps) (loss=0.04915): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (16910 / 25000 Steps) (loss=0.03703): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (16913 / 25000 Steps) (loss=0.03749): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (16916 / 25000 Steps) (loss=0.03605): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (16919 / 25000 Steps) (loss=0.04281): 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]\n",
      "Training (16922 / 25000 Steps) (loss=0.03720): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (16925 / 25000 Steps) (loss=0.03586): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (16928 / 25000 Steps) (loss=0.03975): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (16931 / 25000 Steps) (loss=0.05239): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (16934 / 25000 Steps) (loss=0.04604): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (16937 / 25000 Steps) (loss=0.03420): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (16940 / 25000 Steps) (loss=0.03658): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (16943 / 25000 Steps) (loss=0.04794): 100%|██████████| 3/3 [00:02<00:00,  1.07it/s]\n",
      "Training (16946 / 25000 Steps) (loss=0.04144): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (16949 / 25000 Steps) (loss=0.04625): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (16952 / 25000 Steps) (loss=0.03585): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (16955 / 25000 Steps) (loss=0.03721): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (16958 / 25000 Steps) (loss=0.03198): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (16961 / 25000 Steps) (loss=0.03314): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (16964 / 25000 Steps) (loss=0.03782): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (16967 / 25000 Steps) (loss=0.04488): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (16970 / 25000 Steps) (loss=0.04094): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (16973 / 25000 Steps) (loss=0.03952): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (16976 / 25000 Steps) (loss=0.03708): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (16979 / 25000 Steps) (loss=0.04500): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (16982 / 25000 Steps) (loss=0.03860): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (16985 / 25000 Steps) (loss=0.03502): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (16988 / 25000 Steps) (loss=0.03115): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (16991 / 25000 Steps) (loss=0.02881): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (16994 / 25000 Steps) (loss=0.02971): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (16997 / 25000 Steps) (loss=0.03192): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Validate (16998 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]/s]\n",
      "Training (17000 / 25000 Steps) (loss=0.04486): 100%|██████████| 3/3 [00:02<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (17000 / 25000 Steps) (loss=0.04486): 100%|██████████| 3/3 [00:02<00:00,  1.35it/s]\n",
      "Training (17003 / 25000 Steps) (loss=0.03842): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (17006 / 25000 Steps) (loss=0.03798): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (17009 / 25000 Steps) (loss=0.03371): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (17012 / 25000 Steps) (loss=0.03216): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (17015 / 25000 Steps) (loss=0.03590): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (17018 / 25000 Steps) (loss=0.04345): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (17021 / 25000 Steps) (loss=0.02688): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (17024 / 25000 Steps) (loss=0.02893): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (17027 / 25000 Steps) (loss=0.03400): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (17030 / 25000 Steps) (loss=0.03965): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (17033 / 25000 Steps) (loss=0.03130): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (17036 / 25000 Steps) (loss=0.02557): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (17039 / 25000 Steps) (loss=0.05299): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (17042 / 25000 Steps) (loss=0.03520): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (17045 / 25000 Steps) (loss=0.03485): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (17048 / 25000 Steps) (loss=0.03831): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (17051 / 25000 Steps) (loss=0.02198): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (17054 / 25000 Steps) (loss=0.02766): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (17057 / 25000 Steps) (loss=0.02820): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (17060 / 25000 Steps) (loss=0.02589): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (17063 / 25000 Steps) (loss=0.03656): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (17066 / 25000 Steps) (loss=0.04218): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (17069 / 25000 Steps) (loss=0.03764): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (17072 / 25000 Steps) (loss=0.04391): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (17075 / 25000 Steps) (loss=0.02993): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "Training (17078 / 25000 Steps) (loss=0.03314): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (17081 / 25000 Steps) (loss=0.03603): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (17084 / 25000 Steps) (loss=0.02854): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (17087 / 25000 Steps) (loss=0.03456): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (17090 / 25000 Steps) (loss=0.03146): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (17093 / 25000 Steps) (loss=0.03589): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (17096 / 25000 Steps) (loss=0.03828): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (17099 / 25000 Steps) (loss=0.02889): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (17102 / 25000 Steps) (loss=0.03279): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (17105 / 25000 Steps) (loss=0.03517): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (17108 / 25000 Steps) (loss=0.02707): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (17111 / 25000 Steps) (loss=0.03448): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (17114 / 25000 Steps) (loss=0.03876): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (17117 / 25000 Steps) (loss=0.02861): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (17120 / 25000 Steps) (loss=0.04234): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (17123 / 25000 Steps) (loss=0.03646): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (17126 / 25000 Steps) (loss=0.03155): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (17129 / 25000 Steps) (loss=0.02729): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (17132 / 25000 Steps) (loss=0.03548): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (17135 / 25000 Steps) (loss=0.03840): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (17138 / 25000 Steps) (loss=0.04090): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (17141 / 25000 Steps) (loss=0.03414): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (17144 / 25000 Steps) (loss=0.03760): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (17147 / 25000 Steps) (loss=0.03220): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (17150 / 25000 Steps) (loss=0.03272): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (17153 / 25000 Steps) (loss=0.03761): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (17156 / 25000 Steps) (loss=0.02436): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (17159 / 25000 Steps) (loss=0.05476): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (17162 / 25000 Steps) (loss=0.03578): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (17165 / 25000 Steps) (loss=0.03118): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (17168 / 25000 Steps) (loss=0.02845): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (17171 / 25000 Steps) (loss=0.02847): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (17174 / 25000 Steps) (loss=0.02605): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (17177 / 25000 Steps) (loss=0.03836): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (17180 / 25000 Steps) (loss=0.04230): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (17183 / 25000 Steps) (loss=0.03870): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (17186 / 25000 Steps) (loss=0.03373): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (17189 / 25000 Steps) (loss=0.02889): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (17192 / 25000 Steps) (loss=0.03671): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (17195 / 25000 Steps) (loss=0.03774): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (17198 / 25000 Steps) (loss=0.04368): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (17201 / 25000 Steps) (loss=0.02903): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (17204 / 25000 Steps) (loss=0.03765): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (17207 / 25000 Steps) (loss=0.03560): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (17210 / 25000 Steps) (loss=0.03825): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (17213 / 25000 Steps) (loss=0.03060): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (17216 / 25000 Steps) (loss=0.03394): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (17219 / 25000 Steps) (loss=0.04615): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (17222 / 25000 Steps) (loss=0.03934): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (17225 / 25000 Steps) (loss=0.02947): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (17228 / 25000 Steps) (loss=0.02939): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (17231 / 25000 Steps) (loss=0.03125): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (17234 / 25000 Steps) (loss=0.03048): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (17237 / 25000 Steps) (loss=0.03114): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (17240 / 25000 Steps) (loss=0.03157): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (17243 / 25000 Steps) (loss=0.04416): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (17246 / 25000 Steps) (loss=0.03609): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (17249 / 25000 Steps) (loss=0.04106): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (17252 / 25000 Steps) (loss=0.02832): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (17255 / 25000 Steps) (loss=0.03118): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (17258 / 25000 Steps) (loss=0.02801): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (17261 / 25000 Steps) (loss=0.04159): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (17264 / 25000 Steps) (loss=0.03143): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (17267 / 25000 Steps) (loss=0.02570): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (17270 / 25000 Steps) (loss=0.03695): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (17273 / 25000 Steps) (loss=0.02845): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (17276 / 25000 Steps) (loss=0.02831): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (17279 / 25000 Steps) (loss=0.02714): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (17282 / 25000 Steps) (loss=0.03720): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (17285 / 25000 Steps) (loss=0.03278): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (17288 / 25000 Steps) (loss=0.03252): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (17291 / 25000 Steps) (loss=0.03814): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (17294 / 25000 Steps) (loss=0.03578): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (17297 / 25000 Steps) (loss=0.03427): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (17300 / 25000 Steps) (loss=0.03057): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (17303 / 25000 Steps) (loss=0.03329): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (17306 / 25000 Steps) (loss=0.03402): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (17309 / 25000 Steps) (loss=0.03590): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (17312 / 25000 Steps) (loss=0.04160): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (17315 / 25000 Steps) (loss=0.03345): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (17318 / 25000 Steps) (loss=0.03821): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (17321 / 25000 Steps) (loss=0.04066): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (17324 / 25000 Steps) (loss=0.03874): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (17327 / 25000 Steps) (loss=0.03575): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (17330 / 25000 Steps) (loss=0.03176): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (17333 / 25000 Steps) (loss=0.02144): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (17336 / 25000 Steps) (loss=0.02985): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (17339 / 25000 Steps) (loss=0.02946): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (17342 / 25000 Steps) (loss=0.03553): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (17345 / 25000 Steps) (loss=0.03132): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (17348 / 25000 Steps) (loss=0.03441): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (17351 / 25000 Steps) (loss=0.03076): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (17354 / 25000 Steps) (loss=0.02939): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (17357 / 25000 Steps) (loss=0.03542): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (17360 / 25000 Steps) (loss=0.03040): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (17363 / 25000 Steps) (loss=0.03551): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (17366 / 25000 Steps) (loss=0.04362): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (17369 / 25000 Steps) (loss=0.03198): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (17372 / 25000 Steps) (loss=0.03208): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (17375 / 25000 Steps) (loss=0.04860): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (17378 / 25000 Steps) (loss=0.03379): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (17381 / 25000 Steps) (loss=0.03734): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (17384 / 25000 Steps) (loss=0.02725): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (17387 / 25000 Steps) (loss=0.03021): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (17390 / 25000 Steps) (loss=0.03306): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (17393 / 25000 Steps) (loss=0.03472): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (17396 / 25000 Steps) (loss=0.03080): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (17399 / 25000 Steps) (loss=0.03328): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (17402 / 25000 Steps) (loss=0.02924): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (17405 / 25000 Steps) (loss=0.04065): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (17408 / 25000 Steps) (loss=0.02606): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (17411 / 25000 Steps) (loss=0.03249): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (17414 / 25000 Steps) (loss=0.04207): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (17417 / 25000 Steps) (loss=0.03570): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (17420 / 25000 Steps) (loss=0.03297): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (17423 / 25000 Steps) (loss=0.03944): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (17426 / 25000 Steps) (loss=0.03953): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (17429 / 25000 Steps) (loss=0.04196): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (17432 / 25000 Steps) (loss=0.03555): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (17435 / 25000 Steps) (loss=0.03269): 100%|██████████| 3/3 [00:02<00:00,  1.14it/s]\n",
      "Training (17438 / 25000 Steps) (loss=0.03561): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (17441 / 25000 Steps) (loss=0.03386): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (17444 / 25000 Steps) (loss=0.03008): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (17447 / 25000 Steps) (loss=0.03459): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (17450 / 25000 Steps) (loss=0.03373): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (17453 / 25000 Steps) (loss=0.03332): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (17456 / 25000 Steps) (loss=0.03432): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (17459 / 25000 Steps) (loss=0.02759): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (17462 / 25000 Steps) (loss=0.02836): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (17465 / 25000 Steps) (loss=0.04205): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (17468 / 25000 Steps) (loss=0.03856): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (17471 / 25000 Steps) (loss=0.03054): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (17474 / 25000 Steps) (loss=0.03435): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (17477 / 25000 Steps) (loss=0.03601): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (17480 / 25000 Steps) (loss=0.03807): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (17483 / 25000 Steps) (loss=0.03328): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (17486 / 25000 Steps) (loss=0.02967): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (17489 / 25000 Steps) (loss=0.03126): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (17492 / 25000 Steps) (loss=0.04597): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (17495 / 25000 Steps) (loss=0.02890): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (17498 / 25000 Steps) (loss=0.04088): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Validate (17499 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]it]\n",
      "Training (17501 / 25000 Steps) (loss=0.02863):  67%|██████▋   | 2/3 [00:02<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (17501 / 25000 Steps) (loss=0.02863): 100%|██████████| 3/3 [00:02<00:00,  1.35it/s]\n",
      "Training (17504 / 25000 Steps) (loss=0.02985): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (17507 / 25000 Steps) (loss=0.02969): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (17510 / 25000 Steps) (loss=0.02604): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (17513 / 25000 Steps) (loss=0.04320): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (17516 / 25000 Steps) (loss=0.02748): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (17519 / 25000 Steps) (loss=0.04916): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (17522 / 25000 Steps) (loss=0.03446): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (17525 / 25000 Steps) (loss=0.03544): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (17528 / 25000 Steps) (loss=0.03261): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (17531 / 25000 Steps) (loss=0.03418): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (17534 / 25000 Steps) (loss=0.03681): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (17537 / 25000 Steps) (loss=0.03690): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (17540 / 25000 Steps) (loss=0.02271): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (17543 / 25000 Steps) (loss=0.02744): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (17546 / 25000 Steps) (loss=0.04291): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (17549 / 25000 Steps) (loss=0.02901): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (17552 / 25000 Steps) (loss=0.02501): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (17555 / 25000 Steps) (loss=0.04162): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (17558 / 25000 Steps) (loss=0.02907): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (17561 / 25000 Steps) (loss=0.02694): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (17564 / 25000 Steps) (loss=0.03485): 100%|██████████| 3/3 [00:02<00:00,  1.10it/s]\n",
      "Training (17567 / 25000 Steps) (loss=0.05056): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (17570 / 25000 Steps) (loss=0.03931): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (17573 / 25000 Steps) (loss=0.03385): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (17576 / 25000 Steps) (loss=0.03461): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (17579 / 25000 Steps) (loss=0.04987): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (17582 / 25000 Steps) (loss=0.03075): 100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
      "Training (17585 / 25000 Steps) (loss=0.03547): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (17588 / 25000 Steps) (loss=0.03670): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (17591 / 25000 Steps) (loss=0.03094): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (17594 / 25000 Steps) (loss=0.04130): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (17597 / 25000 Steps) (loss=0.02821): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (17600 / 25000 Steps) (loss=0.02752): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (17603 / 25000 Steps) (loss=0.02583): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (17606 / 25000 Steps) (loss=0.03630): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (17609 / 25000 Steps) (loss=0.04157): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (17612 / 25000 Steps) (loss=0.02970): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (17615 / 25000 Steps) (loss=0.03166): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (17618 / 25000 Steps) (loss=0.02543): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (17621 / 25000 Steps) (loss=0.03429): 100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
      "Training (17624 / 25000 Steps) (loss=0.03868): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (17627 / 25000 Steps) (loss=0.03428): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (17630 / 25000 Steps) (loss=0.03141): 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]\n",
      "Training (17633 / 25000 Steps) (loss=0.03626): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (17636 / 25000 Steps) (loss=0.04207): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (17639 / 25000 Steps) (loss=0.03004): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (17642 / 25000 Steps) (loss=0.02694): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (17645 / 25000 Steps) (loss=0.03052): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (17648 / 25000 Steps) (loss=0.03352): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (17651 / 25000 Steps) (loss=0.03063): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (17654 / 25000 Steps) (loss=0.03412): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (17657 / 25000 Steps) (loss=0.02898): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (17660 / 25000 Steps) (loss=0.04257): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (17663 / 25000 Steps) (loss=0.03161): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (17666 / 25000 Steps) (loss=0.02837): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (17669 / 25000 Steps) (loss=0.05167): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (17672 / 25000 Steps) (loss=0.03769): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (17675 / 25000 Steps) (loss=0.03233): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (17678 / 25000 Steps) (loss=0.02877): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (17681 / 25000 Steps) (loss=0.03436): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (17684 / 25000 Steps) (loss=0.03645): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (17687 / 25000 Steps) (loss=0.03701): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (17690 / 25000 Steps) (loss=0.03041): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (17693 / 25000 Steps) (loss=0.03185): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (17696 / 25000 Steps) (loss=0.03047): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (17699 / 25000 Steps) (loss=0.03439): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (17702 / 25000 Steps) (loss=0.03612): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (17705 / 25000 Steps) (loss=0.02669): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (17708 / 25000 Steps) (loss=0.04631): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (17711 / 25000 Steps) (loss=0.03520): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (17714 / 25000 Steps) (loss=0.03422): 100%|██████████| 3/3 [00:02<00:00,  1.35it/s]\n",
      "Training (17717 / 25000 Steps) (loss=0.03791): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (17720 / 25000 Steps) (loss=0.03572): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (17723 / 25000 Steps) (loss=0.03136): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (17726 / 25000 Steps) (loss=0.03175): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (17729 / 25000 Steps) (loss=0.03265): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (17732 / 25000 Steps) (loss=0.03925): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (17735 / 25000 Steps) (loss=0.03435): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (17738 / 25000 Steps) (loss=0.03009): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (17741 / 25000 Steps) (loss=0.02628): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (17744 / 25000 Steps) (loss=0.02910): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (17747 / 25000 Steps) (loss=0.02447): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (17750 / 25000 Steps) (loss=0.02894): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (17753 / 25000 Steps) (loss=0.04831): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (17756 / 25000 Steps) (loss=0.03905): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (17759 / 25000 Steps) (loss=0.03571): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (17762 / 25000 Steps) (loss=0.04130): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (17765 / 25000 Steps) (loss=0.03138): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (17768 / 25000 Steps) (loss=0.04681): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (17771 / 25000 Steps) (loss=0.04069): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (17774 / 25000 Steps) (loss=0.02960): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (17777 / 25000 Steps) (loss=0.03138): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (17780 / 25000 Steps) (loss=0.03016): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (17783 / 25000 Steps) (loss=0.04421): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (17786 / 25000 Steps) (loss=0.02872): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (17789 / 25000 Steps) (loss=0.02646): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (17792 / 25000 Steps) (loss=0.04769): 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
      "Training (17795 / 25000 Steps) (loss=0.03155): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (17798 / 25000 Steps) (loss=0.02668): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (17801 / 25000 Steps) (loss=0.02833): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (17804 / 25000 Steps) (loss=0.03678): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (17807 / 25000 Steps) (loss=0.03855): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (17810 / 25000 Steps) (loss=0.02129): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (17813 / 25000 Steps) (loss=0.02876): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (17816 / 25000 Steps) (loss=0.03862): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (17819 / 25000 Steps) (loss=0.03512): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (17822 / 25000 Steps) (loss=0.03377): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (17825 / 25000 Steps) (loss=0.04300): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (17828 / 25000 Steps) (loss=0.03439): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (17831 / 25000 Steps) (loss=0.03334): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (17834 / 25000 Steps) (loss=0.03790): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (17837 / 25000 Steps) (loss=0.03282): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (17840 / 25000 Steps) (loss=0.02882): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (17843 / 25000 Steps) (loss=0.03287): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (17846 / 25000 Steps) (loss=0.03689): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (17849 / 25000 Steps) (loss=0.03999): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (17852 / 25000 Steps) (loss=0.03693): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (17855 / 25000 Steps) (loss=0.03244): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (17858 / 25000 Steps) (loss=0.04174): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (17861 / 25000 Steps) (loss=0.04563): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (17864 / 25000 Steps) (loss=0.02263): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (17867 / 25000 Steps) (loss=0.03178): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (17870 / 25000 Steps) (loss=0.03573): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (17873 / 25000 Steps) (loss=0.02760): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (17876 / 25000 Steps) (loss=0.02565): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (17879 / 25000 Steps) (loss=0.03056): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (17882 / 25000 Steps) (loss=0.03511): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (17885 / 25000 Steps) (loss=0.03193): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (17888 / 25000 Steps) (loss=0.04205): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (17891 / 25000 Steps) (loss=0.03091): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (17894 / 25000 Steps) (loss=0.04492): 100%|██████████| 3/3 [00:02<00:00,  1.13it/s]\n",
      "Training (17897 / 25000 Steps) (loss=0.03481): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (17900 / 25000 Steps) (loss=0.03744): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (17903 / 25000 Steps) (loss=0.03433): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (17906 / 25000 Steps) (loss=0.04275): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (17909 / 25000 Steps) (loss=0.02751): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (17912 / 25000 Steps) (loss=0.04443): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (17915 / 25000 Steps) (loss=0.03037): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (17918 / 25000 Steps) (loss=0.03998): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (17921 / 25000 Steps) (loss=0.04160): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (17924 / 25000 Steps) (loss=0.02518): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (17927 / 25000 Steps) (loss=0.03035): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (17930 / 25000 Steps) (loss=0.03523): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (17933 / 25000 Steps) (loss=0.03257): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (17936 / 25000 Steps) (loss=0.03064): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (17939 / 25000 Steps) (loss=0.03701): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (17942 / 25000 Steps) (loss=0.03219): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (17945 / 25000 Steps) (loss=0.04442): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (17948 / 25000 Steps) (loss=0.02826): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (17951 / 25000 Steps) (loss=0.03826): 100%|██████████| 3/3 [00:02<00:00,  1.10it/s]\n",
      "Training (17954 / 25000 Steps) (loss=0.03425): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (17957 / 25000 Steps) (loss=0.04656): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (17960 / 25000 Steps) (loss=0.03421): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "Training (17963 / 25000 Steps) (loss=0.03484): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (17966 / 25000 Steps) (loss=0.03501): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (17969 / 25000 Steps) (loss=0.02902): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (17972 / 25000 Steps) (loss=0.03457): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (17975 / 25000 Steps) (loss=0.03728): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (17978 / 25000 Steps) (loss=0.02665): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (17981 / 25000 Steps) (loss=0.03987): 100%|██████████| 3/3 [00:01<00:00,  1.99it/s]\n",
      "Training (17984 / 25000 Steps) (loss=0.02856): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "Training (17987 / 25000 Steps) (loss=0.02570): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (17990 / 25000 Steps) (loss=0.04135): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (17993 / 25000 Steps) (loss=0.02939): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (17996 / 25000 Steps) (loss=0.03281): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (17999 / 25000 Steps) (loss=0.03592): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Validate (18000 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "Training (18002 / 25000 Steps) (loss=0.02584): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (18002 / 25000 Steps) (loss=0.02584): 100%|██████████| 3/3 [00:03<00:00,  1.03s/it]\n",
      "Training (18005 / 25000 Steps) (loss=0.03150): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (18008 / 25000 Steps) (loss=0.03334): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (18011 / 25000 Steps) (loss=0.03332): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (18014 / 25000 Steps) (loss=0.03636): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (18017 / 25000 Steps) (loss=0.02746): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (18020 / 25000 Steps) (loss=0.04282): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (18023 / 25000 Steps) (loss=0.03108): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (18026 / 25000 Steps) (loss=0.03005): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (18029 / 25000 Steps) (loss=0.02391): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (18032 / 25000 Steps) (loss=0.03461): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (18035 / 25000 Steps) (loss=0.03854): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (18038 / 25000 Steps) (loss=0.04330): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (18041 / 25000 Steps) (loss=0.03750): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (18044 / 25000 Steps) (loss=0.03327): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (18047 / 25000 Steps) (loss=0.04297): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (18050 / 25000 Steps) (loss=0.03487): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (18053 / 25000 Steps) (loss=0.03152): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (18056 / 25000 Steps) (loss=0.03143): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (18059 / 25000 Steps) (loss=0.03591): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (18062 / 25000 Steps) (loss=0.02612): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (18065 / 25000 Steps) (loss=0.02652): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (18068 / 25000 Steps) (loss=0.03701): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (18071 / 25000 Steps) (loss=0.03697): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (18074 / 25000 Steps) (loss=0.03558): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (18077 / 25000 Steps) (loss=0.03285): 100%|██████████| 3/3 [00:02<00:00,  1.35it/s]\n",
      "Training (18080 / 25000 Steps) (loss=0.03472): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (18083 / 25000 Steps) (loss=0.03237): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (18086 / 25000 Steps) (loss=0.03255): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (18089 / 25000 Steps) (loss=0.02888): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (18092 / 25000 Steps) (loss=0.03351): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (18095 / 25000 Steps) (loss=0.03444): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (18098 / 25000 Steps) (loss=0.04512): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (18101 / 25000 Steps) (loss=0.03524): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (18104 / 25000 Steps) (loss=0.03096): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (18107 / 25000 Steps) (loss=0.03441): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (18110 / 25000 Steps) (loss=0.03628): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (18113 / 25000 Steps) (loss=0.03947): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (18116 / 25000 Steps) (loss=0.03226): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (18119 / 25000 Steps) (loss=0.03455): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (18122 / 25000 Steps) (loss=0.05804): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (18125 / 25000 Steps) (loss=0.03055): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (18128 / 25000 Steps) (loss=0.03234): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (18131 / 25000 Steps) (loss=0.03589): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (18134 / 25000 Steps) (loss=0.04331): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (18137 / 25000 Steps) (loss=0.03683): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (18140 / 25000 Steps) (loss=0.03253): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (18143 / 25000 Steps) (loss=0.04481): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (18146 / 25000 Steps) (loss=0.02773): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (18149 / 25000 Steps) (loss=0.03363): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (18152 / 25000 Steps) (loss=0.03143): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (18155 / 25000 Steps) (loss=0.03218): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (18158 / 25000 Steps) (loss=0.03065): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (18161 / 25000 Steps) (loss=0.02684): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (18164 / 25000 Steps) (loss=0.03176): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (18167 / 25000 Steps) (loss=0.02811): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (18170 / 25000 Steps) (loss=0.05687): 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
      "Training (18173 / 25000 Steps) (loss=0.02459): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (18176 / 25000 Steps) (loss=0.03733): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (18179 / 25000 Steps) (loss=0.02740): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (18182 / 25000 Steps) (loss=0.03401): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (18185 / 25000 Steps) (loss=0.03325): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (18188 / 25000 Steps) (loss=0.03456): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (18191 / 25000 Steps) (loss=0.04138): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (18194 / 25000 Steps) (loss=0.03473): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (18197 / 25000 Steps) (loss=0.03361): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (18200 / 25000 Steps) (loss=0.03797): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (18203 / 25000 Steps) (loss=0.03417): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (18206 / 25000 Steps) (loss=0.03939): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (18209 / 25000 Steps) (loss=0.03342): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (18212 / 25000 Steps) (loss=0.02758): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (18215 / 25000 Steps) (loss=0.02408): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (18218 / 25000 Steps) (loss=0.02303): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (18221 / 25000 Steps) (loss=0.02753): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (18224 / 25000 Steps) (loss=0.03804): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (18227 / 25000 Steps) (loss=0.03354): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (18230 / 25000 Steps) (loss=0.02983): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (18233 / 25000 Steps) (loss=0.03070): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (18236 / 25000 Steps) (loss=0.03384): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (18239 / 25000 Steps) (loss=0.05400): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (18242 / 25000 Steps) (loss=0.03984): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (18245 / 25000 Steps) (loss=0.02499): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (18248 / 25000 Steps) (loss=0.04171): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (18251 / 25000 Steps) (loss=0.03984): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (18254 / 25000 Steps) (loss=0.02261): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (18257 / 25000 Steps) (loss=0.03732): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (18260 / 25000 Steps) (loss=0.03848): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (18263 / 25000 Steps) (loss=0.03015): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (18266 / 25000 Steps) (loss=0.03080): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (18269 / 25000 Steps) (loss=0.03057): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (18272 / 25000 Steps) (loss=0.03737): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (18275 / 25000 Steps) (loss=0.03060): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (18278 / 25000 Steps) (loss=0.04350): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (18281 / 25000 Steps) (loss=0.03940): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (18284 / 25000 Steps) (loss=0.02869): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (18287 / 25000 Steps) (loss=0.02888): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (18290 / 25000 Steps) (loss=0.02618): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (18293 / 25000 Steps) (loss=0.03536): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (18296 / 25000 Steps) (loss=0.03203): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (18299 / 25000 Steps) (loss=0.05281): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (18302 / 25000 Steps) (loss=0.03405): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (18305 / 25000 Steps) (loss=0.03372): 100%|██████████| 3/3 [00:02<00:00,  1.15it/s]\n",
      "Training (18308 / 25000 Steps) (loss=0.03841): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (18311 / 25000 Steps) (loss=0.03809): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (18314 / 25000 Steps) (loss=0.03261): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (18317 / 25000 Steps) (loss=0.03147): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (18320 / 25000 Steps) (loss=0.03373): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (18323 / 25000 Steps) (loss=0.03578): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (18326 / 25000 Steps) (loss=0.03217): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (18329 / 25000 Steps) (loss=0.02724): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (18332 / 25000 Steps) (loss=0.03025): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (18335 / 25000 Steps) (loss=0.02835): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (18338 / 25000 Steps) (loss=0.04689): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (18341 / 25000 Steps) (loss=0.02544): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (18344 / 25000 Steps) (loss=0.03281): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (18347 / 25000 Steps) (loss=0.02864): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (18350 / 25000 Steps) (loss=0.03930): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (18353 / 25000 Steps) (loss=0.03451): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (18356 / 25000 Steps) (loss=0.02688): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (18359 / 25000 Steps) (loss=0.03149): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (18362 / 25000 Steps) (loss=0.02786): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (18365 / 25000 Steps) (loss=0.02743): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (18368 / 25000 Steps) (loss=0.02527): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (18371 / 25000 Steps) (loss=0.03199): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (18374 / 25000 Steps) (loss=0.04005): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (18377 / 25000 Steps) (loss=0.02828): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (18380 / 25000 Steps) (loss=0.03001): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (18383 / 25000 Steps) (loss=0.04301): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (18386 / 25000 Steps) (loss=0.03121): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (18389 / 25000 Steps) (loss=0.02233): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (18392 / 25000 Steps) (loss=0.04436): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (18395 / 25000 Steps) (loss=0.03331): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (18398 / 25000 Steps) (loss=0.04759): 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]\n",
      "Training (18401 / 25000 Steps) (loss=0.04000): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (18404 / 25000 Steps) (loss=0.03812): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (18407 / 25000 Steps) (loss=0.03439): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (18410 / 25000 Steps) (loss=0.04157): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (18413 / 25000 Steps) (loss=0.03566): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (18416 / 25000 Steps) (loss=0.05206): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "Training (18419 / 25000 Steps) (loss=0.03376): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (18422 / 25000 Steps) (loss=0.03095): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (18425 / 25000 Steps) (loss=0.04036): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (18428 / 25000 Steps) (loss=0.02701): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (18431 / 25000 Steps) (loss=0.02781): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (18434 / 25000 Steps) (loss=0.03315): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (18437 / 25000 Steps) (loss=0.03373): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (18440 / 25000 Steps) (loss=0.03521): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (18443 / 25000 Steps) (loss=0.03087): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (18446 / 25000 Steps) (loss=0.04698): 100%|██████████| 3/3 [00:02<00:00,  1.13it/s]\n",
      "Training (18449 / 25000 Steps) (loss=0.03832): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (18452 / 25000 Steps) (loss=0.04429): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (18455 / 25000 Steps) (loss=0.03178): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (18458 / 25000 Steps) (loss=0.03357): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (18461 / 25000 Steps) (loss=0.03502): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (18464 / 25000 Steps) (loss=0.03737): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (18467 / 25000 Steps) (loss=0.02873): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (18470 / 25000 Steps) (loss=0.02283): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (18473 / 25000 Steps) (loss=0.04181): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (18476 / 25000 Steps) (loss=0.03165): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (18479 / 25000 Steps) (loss=0.02550): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (18482 / 25000 Steps) (loss=0.03163): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (18485 / 25000 Steps) (loss=0.02438): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (18488 / 25000 Steps) (loss=0.02703): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (18491 / 25000 Steps) (loss=0.02810): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (18494 / 25000 Steps) (loss=0.03752): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (18497 / 25000 Steps) (loss=0.03216): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Validate (18498 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]it]\n",
      "Training (18500 / 25000 Steps) (loss=0.02583): 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (18503 / 25000 Steps) (loss=0.03126): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (18506 / 25000 Steps) (loss=0.03132): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (18509 / 25000 Steps) (loss=0.03078): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (18512 / 25000 Steps) (loss=0.06109): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (18515 / 25000 Steps) (loss=0.04773): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (18518 / 25000 Steps) (loss=0.04494): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (18521 / 25000 Steps) (loss=0.03827): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (18524 / 25000 Steps) (loss=0.02625): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (18527 / 25000 Steps) (loss=0.03384): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (18530 / 25000 Steps) (loss=0.03864): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (18533 / 25000 Steps) (loss=0.02966): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (18536 / 25000 Steps) (loss=0.03845): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (18539 / 25000 Steps) (loss=0.04709): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (18542 / 25000 Steps) (loss=0.03765): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (18545 / 25000 Steps) (loss=0.02517): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (18548 / 25000 Steps) (loss=0.02662): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (18551 / 25000 Steps) (loss=0.03417): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (18554 / 25000 Steps) (loss=0.02796): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (18557 / 25000 Steps) (loss=0.03640): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (18560 / 25000 Steps) (loss=0.02978): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (18563 / 25000 Steps) (loss=0.04370): 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
      "Training (18566 / 25000 Steps) (loss=0.03037): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (18569 / 25000 Steps) (loss=0.03691): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (18572 / 25000 Steps) (loss=0.03705): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (18575 / 25000 Steps) (loss=0.04171): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (18578 / 25000 Steps) (loss=0.04026): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (18581 / 25000 Steps) (loss=0.03849): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (18584 / 25000 Steps) (loss=0.02468): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (18587 / 25000 Steps) (loss=0.03889): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (18590 / 25000 Steps) (loss=0.03213): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (18593 / 25000 Steps) (loss=0.02204): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (18596 / 25000 Steps) (loss=0.02786): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (18599 / 25000 Steps) (loss=0.03872): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (18602 / 25000 Steps) (loss=0.04698): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (18605 / 25000 Steps) (loss=0.03153): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (18608 / 25000 Steps) (loss=0.03550): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (18611 / 25000 Steps) (loss=0.03479): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (18614 / 25000 Steps) (loss=0.03391): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (18617 / 25000 Steps) (loss=0.03357): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (18620 / 25000 Steps) (loss=0.02748): 100%|██████████| 3/3 [00:02<00:00,  1.15it/s]\n",
      "Training (18623 / 25000 Steps) (loss=0.03543): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (18626 / 25000 Steps) (loss=0.03562): 100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
      "Training (18629 / 25000 Steps) (loss=0.03056): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (18632 / 25000 Steps) (loss=0.03315): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (18635 / 25000 Steps) (loss=0.04240): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (18638 / 25000 Steps) (loss=0.02941): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "Training (18641 / 25000 Steps) (loss=0.03240): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (18644 / 25000 Steps) (loss=0.02737): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (18647 / 25000 Steps) (loss=0.03187): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (18650 / 25000 Steps) (loss=0.02606): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (18653 / 25000 Steps) (loss=0.03421): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (18656 / 25000 Steps) (loss=0.02496): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (18659 / 25000 Steps) (loss=0.03097): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (18662 / 25000 Steps) (loss=0.02796): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (18665 / 25000 Steps) (loss=0.03860): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (18668 / 25000 Steps) (loss=0.02475): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (18671 / 25000 Steps) (loss=0.04724): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (18674 / 25000 Steps) (loss=0.04091): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (18677 / 25000 Steps) (loss=0.04319): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (18680 / 25000 Steps) (loss=0.03598): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (18683 / 25000 Steps) (loss=0.03930): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (18686 / 25000 Steps) (loss=0.02364): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (18689 / 25000 Steps) (loss=0.03766): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (18692 / 25000 Steps) (loss=0.03657): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (18695 / 25000 Steps) (loss=0.03990): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (18698 / 25000 Steps) (loss=0.03467): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (18701 / 25000 Steps) (loss=0.03785): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (18704 / 25000 Steps) (loss=0.03188): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (18707 / 25000 Steps) (loss=0.03697): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (18710 / 25000 Steps) (loss=0.04000): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (18713 / 25000 Steps) (loss=0.03576): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (18716 / 25000 Steps) (loss=0.03132): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (18719 / 25000 Steps) (loss=0.03453): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (18722 / 25000 Steps) (loss=0.02710): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (18725 / 25000 Steps) (loss=0.04729): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (18728 / 25000 Steps) (loss=0.03379): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (18731 / 25000 Steps) (loss=0.02689): 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
      "Training (18734 / 25000 Steps) (loss=0.04163): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (18737 / 25000 Steps) (loss=0.01903): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (18740 / 25000 Steps) (loss=0.02888): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (18743 / 25000 Steps) (loss=0.03037): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (18746 / 25000 Steps) (loss=0.02217): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (18749 / 25000 Steps) (loss=0.02434): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (18752 / 25000 Steps) (loss=0.04723): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (18755 / 25000 Steps) (loss=0.03245): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (18758 / 25000 Steps) (loss=0.02639): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "Training (18761 / 25000 Steps) (loss=0.02626): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (18764 / 25000 Steps) (loss=0.02822): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (18767 / 25000 Steps) (loss=0.03642): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (18770 / 25000 Steps) (loss=0.02763): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (18773 / 25000 Steps) (loss=0.04026): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (18776 / 25000 Steps) (loss=0.03800): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (18779 / 25000 Steps) (loss=0.02824): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (18782 / 25000 Steps) (loss=0.02661): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (18785 / 25000 Steps) (loss=0.03714): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (18788 / 25000 Steps) (loss=0.03352): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (18791 / 25000 Steps) (loss=0.02815): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (18794 / 25000 Steps) (loss=0.02760): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (18797 / 25000 Steps) (loss=0.02507): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (18800 / 25000 Steps) (loss=0.03897): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (18803 / 25000 Steps) (loss=0.05369): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (18806 / 25000 Steps) (loss=0.04569): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (18809 / 25000 Steps) (loss=0.02535): 100%|██████████| 3/3 [00:02<00:00,  1.32it/s]\n",
      "Training (18812 / 25000 Steps) (loss=0.03494): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (18815 / 25000 Steps) (loss=0.03084): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (18818 / 25000 Steps) (loss=0.04244): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (18821 / 25000 Steps) (loss=0.04276): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (18824 / 25000 Steps) (loss=0.03675): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (18827 / 25000 Steps) (loss=0.02810): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (18830 / 25000 Steps) (loss=0.03057): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (18833 / 25000 Steps) (loss=0.04537): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (18836 / 25000 Steps) (loss=0.02737): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (18839 / 25000 Steps) (loss=0.02717): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (18842 / 25000 Steps) (loss=0.03155): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (18845 / 25000 Steps) (loss=0.02944): 100%|██████████| 3/3 [00:02<00:00,  1.24it/s]\n",
      "Training (18848 / 25000 Steps) (loss=0.03779): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (18851 / 25000 Steps) (loss=0.03206): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (18854 / 25000 Steps) (loss=0.02904): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (18857 / 25000 Steps) (loss=0.03784): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (18860 / 25000 Steps) (loss=0.03483): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (18863 / 25000 Steps) (loss=0.03009): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (18866 / 25000 Steps) (loss=0.03357): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (18869 / 25000 Steps) (loss=0.03686): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (18872 / 25000 Steps) (loss=0.03563): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (18875 / 25000 Steps) (loss=0.02771): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (18878 / 25000 Steps) (loss=0.03495): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (18881 / 25000 Steps) (loss=0.03239): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (18884 / 25000 Steps) (loss=0.03734): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (18887 / 25000 Steps) (loss=0.02719): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (18890 / 25000 Steps) (loss=0.04029): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (18893 / 25000 Steps) (loss=0.03426): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (18896 / 25000 Steps) (loss=0.03178): 100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
      "Training (18899 / 25000 Steps) (loss=0.03218): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (18902 / 25000 Steps) (loss=0.03478): 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]\n",
      "Training (18905 / 25000 Steps) (loss=0.02969): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (18908 / 25000 Steps) (loss=0.02861): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (18911 / 25000 Steps) (loss=0.05119): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (18914 / 25000 Steps) (loss=0.02779): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (18917 / 25000 Steps) (loss=0.03133): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (18920 / 25000 Steps) (loss=0.02539): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (18923 / 25000 Steps) (loss=0.02594): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (18926 / 25000 Steps) (loss=0.03293): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (18929 / 25000 Steps) (loss=0.02929): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (18932 / 25000 Steps) (loss=0.03321): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (18935 / 25000 Steps) (loss=0.02765): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (18938 / 25000 Steps) (loss=0.03332): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (18941 / 25000 Steps) (loss=0.03145): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (18944 / 25000 Steps) (loss=0.03041): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (18947 / 25000 Steps) (loss=0.02407): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (18950 / 25000 Steps) (loss=0.03596): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (18953 / 25000 Steps) (loss=0.02775): 100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
      "Training (18956 / 25000 Steps) (loss=0.02413): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (18959 / 25000 Steps) (loss=0.04575): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (18962 / 25000 Steps) (loss=0.03273): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (18965 / 25000 Steps) (loss=0.04196): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (18968 / 25000 Steps) (loss=0.03978): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (18971 / 25000 Steps) (loss=0.02664): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (18974 / 25000 Steps) (loss=0.02924): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (18977 / 25000 Steps) (loss=0.03139): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (18980 / 25000 Steps) (loss=0.03071): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (18983 / 25000 Steps) (loss=0.04369): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (18986 / 25000 Steps) (loss=0.03993): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (18989 / 25000 Steps) (loss=0.03654): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (18992 / 25000 Steps) (loss=0.02684): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (18995 / 25000 Steps) (loss=0.04666): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (18998 / 25000 Steps) (loss=0.03154): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Validate (18999 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]it]\n",
      "Training (19001 / 25000 Steps) (loss=0.03433):  67%|██████▋   | 2/3 [00:02<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (19001 / 25000 Steps) (loss=0.03433): 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
      "Training (19004 / 25000 Steps) (loss=0.03484): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (19007 / 25000 Steps) (loss=0.03067): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (19010 / 25000 Steps) (loss=0.03052): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (19013 / 25000 Steps) (loss=0.03783): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (19016 / 25000 Steps) (loss=0.03229): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (19019 / 25000 Steps) (loss=0.04558): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (19022 / 25000 Steps) (loss=0.03513): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (19025 / 25000 Steps) (loss=0.02737): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (19028 / 25000 Steps) (loss=0.03247): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (19031 / 25000 Steps) (loss=0.03775): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (19034 / 25000 Steps) (loss=0.03622): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (19037 / 25000 Steps) (loss=0.03821): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (19040 / 25000 Steps) (loss=0.03102): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (19043 / 25000 Steps) (loss=0.04309): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (19046 / 25000 Steps) (loss=0.03997): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (19049 / 25000 Steps) (loss=0.03984): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (19052 / 25000 Steps) (loss=0.03172): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (19055 / 25000 Steps) (loss=0.02542): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (19058 / 25000 Steps) (loss=0.04196): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (19061 / 25000 Steps) (loss=0.03195): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (19064 / 25000 Steps) (loss=0.02493): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (19067 / 25000 Steps) (loss=0.02761): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (19070 / 25000 Steps) (loss=0.02652): 100%|██████████| 3/3 [00:02<00:00,  1.17it/s]\n",
      "Training (19073 / 25000 Steps) (loss=0.04206): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (19076 / 25000 Steps) (loss=0.03616): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (19079 / 25000 Steps) (loss=0.02290): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (19082 / 25000 Steps) (loss=0.02674): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (19085 / 25000 Steps) (loss=0.02550): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (19088 / 25000 Steps) (loss=0.04976): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (19091 / 25000 Steps) (loss=0.03100): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (19094 / 25000 Steps) (loss=0.02336): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (19097 / 25000 Steps) (loss=0.03245): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (19100 / 25000 Steps) (loss=0.03023): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (19103 / 25000 Steps) (loss=0.05252): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (19106 / 25000 Steps) (loss=0.03193): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (19109 / 25000 Steps) (loss=0.03969): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (19112 / 25000 Steps) (loss=0.03604): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (19115 / 25000 Steps) (loss=0.02350): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (19118 / 25000 Steps) (loss=0.02354): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (19121 / 25000 Steps) (loss=0.03212): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (19124 / 25000 Steps) (loss=0.02435): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (19127 / 25000 Steps) (loss=0.02946): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (19130 / 25000 Steps) (loss=0.03715): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (19133 / 25000 Steps) (loss=0.04287): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (19136 / 25000 Steps) (loss=0.03162): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (19139 / 25000 Steps) (loss=0.04454): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (19142 / 25000 Steps) (loss=0.02240): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (19145 / 25000 Steps) (loss=0.02620): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (19148 / 25000 Steps) (loss=0.02979): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (19151 / 25000 Steps) (loss=0.03148): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (19154 / 25000 Steps) (loss=0.03027): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (19157 / 25000 Steps) (loss=0.02649): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (19160 / 25000 Steps) (loss=0.03744): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (19163 / 25000 Steps) (loss=0.03694): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (19166 / 25000 Steps) (loss=0.03321): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (19169 / 25000 Steps) (loss=0.03933): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (19172 / 25000 Steps) (loss=0.02609): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (19175 / 25000 Steps) (loss=0.03864): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (19178 / 25000 Steps) (loss=0.03249): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (19181 / 25000 Steps) (loss=0.03776): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (19184 / 25000 Steps) (loss=0.03606): 100%|██████████| 3/3 [00:02<00:00,  1.10it/s]\n",
      "Training (19187 / 25000 Steps) (loss=0.03269): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (19190 / 25000 Steps) (loss=0.04863): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (19193 / 25000 Steps) (loss=0.03116): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (19196 / 25000 Steps) (loss=0.02846): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (19199 / 25000 Steps) (loss=0.04198): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (19202 / 25000 Steps) (loss=0.02924): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (19205 / 25000 Steps) (loss=0.03061): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (19208 / 25000 Steps) (loss=0.04119): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (19211 / 25000 Steps) (loss=0.03416): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (19214 / 25000 Steps) (loss=0.02866): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (19217 / 25000 Steps) (loss=0.03264): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (19220 / 25000 Steps) (loss=0.04574): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (19223 / 25000 Steps) (loss=0.03316): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (19226 / 25000 Steps) (loss=0.02865): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (19229 / 25000 Steps) (loss=0.03518): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (19232 / 25000 Steps) (loss=0.03325): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (19235 / 25000 Steps) (loss=0.03556): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (19238 / 25000 Steps) (loss=0.02801): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (19241 / 25000 Steps) (loss=0.01965): 100%|██████████| 3/3 [00:02<00:00,  1.08it/s]\n",
      "Training (19244 / 25000 Steps) (loss=0.02615): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (19247 / 25000 Steps) (loss=0.04070): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (19250 / 25000 Steps) (loss=0.04056): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (19253 / 25000 Steps) (loss=0.02707): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (19256 / 25000 Steps) (loss=0.03229): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (19259 / 25000 Steps) (loss=0.03078): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (19262 / 25000 Steps) (loss=0.03673): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (19265 / 25000 Steps) (loss=0.02709): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (19268 / 25000 Steps) (loss=0.03190): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (19271 / 25000 Steps) (loss=0.03131): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (19274 / 25000 Steps) (loss=0.03723): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (19277 / 25000 Steps) (loss=0.05276): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (19280 / 25000 Steps) (loss=0.03805): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (19283 / 25000 Steps) (loss=0.03173): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (19286 / 25000 Steps) (loss=0.03358): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (19289 / 25000 Steps) (loss=0.03053): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (19292 / 25000 Steps) (loss=0.03312): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (19295 / 25000 Steps) (loss=0.03323): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (19298 / 25000 Steps) (loss=0.02674): 100%|██████████| 3/3 [00:02<00:00,  1.13it/s]\n",
      "Training (19301 / 25000 Steps) (loss=0.02405): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (19304 / 25000 Steps) (loss=0.03584): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (19307 / 25000 Steps) (loss=0.03845): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (19310 / 25000 Steps) (loss=0.02368): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (19313 / 25000 Steps) (loss=0.02826): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (19316 / 25000 Steps) (loss=0.03717): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (19319 / 25000 Steps) (loss=0.04212): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (19322 / 25000 Steps) (loss=0.03185): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (19325 / 25000 Steps) (loss=0.03135): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (19328 / 25000 Steps) (loss=0.03809): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (19331 / 25000 Steps) (loss=0.02795): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (19334 / 25000 Steps) (loss=0.03661): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (19337 / 25000 Steps) (loss=0.03363): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (19340 / 25000 Steps) (loss=0.02990): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (19343 / 25000 Steps) (loss=0.03201): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (19346 / 25000 Steps) (loss=0.04191): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (19349 / 25000 Steps) (loss=0.03610): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (19352 / 25000 Steps) (loss=0.03587): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (19355 / 25000 Steps) (loss=0.02440): 100%|██████████| 3/3 [00:02<00:00,  1.13it/s]\n",
      "Training (19358 / 25000 Steps) (loss=0.03438): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (19361 / 25000 Steps) (loss=0.03316): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (19364 / 25000 Steps) (loss=0.02440): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (19367 / 25000 Steps) (loss=0.03023): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (19370 / 25000 Steps) (loss=0.02751): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (19373 / 25000 Steps) (loss=0.02951): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (19376 / 25000 Steps) (loss=0.03919): 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "Training (19379 / 25000 Steps) (loss=0.02965): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (19382 / 25000 Steps) (loss=0.03554): 100%|██████████| 3/3 [00:02<00:00,  1.32it/s]\n",
      "Training (19385 / 25000 Steps) (loss=0.03735): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (19388 / 25000 Steps) (loss=0.03102): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (19391 / 25000 Steps) (loss=0.03043): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (19394 / 25000 Steps) (loss=0.02757): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (19397 / 25000 Steps) (loss=0.04246): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (19400 / 25000 Steps) (loss=0.04690): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (19403 / 25000 Steps) (loss=0.04087): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (19406 / 25000 Steps) (loss=0.03345): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (19409 / 25000 Steps) (loss=0.04244): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (19412 / 25000 Steps) (loss=0.02176): 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "Training (19415 / 25000 Steps) (loss=0.04426): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (19418 / 25000 Steps) (loss=0.03593): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (19421 / 25000 Steps) (loss=0.03576): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (19424 / 25000 Steps) (loss=0.03536): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (19427 / 25000 Steps) (loss=0.03617): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (19430 / 25000 Steps) (loss=0.02821): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (19433 / 25000 Steps) (loss=0.03620): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (19436 / 25000 Steps) (loss=0.02817): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (19439 / 25000 Steps) (loss=0.02715): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (19442 / 25000 Steps) (loss=0.03896): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (19445 / 25000 Steps) (loss=0.04054): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (19448 / 25000 Steps) (loss=0.02681): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (19451 / 25000 Steps) (loss=0.03377): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (19454 / 25000 Steps) (loss=0.02298): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (19457 / 25000 Steps) (loss=0.03232): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (19460 / 25000 Steps) (loss=0.04281): 100%|██████████| 3/3 [00:02<00:00,  1.32it/s]\n",
      "Training (19463 / 25000 Steps) (loss=0.03020): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (19466 / 25000 Steps) (loss=0.03173): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (19469 / 25000 Steps) (loss=0.04441): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (19472 / 25000 Steps) (loss=0.02778): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (19475 / 25000 Steps) (loss=0.03130): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (19478 / 25000 Steps) (loss=0.03329): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (19481 / 25000 Steps) (loss=0.03653): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (19484 / 25000 Steps) (loss=0.03800): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (19487 / 25000 Steps) (loss=0.03653): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (19490 / 25000 Steps) (loss=0.04818): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (19493 / 25000 Steps) (loss=0.02906): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (19496 / 25000 Steps) (loss=0.02849): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (19499 / 25000 Steps) (loss=0.03305): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Validate (19500 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "Training (19502 / 25000 Steps) (loss=0.03566): 100%|██████████| 3/3 [00:02<00:00,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (19502 / 25000 Steps) (loss=0.03566): 100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
      "Training (19505 / 25000 Steps) (loss=0.03190): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (19508 / 25000 Steps) (loss=0.03557): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (19511 / 25000 Steps) (loss=0.04237): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (19514 / 25000 Steps) (loss=0.02910): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (19517 / 25000 Steps) (loss=0.05020): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (19520 / 25000 Steps) (loss=0.04110): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (19523 / 25000 Steps) (loss=0.04337): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (19526 / 25000 Steps) (loss=0.04576): 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
      "Training (19529 / 25000 Steps) (loss=0.02856): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (19532 / 25000 Steps) (loss=0.05040): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (19535 / 25000 Steps) (loss=0.03611): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (19538 / 25000 Steps) (loss=0.03274): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (19541 / 25000 Steps) (loss=0.03246): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (19544 / 25000 Steps) (loss=0.03063): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (19547 / 25000 Steps) (loss=0.03001): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (19550 / 25000 Steps) (loss=0.02954): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (19553 / 25000 Steps) (loss=0.03404): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (19556 / 25000 Steps) (loss=0.03625): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (19559 / 25000 Steps) (loss=0.03965): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (19562 / 25000 Steps) (loss=0.02607): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (19565 / 25000 Steps) (loss=0.03512): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (19568 / 25000 Steps) (loss=0.03301): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (19571 / 25000 Steps) (loss=0.03779): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (19574 / 25000 Steps) (loss=0.03097): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (19577 / 25000 Steps) (loss=0.03239): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (19580 / 25000 Steps) (loss=0.02665): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (19583 / 25000 Steps) (loss=0.02899): 100%|██████████| 3/3 [00:02<00:00,  1.04it/s]\n",
      "Training (19586 / 25000 Steps) (loss=0.02629): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (19589 / 25000 Steps) (loss=0.03141): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (19592 / 25000 Steps) (loss=0.02689): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (19595 / 25000 Steps) (loss=0.03899): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (19598 / 25000 Steps) (loss=0.02768): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (19601 / 25000 Steps) (loss=0.03847): 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
      "Training (19604 / 25000 Steps) (loss=0.03359): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (19607 / 25000 Steps) (loss=0.04224): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (19610 / 25000 Steps) (loss=0.03194): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (19613 / 25000 Steps) (loss=0.02816): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (19616 / 25000 Steps) (loss=0.03600): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (19619 / 25000 Steps) (loss=0.03974): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (19622 / 25000 Steps) (loss=0.03110): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (19625 / 25000 Steps) (loss=0.02356): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (19628 / 25000 Steps) (loss=0.04065): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (19631 / 25000 Steps) (loss=0.02501): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (19634 / 25000 Steps) (loss=0.03289): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (19637 / 25000 Steps) (loss=0.04430): 100%|██████████| 3/3 [00:02<00:00,  1.15it/s]\n",
      "Training (19640 / 25000 Steps) (loss=0.04334): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (19643 / 25000 Steps) (loss=0.02467): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (19646 / 25000 Steps) (loss=0.03105): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (19649 / 25000 Steps) (loss=0.03778): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (19652 / 25000 Steps) (loss=0.02808): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (19655 / 25000 Steps) (loss=0.03473): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (19658 / 25000 Steps) (loss=0.02897): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (19661 / 25000 Steps) (loss=0.02499): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (19664 / 25000 Steps) (loss=0.03373): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (19667 / 25000 Steps) (loss=0.02673): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (19670 / 25000 Steps) (loss=0.02844): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (19673 / 25000 Steps) (loss=0.02389): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (19676 / 25000 Steps) (loss=0.03668): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (19679 / 25000 Steps) (loss=0.03484): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (19682 / 25000 Steps) (loss=0.02370): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (19685 / 25000 Steps) (loss=0.02913): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (19688 / 25000 Steps) (loss=0.03603): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (19691 / 25000 Steps) (loss=0.03905): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (19694 / 25000 Steps) (loss=0.02987): 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
      "Training (19697 / 25000 Steps) (loss=0.03280): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (19700 / 25000 Steps) (loss=0.03496): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (19703 / 25000 Steps) (loss=0.04107): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (19706 / 25000 Steps) (loss=0.03721): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (19709 / 25000 Steps) (loss=0.02849): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (19712 / 25000 Steps) (loss=0.03008): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (19715 / 25000 Steps) (loss=0.04224): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (19718 / 25000 Steps) (loss=0.03470): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (19721 / 25000 Steps) (loss=0.03701): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (19724 / 25000 Steps) (loss=0.03680): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (19727 / 25000 Steps) (loss=0.04139): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (19730 / 25000 Steps) (loss=0.03927): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (19733 / 25000 Steps) (loss=0.04254): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (19736 / 25000 Steps) (loss=0.02966): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (19739 / 25000 Steps) (loss=0.02800): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (19742 / 25000 Steps) (loss=0.03296): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (19745 / 25000 Steps) (loss=0.03118): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (19748 / 25000 Steps) (loss=0.03869): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (19751 / 25000 Steps) (loss=0.02658): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (19754 / 25000 Steps) (loss=0.03238): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (19757 / 25000 Steps) (loss=0.03432): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (19760 / 25000 Steps) (loss=0.02618): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (19763 / 25000 Steps) (loss=0.02852): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (19766 / 25000 Steps) (loss=0.04441): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (19769 / 25000 Steps) (loss=0.02559): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (19772 / 25000 Steps) (loss=0.03807): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (19775 / 25000 Steps) (loss=0.02964): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (19778 / 25000 Steps) (loss=0.03150): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (19781 / 25000 Steps) (loss=0.03020): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (19784 / 25000 Steps) (loss=0.03751): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (19787 / 25000 Steps) (loss=0.04181): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (19790 / 25000 Steps) (loss=0.03581): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (19793 / 25000 Steps) (loss=0.03189): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (19796 / 25000 Steps) (loss=0.03048): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (19799 / 25000 Steps) (loss=0.03701): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (19802 / 25000 Steps) (loss=0.03621): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (19805 / 25000 Steps) (loss=0.02953): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (19808 / 25000 Steps) (loss=0.03147): 100%|██████████| 3/3 [00:02<00:00,  1.32it/s]\n",
      "Training (19811 / 25000 Steps) (loss=0.02697): 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]\n",
      "Training (19814 / 25000 Steps) (loss=0.02617): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (19817 / 25000 Steps) (loss=0.03422): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (19820 / 25000 Steps) (loss=0.02943): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (19823 / 25000 Steps) (loss=0.05144): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (19826 / 25000 Steps) (loss=0.03241): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (19829 / 25000 Steps) (loss=0.04356): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "Training (19832 / 25000 Steps) (loss=0.02981): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (19835 / 25000 Steps) (loss=0.04073): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (19838 / 25000 Steps) (loss=0.03029): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (19841 / 25000 Steps) (loss=0.02823): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (19844 / 25000 Steps) (loss=0.03304): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (19847 / 25000 Steps) (loss=0.04142): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (19850 / 25000 Steps) (loss=0.03772): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (19853 / 25000 Steps) (loss=0.03386): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (19856 / 25000 Steps) (loss=0.03521): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (19859 / 25000 Steps) (loss=0.03319): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (19862 / 25000 Steps) (loss=0.03758): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (19865 / 25000 Steps) (loss=0.03425): 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
      "Training (19868 / 25000 Steps) (loss=0.04823): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (19871 / 25000 Steps) (loss=0.03252): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (19874 / 25000 Steps) (loss=0.04623): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (19877 / 25000 Steps) (loss=0.04942): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (19880 / 25000 Steps) (loss=0.03937): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (19883 / 25000 Steps) (loss=0.02621): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (19886 / 25000 Steps) (loss=0.02802): 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "Training (19889 / 25000 Steps) (loss=0.03708): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (19892 / 25000 Steps) (loss=0.03050): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (19895 / 25000 Steps) (loss=0.02607): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (19898 / 25000 Steps) (loss=0.02978): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (19901 / 25000 Steps) (loss=0.03258): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (19904 / 25000 Steps) (loss=0.02912): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (19907 / 25000 Steps) (loss=0.02928): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (19910 / 25000 Steps) (loss=0.02612): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (19913 / 25000 Steps) (loss=0.03098): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (19916 / 25000 Steps) (loss=0.03388): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (19919 / 25000 Steps) (loss=0.02573): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (19922 / 25000 Steps) (loss=0.02751): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (19925 / 25000 Steps) (loss=0.03054): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (19928 / 25000 Steps) (loss=0.02977): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (19931 / 25000 Steps) (loss=0.03335): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (19934 / 25000 Steps) (loss=0.03213): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (19937 / 25000 Steps) (loss=0.02400): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (19940 / 25000 Steps) (loss=0.02718): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (19943 / 25000 Steps) (loss=0.02672): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (19946 / 25000 Steps) (loss=0.02595): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (19949 / 25000 Steps) (loss=0.02740): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (19952 / 25000 Steps) (loss=0.02438): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (19955 / 25000 Steps) (loss=0.03241): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (19958 / 25000 Steps) (loss=0.02661): 100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
      "Training (19961 / 25000 Steps) (loss=0.02840): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (19964 / 25000 Steps) (loss=0.03441): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (19967 / 25000 Steps) (loss=0.04082): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (19970 / 25000 Steps) (loss=0.03137): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (19973 / 25000 Steps) (loss=0.03793): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (19976 / 25000 Steps) (loss=0.02485): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (19979 / 25000 Steps) (loss=0.04306): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (19982 / 25000 Steps) (loss=0.04751): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (19985 / 25000 Steps) (loss=0.03182): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (19988 / 25000 Steps) (loss=0.03680): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (19991 / 25000 Steps) (loss=0.03135): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (19994 / 25000 Steps) (loss=0.03886): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (19997 / 25000 Steps) (loss=0.03143): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Validate (19998 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]/s]\n",
      "Training (20000 / 25000 Steps) (loss=0.03571): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (20000 / 25000 Steps) (loss=0.03571): 100%|██████████| 3/3 [00:02<00:00,  1.20it/s]\n",
      "Training (20003 / 25000 Steps) (loss=0.03320): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (20006 / 25000 Steps) (loss=0.03096): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (20009 / 25000 Steps) (loss=0.03740): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (20012 / 25000 Steps) (loss=0.03520): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (20015 / 25000 Steps) (loss=0.02807): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (20018 / 25000 Steps) (loss=0.03965): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (20021 / 25000 Steps) (loss=0.03238): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (20024 / 25000 Steps) (loss=0.02988): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (20027 / 25000 Steps) (loss=0.03179): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (20030 / 25000 Steps) (loss=0.02644): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (20033 / 25000 Steps) (loss=0.03649): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (20036 / 25000 Steps) (loss=0.02344): 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]\n",
      "Training (20039 / 25000 Steps) (loss=0.03362): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (20042 / 25000 Steps) (loss=0.02554): 100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
      "Training (20045 / 25000 Steps) (loss=0.03456): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (20048 / 25000 Steps) (loss=0.02944): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (20051 / 25000 Steps) (loss=0.03494): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (20054 / 25000 Steps) (loss=0.02850): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (20057 / 25000 Steps) (loss=0.02832): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (20060 / 25000 Steps) (loss=0.03121): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (20063 / 25000 Steps) (loss=0.02708): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (20066 / 25000 Steps) (loss=0.03043): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (20069 / 25000 Steps) (loss=0.03536): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (20072 / 25000 Steps) (loss=0.02670): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (20075 / 25000 Steps) (loss=0.03060): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (20078 / 25000 Steps) (loss=0.03422): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (20081 / 25000 Steps) (loss=0.02239): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (20084 / 25000 Steps) (loss=0.02635): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (20087 / 25000 Steps) (loss=0.03475): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (20090 / 25000 Steps) (loss=0.02984): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (20093 / 25000 Steps) (loss=0.02862): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "Training (20096 / 25000 Steps) (loss=0.03917): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (20099 / 25000 Steps) (loss=0.03161): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (20102 / 25000 Steps) (loss=0.02637): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (20105 / 25000 Steps) (loss=0.03498): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (20108 / 25000 Steps) (loss=0.04457): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (20111 / 25000 Steps) (loss=0.03051): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (20114 / 25000 Steps) (loss=0.03096): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "Training (20117 / 25000 Steps) (loss=0.02385): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (20120 / 25000 Steps) (loss=0.03994): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (20123 / 25000 Steps) (loss=0.03258): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (20126 / 25000 Steps) (loss=0.03065): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (20129 / 25000 Steps) (loss=0.02258): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (20132 / 25000 Steps) (loss=0.03508): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (20135 / 25000 Steps) (loss=0.03935): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (20138 / 25000 Steps) (loss=0.03440): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (20141 / 25000 Steps) (loss=0.03097): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (20144 / 25000 Steps) (loss=0.03017): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (20147 / 25000 Steps) (loss=0.04199): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (20150 / 25000 Steps) (loss=0.03139): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (20153 / 25000 Steps) (loss=0.03266): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (20156 / 25000 Steps) (loss=0.02767): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (20159 / 25000 Steps) (loss=0.02994): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (20162 / 25000 Steps) (loss=0.03674): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (20165 / 25000 Steps) (loss=0.03507): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (20168 / 25000 Steps) (loss=0.03307): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (20171 / 25000 Steps) (loss=0.03633): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (20174 / 25000 Steps) (loss=0.02693): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (20177 / 25000 Steps) (loss=0.03338): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (20180 / 25000 Steps) (loss=0.03198): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (20183 / 25000 Steps) (loss=0.03128): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (20186 / 25000 Steps) (loss=0.03361): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (20189 / 25000 Steps) (loss=0.03380): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (20192 / 25000 Steps) (loss=0.03628): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (20195 / 25000 Steps) (loss=0.02805): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (20198 / 25000 Steps) (loss=0.02676): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (20201 / 25000 Steps) (loss=0.04871): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (20204 / 25000 Steps) (loss=0.03057): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (20207 / 25000 Steps) (loss=0.02489): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (20210 / 25000 Steps) (loss=0.02435): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "Training (20213 / 25000 Steps) (loss=0.03012): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (20216 / 25000 Steps) (loss=0.04109): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (20219 / 25000 Steps) (loss=0.02299): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (20222 / 25000 Steps) (loss=0.03314): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (20225 / 25000 Steps) (loss=0.04423): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (20228 / 25000 Steps) (loss=0.02835): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (20231 / 25000 Steps) (loss=0.02847): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (20234 / 25000 Steps) (loss=0.03599): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (20237 / 25000 Steps) (loss=0.03469): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (20240 / 25000 Steps) (loss=0.02800): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (20243 / 25000 Steps) (loss=0.02995): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (20246 / 25000 Steps) (loss=0.02203): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (20249 / 25000 Steps) (loss=0.03207): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (20252 / 25000 Steps) (loss=0.03218): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (20255 / 25000 Steps) (loss=0.02820): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (20258 / 25000 Steps) (loss=0.02905): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (20261 / 25000 Steps) (loss=0.03734): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (20264 / 25000 Steps) (loss=0.03026): 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "Training (20267 / 25000 Steps) (loss=0.04176): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (20270 / 25000 Steps) (loss=0.04130): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (20273 / 25000 Steps) (loss=0.02951): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (20276 / 25000 Steps) (loss=0.02648): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (20279 / 25000 Steps) (loss=0.03064): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (20282 / 25000 Steps) (loss=0.03067): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (20285 / 25000 Steps) (loss=0.02978): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (20288 / 25000 Steps) (loss=0.03531): 100%|██████████| 3/3 [00:02<00:00,  1.35it/s]\n",
      "Training (20291 / 25000 Steps) (loss=0.03341): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (20294 / 25000 Steps) (loss=0.03406): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (20297 / 25000 Steps) (loss=0.02936): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (20300 / 25000 Steps) (loss=0.03835): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (20303 / 25000 Steps) (loss=0.03037): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (20306 / 25000 Steps) (loss=0.02865): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (20309 / 25000 Steps) (loss=0.02386): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (20312 / 25000 Steps) (loss=0.04137): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (20315 / 25000 Steps) (loss=0.04083): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (20318 / 25000 Steps) (loss=0.03432): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (20321 / 25000 Steps) (loss=0.02504): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (20324 / 25000 Steps) (loss=0.03400): 100%|██████████| 3/3 [00:03<00:00,  1.03s/it]\n",
      "Training (20327 / 25000 Steps) (loss=0.03252): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (20330 / 25000 Steps) (loss=0.02823): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (20333 / 25000 Steps) (loss=0.03146): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (20336 / 25000 Steps) (loss=0.04027): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (20339 / 25000 Steps) (loss=0.03072): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (20342 / 25000 Steps) (loss=0.02717): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (20345 / 25000 Steps) (loss=0.02841): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "Training (20348 / 25000 Steps) (loss=0.04152): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (20351 / 25000 Steps) (loss=0.03607): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (20354 / 25000 Steps) (loss=0.03272): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (20357 / 25000 Steps) (loss=0.02347): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (20360 / 25000 Steps) (loss=0.02355): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (20363 / 25000 Steps) (loss=0.04367): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (20366 / 25000 Steps) (loss=0.03333): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (20369 / 25000 Steps) (loss=0.04857): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (20372 / 25000 Steps) (loss=0.03308): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (20375 / 25000 Steps) (loss=0.03159): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (20378 / 25000 Steps) (loss=0.02715): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (20381 / 25000 Steps) (loss=0.02651): 100%|██████████| 3/3 [00:02<00:00,  1.02it/s]\n",
      "Training (20384 / 25000 Steps) (loss=0.03851): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (20387 / 25000 Steps) (loss=0.02984): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (20390 / 25000 Steps) (loss=0.02625): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (20393 / 25000 Steps) (loss=0.03322): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (20396 / 25000 Steps) (loss=0.02305): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (20399 / 25000 Steps) (loss=0.02882): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (20402 / 25000 Steps) (loss=0.03511): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (20405 / 25000 Steps) (loss=0.04268): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (20408 / 25000 Steps) (loss=0.03983): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (20411 / 25000 Steps) (loss=0.02966): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (20414 / 25000 Steps) (loss=0.02530): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (20417 / 25000 Steps) (loss=0.02712): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (20420 / 25000 Steps) (loss=0.05006): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (20423 / 25000 Steps) (loss=0.03000): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (20426 / 25000 Steps) (loss=0.02778): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (20429 / 25000 Steps) (loss=0.02486): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (20432 / 25000 Steps) (loss=0.04117): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (20435 / 25000 Steps) (loss=0.02549): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (20438 / 25000 Steps) (loss=0.02936): 100%|██████████| 3/3 [00:02<00:00,  1.02it/s]\n",
      "Training (20441 / 25000 Steps) (loss=0.03118): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (20444 / 25000 Steps) (loss=0.03038): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (20447 / 25000 Steps) (loss=0.03202): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (20450 / 25000 Steps) (loss=0.02870): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (20453 / 25000 Steps) (loss=0.04547): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (20456 / 25000 Steps) (loss=0.04040): 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
      "Training (20459 / 25000 Steps) (loss=0.02941): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (20462 / 25000 Steps) (loss=0.03701): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (20465 / 25000 Steps) (loss=0.03453): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (20468 / 25000 Steps) (loss=0.02910): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (20471 / 25000 Steps) (loss=0.03120): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (20474 / 25000 Steps) (loss=0.03885): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (20477 / 25000 Steps) (loss=0.03041): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (20480 / 25000 Steps) (loss=0.03239): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (20483 / 25000 Steps) (loss=0.02760): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (20486 / 25000 Steps) (loss=0.03799): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (20489 / 25000 Steps) (loss=0.03007): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (20492 / 25000 Steps) (loss=0.03328): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (20495 / 25000 Steps) (loss=0.03093): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (20498 / 25000 Steps) (loss=0.04630): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Validate (20499 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]it]\n",
      "Training (20501 / 25000 Steps) (loss=0.02647):  67%|██████▋   | 2/3 [00:02<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (20501 / 25000 Steps) (loss=0.02647): 100%|██████████| 3/3 [00:02<00:00,  1.35it/s]\n",
      "Training (20504 / 25000 Steps) (loss=0.03410): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (20507 / 25000 Steps) (loss=0.02635): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (20510 / 25000 Steps) (loss=0.03841): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (20513 / 25000 Steps) (loss=0.02811): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (20516 / 25000 Steps) (loss=0.03687): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (20519 / 25000 Steps) (loss=0.03539): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (20522 / 25000 Steps) (loss=0.03897): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (20525 / 25000 Steps) (loss=0.03475): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (20528 / 25000 Steps) (loss=0.03145): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (20531 / 25000 Steps) (loss=0.02677): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (20534 / 25000 Steps) (loss=0.03114): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (20537 / 25000 Steps) (loss=0.02798): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (20540 / 25000 Steps) (loss=0.04282): 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "Training (20543 / 25000 Steps) (loss=0.02216): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (20546 / 25000 Steps) (loss=0.03264): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (20549 / 25000 Steps) (loss=0.03501): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (20552 / 25000 Steps) (loss=0.03153): 100%|██████████| 3/3 [00:02<00:00,  1.19it/s]\n",
      "Training (20555 / 25000 Steps) (loss=0.02704): 100%|██████████| 3/3 [00:02<00:00,  1.13it/s]\n",
      "Training (20558 / 25000 Steps) (loss=0.03736): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (20561 / 25000 Steps) (loss=0.03832): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (20564 / 25000 Steps) (loss=0.05114): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (20567 / 25000 Steps) (loss=0.03033): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (20570 / 25000 Steps) (loss=0.04532): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (20573 / 25000 Steps) (loss=0.02623): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (20576 / 25000 Steps) (loss=0.02698): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (20579 / 25000 Steps) (loss=0.03747): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (20582 / 25000 Steps) (loss=0.03780): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (20585 / 25000 Steps) (loss=0.03899): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (20588 / 25000 Steps) (loss=0.04085): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (20591 / 25000 Steps) (loss=0.02627): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (20594 / 25000 Steps) (loss=0.03574): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (20597 / 25000 Steps) (loss=0.03638): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (20600 / 25000 Steps) (loss=0.04315): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (20603 / 25000 Steps) (loss=0.03291): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (20606 / 25000 Steps) (loss=0.03533): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (20609 / 25000 Steps) (loss=0.03938): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (20612 / 25000 Steps) (loss=0.02519): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (20615 / 25000 Steps) (loss=0.02989): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (20618 / 25000 Steps) (loss=0.03458): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (20621 / 25000 Steps) (loss=0.04352): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (20624 / 25000 Steps) (loss=0.04732): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (20627 / 25000 Steps) (loss=0.03043): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (20630 / 25000 Steps) (loss=0.03048): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (20633 / 25000 Steps) (loss=0.03509): 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "Training (20636 / 25000 Steps) (loss=0.03728): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (20639 / 25000 Steps) (loss=0.03315): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (20642 / 25000 Steps) (loss=0.02826): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (20645 / 25000 Steps) (loss=0.03246): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (20648 / 25000 Steps) (loss=0.03344): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (20651 / 25000 Steps) (loss=0.03414): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (20654 / 25000 Steps) (loss=0.02939): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (20657 / 25000 Steps) (loss=0.03209): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (20660 / 25000 Steps) (loss=0.02804): 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "Training (20663 / 25000 Steps) (loss=0.03959): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (20666 / 25000 Steps) (loss=0.04456): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (20669 / 25000 Steps) (loss=0.02970): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (20672 / 25000 Steps) (loss=0.02586): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (20675 / 25000 Steps) (loss=0.03950): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (20678 / 25000 Steps) (loss=0.03119): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (20681 / 25000 Steps) (loss=0.04893): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (20684 / 25000 Steps) (loss=0.02895): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (20687 / 25000 Steps) (loss=0.02529): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (20690 / 25000 Steps) (loss=0.03173): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (20693 / 25000 Steps) (loss=0.02892): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (20696 / 25000 Steps) (loss=0.03043): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (20699 / 25000 Steps) (loss=0.02992): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (20702 / 25000 Steps) (loss=0.02777): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (20705 / 25000 Steps) (loss=0.02975): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (20708 / 25000 Steps) (loss=0.03172): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (20711 / 25000 Steps) (loss=0.03231): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (20714 / 25000 Steps) (loss=0.02987): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (20717 / 25000 Steps) (loss=0.03991): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (20720 / 25000 Steps) (loss=0.04259): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (20723 / 25000 Steps) (loss=0.03672): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (20726 / 25000 Steps) (loss=0.04033): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (20729 / 25000 Steps) (loss=0.02986): 100%|██████████| 3/3 [00:02<00:00,  1.35it/s]\n",
      "Training (20732 / 25000 Steps) (loss=0.02894): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (20735 / 25000 Steps) (loss=0.05036): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (20738 / 25000 Steps) (loss=0.04020): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (20741 / 25000 Steps) (loss=0.02294): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (20744 / 25000 Steps) (loss=0.03756): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (20747 / 25000 Steps) (loss=0.02547): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (20750 / 25000 Steps) (loss=0.04126): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (20753 / 25000 Steps) (loss=0.02980): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (20756 / 25000 Steps) (loss=0.03305): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (20759 / 25000 Steps) (loss=0.03184): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (20762 / 25000 Steps) (loss=0.04909): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (20765 / 25000 Steps) (loss=0.02260): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (20768 / 25000 Steps) (loss=0.02857): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (20771 / 25000 Steps) (loss=0.03174): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (20774 / 25000 Steps) (loss=0.03241): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (20777 / 25000 Steps) (loss=0.04616): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (20780 / 25000 Steps) (loss=0.03435): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (20783 / 25000 Steps) (loss=0.03639): 100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
      "Training (20786 / 25000 Steps) (loss=0.04077): 100%|██████████| 3/3 [00:03<00:00,  1.09s/it]\n",
      "Training (20789 / 25000 Steps) (loss=0.04048): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (20792 / 25000 Steps) (loss=0.02679): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (20795 / 25000 Steps) (loss=0.02319): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (20798 / 25000 Steps) (loss=0.02634): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (20801 / 25000 Steps) (loss=0.02395): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (20804 / 25000 Steps) (loss=0.03612): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (20807 / 25000 Steps) (loss=0.03247): 100%|██████████| 3/3 [00:02<00:00,  1.25it/s]\n",
      "Training (20810 / 25000 Steps) (loss=0.02872): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (20813 / 25000 Steps) (loss=0.03292): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (20816 / 25000 Steps) (loss=0.03407): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (20819 / 25000 Steps) (loss=0.02327): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (20822 / 25000 Steps) (loss=0.02654): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (20825 / 25000 Steps) (loss=0.03529): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (20828 / 25000 Steps) (loss=0.02511): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (20831 / 25000 Steps) (loss=0.03091): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (20834 / 25000 Steps) (loss=0.02791): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (20837 / 25000 Steps) (loss=0.04013): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (20840 / 25000 Steps) (loss=0.02746): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (20843 / 25000 Steps) (loss=0.02573): 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
      "Training (20846 / 25000 Steps) (loss=0.02387): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (20849 / 25000 Steps) (loss=0.04227): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (20852 / 25000 Steps) (loss=0.03133): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (20855 / 25000 Steps) (loss=0.02632): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (20858 / 25000 Steps) (loss=0.02819): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (20861 / 25000 Steps) (loss=0.03138): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (20864 / 25000 Steps) (loss=0.03925): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (20867 / 25000 Steps) (loss=0.04457): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (20870 / 25000 Steps) (loss=0.02943): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (20873 / 25000 Steps) (loss=0.02518): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (20876 / 25000 Steps) (loss=0.02559): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (20879 / 25000 Steps) (loss=0.03303): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (20882 / 25000 Steps) (loss=0.02493): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (20885 / 25000 Steps) (loss=0.02976): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (20888 / 25000 Steps) (loss=0.03402): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (20891 / 25000 Steps) (loss=0.02725): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (20894 / 25000 Steps) (loss=0.03247): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (20897 / 25000 Steps) (loss=0.03719): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (20900 / 25000 Steps) (loss=0.02724): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (20903 / 25000 Steps) (loss=0.02286): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (20906 / 25000 Steps) (loss=0.03356): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (20909 / 25000 Steps) (loss=0.03762): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (20912 / 25000 Steps) (loss=0.02700): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (20915 / 25000 Steps) (loss=0.03533): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (20918 / 25000 Steps) (loss=0.03736): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (20921 / 25000 Steps) (loss=0.03696): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (20924 / 25000 Steps) (loss=0.02815): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (20927 / 25000 Steps) (loss=0.02627): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (20930 / 25000 Steps) (loss=0.03334): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (20933 / 25000 Steps) (loss=0.03523): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (20936 / 25000 Steps) (loss=0.02785): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (20939 / 25000 Steps) (loss=0.04270): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (20942 / 25000 Steps) (loss=0.02916): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (20945 / 25000 Steps) (loss=0.03051): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (20948 / 25000 Steps) (loss=0.03673): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (20951 / 25000 Steps) (loss=0.03037): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (20954 / 25000 Steps) (loss=0.02559): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (20957 / 25000 Steps) (loss=0.02470): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (20960 / 25000 Steps) (loss=0.02811): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (20963 / 25000 Steps) (loss=0.02787): 100%|██████████| 3/3 [00:03<00:00,  1.00s/it]\n",
      "Training (20966 / 25000 Steps) (loss=0.03441): 100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
      "Training (20969 / 25000 Steps) (loss=0.03513): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (20972 / 25000 Steps) (loss=0.03217): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (20975 / 25000 Steps) (loss=0.03894): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (20978 / 25000 Steps) (loss=0.03553): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (20981 / 25000 Steps) (loss=0.03140): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (20984 / 25000 Steps) (loss=0.04146): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (20987 / 25000 Steps) (loss=0.02754): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (20990 / 25000 Steps) (loss=0.02717): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (20993 / 25000 Steps) (loss=0.02477): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (20996 / 25000 Steps) (loss=0.03672): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (20999 / 25000 Steps) (loss=0.02888): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Validate (21000 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "Training (21002 / 25000 Steps) (loss=0.02381): 100%|██████████| 3/3 [00:02<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (21002 / 25000 Steps) (loss=0.02381): 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]\n",
      "Training (21005 / 25000 Steps) (loss=0.04030): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (21008 / 25000 Steps) (loss=0.02987): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (21011 / 25000 Steps) (loss=0.03320): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (21014 / 25000 Steps) (loss=0.03499): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (21017 / 25000 Steps) (loss=0.02972): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (21020 / 25000 Steps) (loss=0.03359): 100%|██████████| 3/3 [00:03<00:00,  1.10s/it]\n",
      "Training (21023 / 25000 Steps) (loss=0.02917): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (21026 / 25000 Steps) (loss=0.02986): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (21029 / 25000 Steps) (loss=0.02710): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (21032 / 25000 Steps) (loss=0.02940): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (21035 / 25000 Steps) (loss=0.02830): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (21038 / 25000 Steps) (loss=0.03455): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (21041 / 25000 Steps) (loss=0.04716): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (21044 / 25000 Steps) (loss=0.03174): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (21047 / 25000 Steps) (loss=0.03999): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (21050 / 25000 Steps) (loss=0.02953): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (21053 / 25000 Steps) (loss=0.03611): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (21056 / 25000 Steps) (loss=0.02546): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "Training (21059 / 25000 Steps) (loss=0.02842): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (21062 / 25000 Steps) (loss=0.02578): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (21065 / 25000 Steps) (loss=0.03607): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (21068 / 25000 Steps) (loss=0.03387): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (21071 / 25000 Steps) (loss=0.02867): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (21074 / 25000 Steps) (loss=0.02547): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (21077 / 25000 Steps) (loss=0.04084): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (21080 / 25000 Steps) (loss=0.03109): 100%|██████████| 3/3 [00:02<00:00,  1.20it/s]\n",
      "Training (21083 / 25000 Steps) (loss=0.03962): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (21086 / 25000 Steps) (loss=0.03835): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (21089 / 25000 Steps) (loss=0.03722): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (21092 / 25000 Steps) (loss=0.02912): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (21095 / 25000 Steps) (loss=0.02949): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (21098 / 25000 Steps) (loss=0.02930): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (21101 / 25000 Steps) (loss=0.04437): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (21104 / 25000 Steps) (loss=0.03662): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (21107 / 25000 Steps) (loss=0.03606): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "Training (21110 / 25000 Steps) (loss=0.02326): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (21113 / 25000 Steps) (loss=0.03900): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (21116 / 25000 Steps) (loss=0.03656): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (21119 / 25000 Steps) (loss=0.03834): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (21122 / 25000 Steps) (loss=0.03826): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (21125 / 25000 Steps) (loss=0.03169): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (21128 / 25000 Steps) (loss=0.02666): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (21131 / 25000 Steps) (loss=0.03316): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (21134 / 25000 Steps) (loss=0.02832): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (21137 / 25000 Steps) (loss=0.03429): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (21140 / 25000 Steps) (loss=0.02871): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (21143 / 25000 Steps) (loss=0.02278): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (21146 / 25000 Steps) (loss=0.03602): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (21149 / 25000 Steps) (loss=0.03184): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (21152 / 25000 Steps) (loss=0.03150): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (21155 / 25000 Steps) (loss=0.03073): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (21158 / 25000 Steps) (loss=0.03396): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (21161 / 25000 Steps) (loss=0.03778): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (21164 / 25000 Steps) (loss=0.04086): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (21167 / 25000 Steps) (loss=0.02923): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (21170 / 25000 Steps) (loss=0.02564): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (21173 / 25000 Steps) (loss=0.02532): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (21176 / 25000 Steps) (loss=0.02640): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (21179 / 25000 Steps) (loss=0.03418): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (21182 / 25000 Steps) (loss=0.02677): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (21185 / 25000 Steps) (loss=0.03666): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (21188 / 25000 Steps) (loss=0.03445): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (21191 / 25000 Steps) (loss=0.03502): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (21194 / 25000 Steps) (loss=0.03419): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (21197 / 25000 Steps) (loss=0.02645): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (21200 / 25000 Steps) (loss=0.03059): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (21203 / 25000 Steps) (loss=0.02309): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (21206 / 25000 Steps) (loss=0.05081): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (21209 / 25000 Steps) (loss=0.02812): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (21212 / 25000 Steps) (loss=0.03421): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (21215 / 25000 Steps) (loss=0.03152): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (21218 / 25000 Steps) (loss=0.03120): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (21221 / 25000 Steps) (loss=0.03705): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (21224 / 25000 Steps) (loss=0.03827): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (21227 / 25000 Steps) (loss=0.02940): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (21230 / 25000 Steps) (loss=0.02425): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (21233 / 25000 Steps) (loss=0.03505): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (21236 / 25000 Steps) (loss=0.02387): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (21239 / 25000 Steps) (loss=0.04495): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (21242 / 25000 Steps) (loss=0.02523): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (21245 / 25000 Steps) (loss=0.03675): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (21248 / 25000 Steps) (loss=0.02546): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (21251 / 25000 Steps) (loss=0.03280): 100%|██████████| 3/3 [00:02<00:00,  1.35it/s]\n",
      "Training (21254 / 25000 Steps) (loss=0.02586): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (21257 / 25000 Steps) (loss=0.02434): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (21260 / 25000 Steps) (loss=0.02234): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (21263 / 25000 Steps) (loss=0.03493): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (21266 / 25000 Steps) (loss=0.02608): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (21269 / 25000 Steps) (loss=0.03898): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (21272 / 25000 Steps) (loss=0.03598): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (21275 / 25000 Steps) (loss=0.02750): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (21278 / 25000 Steps) (loss=0.03474): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (21281 / 25000 Steps) (loss=0.02727): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (21284 / 25000 Steps) (loss=0.04895): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (21287 / 25000 Steps) (loss=0.03448): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (21290 / 25000 Steps) (loss=0.04814): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (21293 / 25000 Steps) (loss=0.02775): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (21296 / 25000 Steps) (loss=0.02432): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (21299 / 25000 Steps) (loss=0.03108): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (21302 / 25000 Steps) (loss=0.03004): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (21305 / 25000 Steps) (loss=0.03372): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (21308 / 25000 Steps) (loss=0.02079): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (21311 / 25000 Steps) (loss=0.03046): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (21314 / 25000 Steps) (loss=0.02808): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (21317 / 25000 Steps) (loss=0.04041): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (21320 / 25000 Steps) (loss=0.02917): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (21323 / 25000 Steps) (loss=0.03624): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (21326 / 25000 Steps) (loss=0.02557): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (21329 / 25000 Steps) (loss=0.03583): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (21332 / 25000 Steps) (loss=0.02722): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (21335 / 25000 Steps) (loss=0.02556): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (21338 / 25000 Steps) (loss=0.02789): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (21341 / 25000 Steps) (loss=0.04737): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (21344 / 25000 Steps) (loss=0.03074): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (21347 / 25000 Steps) (loss=0.03123): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (21350 / 25000 Steps) (loss=0.02837): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (21353 / 25000 Steps) (loss=0.02612): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (21356 / 25000 Steps) (loss=0.03697): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (21359 / 25000 Steps) (loss=0.03644): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (21362 / 25000 Steps) (loss=0.03620): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (21365 / 25000 Steps) (loss=0.02751): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (21368 / 25000 Steps) (loss=0.04102): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "Training (21371 / 25000 Steps) (loss=0.03705): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (21374 / 25000 Steps) (loss=0.02675): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (21377 / 25000 Steps) (loss=0.02962): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (21380 / 25000 Steps) (loss=0.03670): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (21383 / 25000 Steps) (loss=0.04607): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (21386 / 25000 Steps) (loss=0.02996): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (21389 / 25000 Steps) (loss=0.03040): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (21392 / 25000 Steps) (loss=0.03530): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (21395 / 25000 Steps) (loss=0.02573): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (21398 / 25000 Steps) (loss=0.02904): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (21401 / 25000 Steps) (loss=0.02955): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (21404 / 25000 Steps) (loss=0.03013): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (21407 / 25000 Steps) (loss=0.03504): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (21410 / 25000 Steps) (loss=0.02628): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (21413 / 25000 Steps) (loss=0.02803): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (21416 / 25000 Steps) (loss=0.03175): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (21419 / 25000 Steps) (loss=0.03534): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (21422 / 25000 Steps) (loss=0.03448): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (21425 / 25000 Steps) (loss=0.03035): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (21428 / 25000 Steps) (loss=0.03252): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (21431 / 25000 Steps) (loss=0.03724): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (21434 / 25000 Steps) (loss=0.03335): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (21437 / 25000 Steps) (loss=0.03738): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (21440 / 25000 Steps) (loss=0.03688): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (21443 / 25000 Steps) (loss=0.03307): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (21446 / 25000 Steps) (loss=0.03726): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (21449 / 25000 Steps) (loss=0.03322): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (21452 / 25000 Steps) (loss=0.04119): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (21455 / 25000 Steps) (loss=0.04301): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (21458 / 25000 Steps) (loss=0.03516): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (21461 / 25000 Steps) (loss=0.04310): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (21464 / 25000 Steps) (loss=0.03607): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (21467 / 25000 Steps) (loss=0.02809): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (21470 / 25000 Steps) (loss=0.04158): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (21473 / 25000 Steps) (loss=0.03522): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (21476 / 25000 Steps) (loss=0.02919): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (21479 / 25000 Steps) (loss=0.03012): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (21482 / 25000 Steps) (loss=0.03498): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (21485 / 25000 Steps) (loss=0.02631): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (21488 / 25000 Steps) (loss=0.03564): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (21491 / 25000 Steps) (loss=0.04391): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "Training (21494 / 25000 Steps) (loss=0.04398): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (21497 / 25000 Steps) (loss=0.03268): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Validate (21498 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]/s]\n",
      "Training (21500 / 25000 Steps) (loss=0.03814): 100%|██████████| 3/3 [00:02<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (21500 / 25000 Steps) (loss=0.03814): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (21503 / 25000 Steps) (loss=0.03301): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (21506 / 25000 Steps) (loss=0.03288): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (21509 / 25000 Steps) (loss=0.03509): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (21512 / 25000 Steps) (loss=0.05154): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (21515 / 25000 Steps) (loss=0.03365): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (21518 / 25000 Steps) (loss=0.03358): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (21521 / 25000 Steps) (loss=0.03684): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (21524 / 25000 Steps) (loss=0.03438): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (21527 / 25000 Steps) (loss=0.03102): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (21530 / 25000 Steps) (loss=0.02428): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (21533 / 25000 Steps) (loss=0.05171): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (21536 / 25000 Steps) (loss=0.03249): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (21539 / 25000 Steps) (loss=0.04590): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (21542 / 25000 Steps) (loss=0.04387): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (21545 / 25000 Steps) (loss=0.03404): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (21548 / 25000 Steps) (loss=0.04337): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (21551 / 25000 Steps) (loss=0.03902): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (21554 / 25000 Steps) (loss=0.03894): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (21557 / 25000 Steps) (loss=0.02611): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (21560 / 25000 Steps) (loss=0.03397): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (21563 / 25000 Steps) (loss=0.03391): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (21566 / 25000 Steps) (loss=0.03591): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (21569 / 25000 Steps) (loss=0.04373): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (21572 / 25000 Steps) (loss=0.04544): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (21575 / 25000 Steps) (loss=0.03735): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (21578 / 25000 Steps) (loss=0.05392): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (21581 / 25000 Steps) (loss=0.03833): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (21584 / 25000 Steps) (loss=0.04001): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (21587 / 25000 Steps) (loss=0.02928): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (21590 / 25000 Steps) (loss=0.03440): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (21593 / 25000 Steps) (loss=0.04497): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (21596 / 25000 Steps) (loss=0.02710): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (21599 / 25000 Steps) (loss=0.03146): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (21602 / 25000 Steps) (loss=0.02828): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (21605 / 25000 Steps) (loss=0.03313): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (21608 / 25000 Steps) (loss=0.03076): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (21611 / 25000 Steps) (loss=0.04005): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (21614 / 25000 Steps) (loss=0.03708): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (21617 / 25000 Steps) (loss=0.04049): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (21620 / 25000 Steps) (loss=0.04034): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (21623 / 25000 Steps) (loss=0.02794): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (21626 / 25000 Steps) (loss=0.03145): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (21629 / 25000 Steps) (loss=0.02721): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (21632 / 25000 Steps) (loss=0.03071): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (21635 / 25000 Steps) (loss=0.02541): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (21638 / 25000 Steps) (loss=0.04053): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (21641 / 25000 Steps) (loss=0.02559): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (21644 / 25000 Steps) (loss=0.03402): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (21647 / 25000 Steps) (loss=0.03358): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (21650 / 25000 Steps) (loss=0.03422): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (21653 / 25000 Steps) (loss=0.03233): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (21656 / 25000 Steps) (loss=0.03194): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (21659 / 25000 Steps) (loss=0.03550): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (21662 / 25000 Steps) (loss=0.02460): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (21665 / 25000 Steps) (loss=0.02875): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (21668 / 25000 Steps) (loss=0.02748): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "Training (21671 / 25000 Steps) (loss=0.04020): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (21674 / 25000 Steps) (loss=0.03354): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (21677 / 25000 Steps) (loss=0.02134): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (21680 / 25000 Steps) (loss=0.02671): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (21683 / 25000 Steps) (loss=0.02675): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (21686 / 25000 Steps) (loss=0.03599): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (21689 / 25000 Steps) (loss=0.03168): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (21692 / 25000 Steps) (loss=0.03180): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (21695 / 25000 Steps) (loss=0.02796): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (21698 / 25000 Steps) (loss=0.03109): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (21701 / 25000 Steps) (loss=0.03755): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (21704 / 25000 Steps) (loss=0.03421): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (21707 / 25000 Steps) (loss=0.03804): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (21710 / 25000 Steps) (loss=0.02153): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (21713 / 25000 Steps) (loss=0.03258): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (21716 / 25000 Steps) (loss=0.03569): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (21719 / 25000 Steps) (loss=0.02981): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (21722 / 25000 Steps) (loss=0.03232): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (21725 / 25000 Steps) (loss=0.03349): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (21728 / 25000 Steps) (loss=0.02810): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (21731 / 25000 Steps) (loss=0.03420): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (21734 / 25000 Steps) (loss=0.03013): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (21737 / 25000 Steps) (loss=0.02089): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (21740 / 25000 Steps) (loss=0.03198): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (21743 / 25000 Steps) (loss=0.02321): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (21746 / 25000 Steps) (loss=0.03130): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "Training (21749 / 25000 Steps) (loss=0.02121): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (21752 / 25000 Steps) (loss=0.02477): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (21755 / 25000 Steps) (loss=0.03369): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (21758 / 25000 Steps) (loss=0.03838): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (21761 / 25000 Steps) (loss=0.03243): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (21764 / 25000 Steps) (loss=0.03949): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (21767 / 25000 Steps) (loss=0.02502): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (21770 / 25000 Steps) (loss=0.02549): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (21773 / 25000 Steps) (loss=0.02480): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (21776 / 25000 Steps) (loss=0.02234): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (21779 / 25000 Steps) (loss=0.02802): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (21782 / 25000 Steps) (loss=0.03506): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (21785 / 25000 Steps) (loss=0.02509): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (21788 / 25000 Steps) (loss=0.03377): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (21791 / 25000 Steps) (loss=0.03158): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (21794 / 25000 Steps) (loss=0.02778): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (21797 / 25000 Steps) (loss=0.05243): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (21800 / 25000 Steps) (loss=0.02602): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (21803 / 25000 Steps) (loss=0.03132): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (21806 / 25000 Steps) (loss=0.03099): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (21809 / 25000 Steps) (loss=0.03940): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (21812 / 25000 Steps) (loss=0.03490): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (21815 / 25000 Steps) (loss=0.03640): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (21818 / 25000 Steps) (loss=0.03252): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (21821 / 25000 Steps) (loss=0.02496): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (21824 / 25000 Steps) (loss=0.03306): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (21827 / 25000 Steps) (loss=0.03709): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (21830 / 25000 Steps) (loss=0.03017): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (21833 / 25000 Steps) (loss=0.04239): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (21836 / 25000 Steps) (loss=0.02534): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (21839 / 25000 Steps) (loss=0.04139): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (21842 / 25000 Steps) (loss=0.03042): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (21845 / 25000 Steps) (loss=0.02897): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (21848 / 25000 Steps) (loss=0.02887): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (21851 / 25000 Steps) (loss=0.03770): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (21854 / 25000 Steps) (loss=0.02823): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (21857 / 25000 Steps) (loss=0.03019): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (21860 / 25000 Steps) (loss=0.03125): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (21863 / 25000 Steps) (loss=0.02736): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (21866 / 25000 Steps) (loss=0.03109): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (21869 / 25000 Steps) (loss=0.02751): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (21872 / 25000 Steps) (loss=0.02468): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (21875 / 25000 Steps) (loss=0.02828): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (21878 / 25000 Steps) (loss=0.03326): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (21881 / 25000 Steps) (loss=0.02702): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (21884 / 25000 Steps) (loss=0.04813): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (21887 / 25000 Steps) (loss=0.02461): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (21890 / 25000 Steps) (loss=0.03299): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (21893 / 25000 Steps) (loss=0.02741): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (21896 / 25000 Steps) (loss=0.02814): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (21899 / 25000 Steps) (loss=0.02844): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (21902 / 25000 Steps) (loss=0.02898): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (21905 / 25000 Steps) (loss=0.02908): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (21908 / 25000 Steps) (loss=0.03002): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (21911 / 25000 Steps) (loss=0.04329): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (21914 / 25000 Steps) (loss=0.03126): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (21917 / 25000 Steps) (loss=0.03553): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (21920 / 25000 Steps) (loss=0.02226): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (21923 / 25000 Steps) (loss=0.02471): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (21926 / 25000 Steps) (loss=0.03974): 100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
      "Training (21929 / 25000 Steps) (loss=0.02548): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (21932 / 25000 Steps) (loss=0.03443): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (21935 / 25000 Steps) (loss=0.03248): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (21938 / 25000 Steps) (loss=0.02513): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (21941 / 25000 Steps) (loss=0.02378): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (21944 / 25000 Steps) (loss=0.03844): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (21947 / 25000 Steps) (loss=0.02721): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (21950 / 25000 Steps) (loss=0.02795): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (21953 / 25000 Steps) (loss=0.03716): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (21956 / 25000 Steps) (loss=0.02753): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (21959 / 25000 Steps) (loss=0.03058): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (21962 / 25000 Steps) (loss=0.03993): 100%|██████████| 3/3 [00:02<00:00,  1.08it/s]\n",
      "Training (21965 / 25000 Steps) (loss=0.02464): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (21968 / 25000 Steps) (loss=0.02936): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (21971 / 25000 Steps) (loss=0.04243): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (21974 / 25000 Steps) (loss=0.02608): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (21977 / 25000 Steps) (loss=0.03091): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (21980 / 25000 Steps) (loss=0.03256): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (21983 / 25000 Steps) (loss=0.04579): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (21986 / 25000 Steps) (loss=0.03749): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (21989 / 25000 Steps) (loss=0.03365): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (21992 / 25000 Steps) (loss=0.03702): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (21995 / 25000 Steps) (loss=0.02697): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (21998 / 25000 Steps) (loss=0.02279): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Validate (21999 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]it]\n",
      "Training (22001 / 25000 Steps) (loss=0.02820):  67%|██████▋   | 2/3 [00:02<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (22001 / 25000 Steps) (loss=0.02820): 100%|██████████| 3/3 [00:02<00:00,  1.32it/s]\n",
      "Training (22004 / 25000 Steps) (loss=0.03043): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (22007 / 25000 Steps) (loss=0.02805): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (22010 / 25000 Steps) (loss=0.03914): 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n",
      "Training (22013 / 25000 Steps) (loss=0.02589): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (22016 / 25000 Steps) (loss=0.04117): 100%|██████████| 3/3 [00:02<00:00,  1.20it/s]\n",
      "Training (22019 / 25000 Steps) (loss=0.02424): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (22022 / 25000 Steps) (loss=0.03439): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (22025 / 25000 Steps) (loss=0.03380): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (22028 / 25000 Steps) (loss=0.03430): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (22031 / 25000 Steps) (loss=0.03579): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (22034 / 25000 Steps) (loss=0.02831): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (22037 / 25000 Steps) (loss=0.03864): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (22040 / 25000 Steps) (loss=0.03410): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (22043 / 25000 Steps) (loss=0.03764): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (22046 / 25000 Steps) (loss=0.02684): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (22049 / 25000 Steps) (loss=0.03883): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (22052 / 25000 Steps) (loss=0.02251): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (22055 / 25000 Steps) (loss=0.02188): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (22058 / 25000 Steps) (loss=0.03161): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (22061 / 25000 Steps) (loss=0.03059): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (22064 / 25000 Steps) (loss=0.03058): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (22067 / 25000 Steps) (loss=0.03125): 100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
      "Training (22070 / 25000 Steps) (loss=0.03068): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (22073 / 25000 Steps) (loss=0.02612): 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]\n",
      "Training (22076 / 25000 Steps) (loss=0.02271): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (22079 / 25000 Steps) (loss=0.02243): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (22082 / 25000 Steps) (loss=0.03178): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (22085 / 25000 Steps) (loss=0.03119): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (22088 / 25000 Steps) (loss=0.03466): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (22091 / 25000 Steps) (loss=0.03136): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (22094 / 25000 Steps) (loss=0.02751): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (22097 / 25000 Steps) (loss=0.03277): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (22100 / 25000 Steps) (loss=0.02998): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (22103 / 25000 Steps) (loss=0.03277): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (22106 / 25000 Steps) (loss=0.02844): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (22109 / 25000 Steps) (loss=0.03173): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (22112 / 25000 Steps) (loss=0.02280): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (22115 / 25000 Steps) (loss=0.03102): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (22118 / 25000 Steps) (loss=0.03663): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (22121 / 25000 Steps) (loss=0.02718): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (22124 / 25000 Steps) (loss=0.04163): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (22127 / 25000 Steps) (loss=0.02733): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (22130 / 25000 Steps) (loss=0.02990): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (22133 / 25000 Steps) (loss=0.02984): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (22136 / 25000 Steps) (loss=0.03066): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (22139 / 25000 Steps) (loss=0.03786): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (22142 / 25000 Steps) (loss=0.02120): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (22145 / 25000 Steps) (loss=0.02232): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (22148 / 25000 Steps) (loss=0.02770): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (22151 / 25000 Steps) (loss=0.04336): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (22154 / 25000 Steps) (loss=0.03104): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (22157 / 25000 Steps) (loss=0.03726): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (22160 / 25000 Steps) (loss=0.02632): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (22163 / 25000 Steps) (loss=0.03097): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (22166 / 25000 Steps) (loss=0.02350): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (22169 / 25000 Steps) (loss=0.03278): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (22172 / 25000 Steps) (loss=0.02507): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (22175 / 25000 Steps) (loss=0.02836): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (22178 / 25000 Steps) (loss=0.03368): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (22181 / 25000 Steps) (loss=0.03130): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (22184 / 25000 Steps) (loss=0.03058): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (22187 / 25000 Steps) (loss=0.02441): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (22190 / 25000 Steps) (loss=0.02767): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (22193 / 25000 Steps) (loss=0.02762): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (22196 / 25000 Steps) (loss=0.03695): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (22199 / 25000 Steps) (loss=0.02301): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (22202 / 25000 Steps) (loss=0.04216): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (22205 / 25000 Steps) (loss=0.03548): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (22208 / 25000 Steps) (loss=0.03991): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (22211 / 25000 Steps) (loss=0.03022): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (22214 / 25000 Steps) (loss=0.03952): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (22217 / 25000 Steps) (loss=0.03738): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (22220 / 25000 Steps) (loss=0.04711): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (22223 / 25000 Steps) (loss=0.03164): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (22226 / 25000 Steps) (loss=0.02121): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (22229 / 25000 Steps) (loss=0.02669): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (22232 / 25000 Steps) (loss=0.02976): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (22235 / 25000 Steps) (loss=0.03180): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (22238 / 25000 Steps) (loss=0.02834): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (22241 / 25000 Steps) (loss=0.02688): 100%|██████████| 3/3 [00:02<00:00,  1.13it/s]\n",
      "Training (22244 / 25000 Steps) (loss=0.02887): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (22247 / 25000 Steps) (loss=0.02781): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (22250 / 25000 Steps) (loss=0.03773): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (22253 / 25000 Steps) (loss=0.03920): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (22256 / 25000 Steps) (loss=0.02792): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (22259 / 25000 Steps) (loss=0.03272): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (22262 / 25000 Steps) (loss=0.02694): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (22265 / 25000 Steps) (loss=0.03407): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (22268 / 25000 Steps) (loss=0.02071): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (22271 / 25000 Steps) (loss=0.03516): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (22274 / 25000 Steps) (loss=0.02654): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (22277 / 25000 Steps) (loss=0.04884): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (22280 / 25000 Steps) (loss=0.04055): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (22283 / 25000 Steps) (loss=0.03389): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (22286 / 25000 Steps) (loss=0.02589): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (22289 / 25000 Steps) (loss=0.02698): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (22292 / 25000 Steps) (loss=0.02807): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (22295 / 25000 Steps) (loss=0.04248): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (22298 / 25000 Steps) (loss=0.03561): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (22301 / 25000 Steps) (loss=0.03380): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (22304 / 25000 Steps) (loss=0.02523): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (22307 / 25000 Steps) (loss=0.02487): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (22310 / 25000 Steps) (loss=0.03751): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (22313 / 25000 Steps) (loss=0.04303): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (22316 / 25000 Steps) (loss=0.02531): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (22319 / 25000 Steps) (loss=0.02329): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (22322 / 25000 Steps) (loss=0.03430): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (22325 / 25000 Steps) (loss=0.01967): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (22328 / 25000 Steps) (loss=0.02629): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (22331 / 25000 Steps) (loss=0.03240): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (22334 / 25000 Steps) (loss=0.04304): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (22337 / 25000 Steps) (loss=0.02612): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (22340 / 25000 Steps) (loss=0.03387): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (22343 / 25000 Steps) (loss=0.03622): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (22346 / 25000 Steps) (loss=0.02453): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (22349 / 25000 Steps) (loss=0.02853): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (22352 / 25000 Steps) (loss=0.03466): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (22355 / 25000 Steps) (loss=0.03582): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (22358 / 25000 Steps) (loss=0.03926): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (22361 / 25000 Steps) (loss=0.04102): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (22364 / 25000 Steps) (loss=0.03916): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (22367 / 25000 Steps) (loss=0.02932): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (22370 / 25000 Steps) (loss=0.02810): 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "Training (22373 / 25000 Steps) (loss=0.02425): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (22376 / 25000 Steps) (loss=0.02840): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (22379 / 25000 Steps) (loss=0.02962): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (22382 / 25000 Steps) (loss=0.04438): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (22385 / 25000 Steps) (loss=0.02898): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (22388 / 25000 Steps) (loss=0.04081): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (22391 / 25000 Steps) (loss=0.02163): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (22394 / 25000 Steps) (loss=0.03342): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (22397 / 25000 Steps) (loss=0.02690): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (22400 / 25000 Steps) (loss=0.03037): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (22403 / 25000 Steps) (loss=0.02652): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (22406 / 25000 Steps) (loss=0.03067): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (22409 / 25000 Steps) (loss=0.03221): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (22412 / 25000 Steps) (loss=0.02802): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (22415 / 25000 Steps) (loss=0.03280): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (22418 / 25000 Steps) (loss=0.03400): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (22421 / 25000 Steps) (loss=0.02846): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (22424 / 25000 Steps) (loss=0.03835): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (22427 / 25000 Steps) (loss=0.03935): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (22430 / 25000 Steps) (loss=0.02973): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (22433 / 25000 Steps) (loss=0.03415): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (22436 / 25000 Steps) (loss=0.03004): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (22439 / 25000 Steps) (loss=0.04689): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (22442 / 25000 Steps) (loss=0.02741): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (22445 / 25000 Steps) (loss=0.02658): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (22448 / 25000 Steps) (loss=0.03126): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (22451 / 25000 Steps) (loss=0.03577): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (22454 / 25000 Steps) (loss=0.03964): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (22457 / 25000 Steps) (loss=0.03827): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (22460 / 25000 Steps) (loss=0.03071): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (22463 / 25000 Steps) (loss=0.02859): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (22466 / 25000 Steps) (loss=0.04434): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (22469 / 25000 Steps) (loss=0.03518): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (22472 / 25000 Steps) (loss=0.03433): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (22475 / 25000 Steps) (loss=0.02747): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (22478 / 25000 Steps) (loss=0.03227): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (22481 / 25000 Steps) (loss=0.03126): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (22484 / 25000 Steps) (loss=0.03838): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (22487 / 25000 Steps) (loss=0.03347): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (22490 / 25000 Steps) (loss=0.02487): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (22493 / 25000 Steps) (loss=0.02664): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (22496 / 25000 Steps) (loss=0.03655): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (22499 / 25000 Steps) (loss=0.02446): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Validate (22500 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Training (22502 / 25000 Steps) (loss=0.03215): 100%|██████████| 3/3 [00:02<00:00,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (22502 / 25000 Steps) (loss=0.03215): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (22505 / 25000 Steps) (loss=0.03203): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (22508 / 25000 Steps) (loss=0.02642): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (22511 / 25000 Steps) (loss=0.04468): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (22514 / 25000 Steps) (loss=0.03657): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (22517 / 25000 Steps) (loss=0.03622): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (22520 / 25000 Steps) (loss=0.03190): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (22523 / 25000 Steps) (loss=0.02857): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (22526 / 25000 Steps) (loss=0.03478): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (22529 / 25000 Steps) (loss=0.03309): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (22532 / 25000 Steps) (loss=0.03703): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (22535 / 25000 Steps) (loss=0.02955): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (22538 / 25000 Steps) (loss=0.03067): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (22541 / 25000 Steps) (loss=0.02609): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (22544 / 25000 Steps) (loss=0.02889): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (22547 / 25000 Steps) (loss=0.03618): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (22550 / 25000 Steps) (loss=0.02826): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (22553 / 25000 Steps) (loss=0.03182): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (22556 / 25000 Steps) (loss=0.02222): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (22559 / 25000 Steps) (loss=0.02608): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (22562 / 25000 Steps) (loss=0.03009): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (22565 / 25000 Steps) (loss=0.03032): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (22568 / 25000 Steps) (loss=0.02829): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (22571 / 25000 Steps) (loss=0.02525): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (22574 / 25000 Steps) (loss=0.02464): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (22577 / 25000 Steps) (loss=0.03832): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (22580 / 25000 Steps) (loss=0.03581): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (22583 / 25000 Steps) (loss=0.03228): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (22586 / 25000 Steps) (loss=0.03014): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (22589 / 25000 Steps) (loss=0.03161): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (22592 / 25000 Steps) (loss=0.03254): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (22595 / 25000 Steps) (loss=0.03408): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "Training (22598 / 25000 Steps) (loss=0.02739): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (22601 / 25000 Steps) (loss=0.02970): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (22604 / 25000 Steps) (loss=0.03016): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (22607 / 25000 Steps) (loss=0.03007): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (22610 / 25000 Steps) (loss=0.03380): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (22613 / 25000 Steps) (loss=0.02596): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (22616 / 25000 Steps) (loss=0.03277): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (22619 / 25000 Steps) (loss=0.02928): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (22622 / 25000 Steps) (loss=0.03420): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (22625 / 25000 Steps) (loss=0.03148): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (22628 / 25000 Steps) (loss=0.02722): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (22631 / 25000 Steps) (loss=0.05507): 100%|██████████| 3/3 [00:02<00:00,  1.15it/s]\n",
      "Training (22634 / 25000 Steps) (loss=0.02508): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (22637 / 25000 Steps) (loss=0.03264): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (22640 / 25000 Steps) (loss=0.03651): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (22643 / 25000 Steps) (loss=0.02782): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (22646 / 25000 Steps) (loss=0.02665): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (22649 / 25000 Steps) (loss=0.03375): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (22652 / 25000 Steps) (loss=0.03609): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (22655 / 25000 Steps) (loss=0.02527): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (22658 / 25000 Steps) (loss=0.03349): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (22661 / 25000 Steps) (loss=0.02661): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (22664 / 25000 Steps) (loss=0.02652): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (22667 / 25000 Steps) (loss=0.03864): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (22670 / 25000 Steps) (loss=0.02434): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (22673 / 25000 Steps) (loss=0.01925): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (22676 / 25000 Steps) (loss=0.03186): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (22679 / 25000 Steps) (loss=0.02578): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (22682 / 25000 Steps) (loss=0.03057): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (22685 / 25000 Steps) (loss=0.03802): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (22688 / 25000 Steps) (loss=0.03730): 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]\n",
      "Training (22691 / 25000 Steps) (loss=0.03220): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (22694 / 25000 Steps) (loss=0.03237): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (22697 / 25000 Steps) (loss=0.02917): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (22700 / 25000 Steps) (loss=0.02639): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (22703 / 25000 Steps) (loss=0.03458): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (22706 / 25000 Steps) (loss=0.04032): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (22709 / 25000 Steps) (loss=0.02950): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (22712 / 25000 Steps) (loss=0.04286): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (22715 / 25000 Steps) (loss=0.02697): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (22718 / 25000 Steps) (loss=0.04052): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (22721 / 25000 Steps) (loss=0.02523): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (22724 / 25000 Steps) (loss=0.03585): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (22727 / 25000 Steps) (loss=0.03091): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (22730 / 25000 Steps) (loss=0.03087): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (22733 / 25000 Steps) (loss=0.03386): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (22736 / 25000 Steps) (loss=0.02583): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (22739 / 25000 Steps) (loss=0.02977): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (22742 / 25000 Steps) (loss=0.02979): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (22745 / 25000 Steps) (loss=0.02980): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (22748 / 25000 Steps) (loss=0.03042): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (22751 / 25000 Steps) (loss=0.03712): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (22754 / 25000 Steps) (loss=0.03623): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (22757 / 25000 Steps) (loss=0.03466): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (22760 / 25000 Steps) (loss=0.03769): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (22763 / 25000 Steps) (loss=0.03857): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "Training (22766 / 25000 Steps) (loss=0.03076): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (22769 / 25000 Steps) (loss=0.03346): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (22772 / 25000 Steps) (loss=0.02326): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (22775 / 25000 Steps) (loss=0.02766): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (22778 / 25000 Steps) (loss=0.03014): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (22781 / 25000 Steps) (loss=0.02977): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (22784 / 25000 Steps) (loss=0.03271): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (22787 / 25000 Steps) (loss=0.03191): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (22790 / 25000 Steps) (loss=0.02870): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (22793 / 25000 Steps) (loss=0.02723): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (22796 / 25000 Steps) (loss=0.03398): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (22799 / 25000 Steps) (loss=0.02531): 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
      "Training (22802 / 25000 Steps) (loss=0.03370): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (22805 / 25000 Steps) (loss=0.02955): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (22808 / 25000 Steps) (loss=0.03085): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (22811 / 25000 Steps) (loss=0.02586): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (22814 / 25000 Steps) (loss=0.03017): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (22817 / 25000 Steps) (loss=0.03963): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (22820 / 25000 Steps) (loss=0.03947): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (22823 / 25000 Steps) (loss=0.02894): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (22826 / 25000 Steps) (loss=0.02579): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (22829 / 25000 Steps) (loss=0.02773): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (22832 / 25000 Steps) (loss=0.02746): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (22835 / 25000 Steps) (loss=0.04234): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (22838 / 25000 Steps) (loss=0.03494): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (22841 / 25000 Steps) (loss=0.02639): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (22844 / 25000 Steps) (loss=0.03174): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (22847 / 25000 Steps) (loss=0.04472): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (22850 / 25000 Steps) (loss=0.03163): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "Training (22853 / 25000 Steps) (loss=0.02499): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (22856 / 25000 Steps) (loss=0.02683): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (22859 / 25000 Steps) (loss=0.02700): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (22862 / 25000 Steps) (loss=0.02241): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (22865 / 25000 Steps) (loss=0.03175): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (22868 / 25000 Steps) (loss=0.04505): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (22871 / 25000 Steps) (loss=0.03351): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (22874 / 25000 Steps) (loss=0.02428): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (22877 / 25000 Steps) (loss=0.02949): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (22880 / 25000 Steps) (loss=0.03280): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (22883 / 25000 Steps) (loss=0.02416): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (22886 / 25000 Steps) (loss=0.03498): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (22889 / 25000 Steps) (loss=0.03427): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (22892 / 25000 Steps) (loss=0.02921): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (22895 / 25000 Steps) (loss=0.02668): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (22898 / 25000 Steps) (loss=0.02166): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (22901 / 25000 Steps) (loss=0.03880): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (22904 / 25000 Steps) (loss=0.03338): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (22907 / 25000 Steps) (loss=0.02224): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (22910 / 25000 Steps) (loss=0.02412): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (22913 / 25000 Steps) (loss=0.02739): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (22916 / 25000 Steps) (loss=0.03193): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "Training (22919 / 25000 Steps) (loss=0.02246): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (22922 / 25000 Steps) (loss=0.02912): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (22925 / 25000 Steps) (loss=0.02328): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (22928 / 25000 Steps) (loss=0.02800): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (22931 / 25000 Steps) (loss=0.03030): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Training (22934 / 25000 Steps) (loss=0.02915): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (22937 / 25000 Steps) (loss=0.04200): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (22940 / 25000 Steps) (loss=0.02917): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (22943 / 25000 Steps) (loss=0.02810): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (22946 / 25000 Steps) (loss=0.02400): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (22949 / 25000 Steps) (loss=0.02384): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (22952 / 25000 Steps) (loss=0.03315): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (22955 / 25000 Steps) (loss=0.02958): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (22958 / 25000 Steps) (loss=0.03680): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (22961 / 25000 Steps) (loss=0.03049): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (22964 / 25000 Steps) (loss=0.03192): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (22967 / 25000 Steps) (loss=0.02787): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (22970 / 25000 Steps) (loss=0.03792): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (22973 / 25000 Steps) (loss=0.02600): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (22976 / 25000 Steps) (loss=0.02682): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (22979 / 25000 Steps) (loss=0.02818): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (22982 / 25000 Steps) (loss=0.03585): 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "Training (22985 / 25000 Steps) (loss=0.02971): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "Training (22988 / 25000 Steps) (loss=0.02748): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (22991 / 25000 Steps) (loss=0.02697): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (22994 / 25000 Steps) (loss=0.03870): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (22997 / 25000 Steps) (loss=0.02586): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Validate (22998 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]it]\n",
      "Training (23000 / 25000 Steps) (loss=0.02781): 100%|██████████| 3/3 [00:02<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (23000 / 25000 Steps) (loss=0.02781): 100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
      "Training (23003 / 25000 Steps) (loss=0.03648): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (23006 / 25000 Steps) (loss=0.03249): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (23009 / 25000 Steps) (loss=0.02622): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (23012 / 25000 Steps) (loss=0.02956): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (23015 / 25000 Steps) (loss=0.02696): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (23018 / 25000 Steps) (loss=0.04637): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (23021 / 25000 Steps) (loss=0.03806): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (23024 / 25000 Steps) (loss=0.02877): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (23027 / 25000 Steps) (loss=0.04942): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (23030 / 25000 Steps) (loss=0.02579): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (23033 / 25000 Steps) (loss=0.02362): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (23036 / 25000 Steps) (loss=0.02429): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (23039 / 25000 Steps) (loss=0.03027): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (23042 / 25000 Steps) (loss=0.03857): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (23045 / 25000 Steps) (loss=0.02719): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (23048 / 25000 Steps) (loss=0.02929): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (23051 / 25000 Steps) (loss=0.03454): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (23054 / 25000 Steps) (loss=0.02331): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (23057 / 25000 Steps) (loss=0.03231): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (23060 / 25000 Steps) (loss=0.02668): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (23063 / 25000 Steps) (loss=0.02829): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (23066 / 25000 Steps) (loss=0.02919): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (23069 / 25000 Steps) (loss=0.03091): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (23072 / 25000 Steps) (loss=0.03076): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (23075 / 25000 Steps) (loss=0.03168): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (23078 / 25000 Steps) (loss=0.02406): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (23081 / 25000 Steps) (loss=0.02755): 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
      "Training (23084 / 25000 Steps) (loss=0.02770): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (23087 / 25000 Steps) (loss=0.03293): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (23090 / 25000 Steps) (loss=0.03321): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (23093 / 25000 Steps) (loss=0.03539): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (23096 / 25000 Steps) (loss=0.03723): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (23099 / 25000 Steps) (loss=0.03299): 100%|██████████| 3/3 [00:02<00:00,  1.25it/s]\n",
      "Training (23102 / 25000 Steps) (loss=0.03346): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (23105 / 25000 Steps) (loss=0.03014): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (23108 / 25000 Steps) (loss=0.02668): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (23111 / 25000 Steps) (loss=0.03919): 100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
      "Training (23114 / 25000 Steps) (loss=0.02065): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (23117 / 25000 Steps) (loss=0.03230): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (23120 / 25000 Steps) (loss=0.03322): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (23123 / 25000 Steps) (loss=0.04282): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (23126 / 25000 Steps) (loss=0.03423): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (23129 / 25000 Steps) (loss=0.03935): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (23132 / 25000 Steps) (loss=0.03244): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (23135 / 25000 Steps) (loss=0.04011): 100%|██████████| 3/3 [00:02<00:00,  1.06it/s]\n",
      "Training (23138 / 25000 Steps) (loss=0.02767): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (23141 / 25000 Steps) (loss=0.03019): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (23144 / 25000 Steps) (loss=0.02404): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (23147 / 25000 Steps) (loss=0.03233): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (23150 / 25000 Steps) (loss=0.03888): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (23153 / 25000 Steps) (loss=0.02928): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (23156 / 25000 Steps) (loss=0.02862): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (23159 / 25000 Steps) (loss=0.03134): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (23162 / 25000 Steps) (loss=0.02632): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (23165 / 25000 Steps) (loss=0.03230): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (23168 / 25000 Steps) (loss=0.03511): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (23171 / 25000 Steps) (loss=0.02433): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (23174 / 25000 Steps) (loss=0.02634): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (23177 / 25000 Steps) (loss=0.02567): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (23180 / 25000 Steps) (loss=0.03686): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "Training (23183 / 25000 Steps) (loss=0.04601): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (23186 / 25000 Steps) (loss=0.03292): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (23189 / 25000 Steps) (loss=0.04276): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "Training (23192 / 25000 Steps) (loss=0.03875): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (23195 / 25000 Steps) (loss=0.03685): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (23198 / 25000 Steps) (loss=0.03443): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (23201 / 25000 Steps) (loss=0.02994): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (23204 / 25000 Steps) (loss=0.03197): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (23207 / 25000 Steps) (loss=0.03559): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (23210 / 25000 Steps) (loss=0.03098): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (23213 / 25000 Steps) (loss=0.02819): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (23216 / 25000 Steps) (loss=0.03643): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (23219 / 25000 Steps) (loss=0.02854): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (23222 / 25000 Steps) (loss=0.02976): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (23225 / 25000 Steps) (loss=0.04129): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (23228 / 25000 Steps) (loss=0.03212): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (23231 / 25000 Steps) (loss=0.03398): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (23234 / 25000 Steps) (loss=0.03403): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (23237 / 25000 Steps) (loss=0.03386): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (23240 / 25000 Steps) (loss=0.02462): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (23243 / 25000 Steps) (loss=0.02933): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (23246 / 25000 Steps) (loss=0.03354): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (23249 / 25000 Steps) (loss=0.02603): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (23252 / 25000 Steps) (loss=0.03064): 100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
      "Training (23255 / 25000 Steps) (loss=0.02862): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (23258 / 25000 Steps) (loss=0.04402): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (23261 / 25000 Steps) (loss=0.03106): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (23264 / 25000 Steps) (loss=0.02696): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (23267 / 25000 Steps) (loss=0.02906): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (23270 / 25000 Steps) (loss=0.04403): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "Training (23273 / 25000 Steps) (loss=0.02780): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "Training (23276 / 25000 Steps) (loss=0.02985): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (23279 / 25000 Steps) (loss=0.02928): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (23282 / 25000 Steps) (loss=0.02495): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (23285 / 25000 Steps) (loss=0.03877): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (23288 / 25000 Steps) (loss=0.03178): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (23291 / 25000 Steps) (loss=0.02905): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (23294 / 25000 Steps) (loss=0.03207): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (23297 / 25000 Steps) (loss=0.03171): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (23300 / 25000 Steps) (loss=0.03384): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (23303 / 25000 Steps) (loss=0.02780): 100%|██████████| 3/3 [00:02<00:00,  1.16it/s]\n",
      "Training (23306 / 25000 Steps) (loss=0.03059): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (23309 / 25000 Steps) (loss=0.03166): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (23312 / 25000 Steps) (loss=0.04733): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (23315 / 25000 Steps) (loss=0.03357): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (23318 / 25000 Steps) (loss=0.03008): 100%|██████████| 3/3 [00:02<00:00,  1.32it/s]\n",
      "Training (23321 / 25000 Steps) (loss=0.02792): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (23324 / 25000 Steps) (loss=0.03268): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (23327 / 25000 Steps) (loss=0.03359): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (23330 / 25000 Steps) (loss=0.02812): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (23333 / 25000 Steps) (loss=0.03501): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (23336 / 25000 Steps) (loss=0.03097): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (23339 / 25000 Steps) (loss=0.02163): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (23342 / 25000 Steps) (loss=0.03474): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (23345 / 25000 Steps) (loss=0.02709): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (23348 / 25000 Steps) (loss=0.04134): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (23351 / 25000 Steps) (loss=0.02763): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (23354 / 25000 Steps) (loss=0.03263): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (23357 / 25000 Steps) (loss=0.02915): 100%|██████████| 3/3 [00:02<00:00,  1.32it/s]\n",
      "Training (23360 / 25000 Steps) (loss=0.03261): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (23363 / 25000 Steps) (loss=0.03123): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (23366 / 25000 Steps) (loss=0.04171): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (23369 / 25000 Steps) (loss=0.02920): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (23372 / 25000 Steps) (loss=0.03614): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (23375 / 25000 Steps) (loss=0.03218): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (23378 / 25000 Steps) (loss=0.04404): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "Training (23381 / 25000 Steps) (loss=0.03555): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (23384 / 25000 Steps) (loss=0.04151): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (23387 / 25000 Steps) (loss=0.03675): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (23390 / 25000 Steps) (loss=0.03204): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (23393 / 25000 Steps) (loss=0.02931): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (23396 / 25000 Steps) (loss=0.04741): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (23399 / 25000 Steps) (loss=0.02970): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (23402 / 25000 Steps) (loss=0.02825): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (23405 / 25000 Steps) (loss=0.02628): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (23408 / 25000 Steps) (loss=0.03254): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (23411 / 25000 Steps) (loss=0.03449): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (23414 / 25000 Steps) (loss=0.03546): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (23417 / 25000 Steps) (loss=0.03776): 100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
      "Training (23420 / 25000 Steps) (loss=0.03478): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (23423 / 25000 Steps) (loss=0.03686): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (23426 / 25000 Steps) (loss=0.02536): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (23429 / 25000 Steps) (loss=0.03861): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (23432 / 25000 Steps) (loss=0.02554): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (23435 / 25000 Steps) (loss=0.03032): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (23438 / 25000 Steps) (loss=0.03308): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (23441 / 25000 Steps) (loss=0.04599): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (23444 / 25000 Steps) (loss=0.02957): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (23447 / 25000 Steps) (loss=0.02948): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (23450 / 25000 Steps) (loss=0.02619): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "Training (23453 / 25000 Steps) (loss=0.03546): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (23456 / 25000 Steps) (loss=0.02992): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (23459 / 25000 Steps) (loss=0.03423): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (23462 / 25000 Steps) (loss=0.03176): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (23465 / 25000 Steps) (loss=0.02978): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (23468 / 25000 Steps) (loss=0.03808): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (23471 / 25000 Steps) (loss=0.03345): 100%|██████████| 3/3 [00:02<00:00,  1.07it/s]\n",
      "Training (23474 / 25000 Steps) (loss=0.03178): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (23477 / 25000 Steps) (loss=0.03091): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (23480 / 25000 Steps) (loss=0.03309): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (23483 / 25000 Steps) (loss=0.02886): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (23486 / 25000 Steps) (loss=0.02962): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (23489 / 25000 Steps) (loss=0.02510): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (23492 / 25000 Steps) (loss=0.03457): 100%|██████████| 3/3 [00:02<00:00,  1.24it/s]\n",
      "Training (23495 / 25000 Steps) (loss=0.03446): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (23498 / 25000 Steps) (loss=0.03158): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Validate (23499 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]it]\n",
      "Training (23501 / 25000 Steps) (loss=0.03284):  67%|██████▋   | 2/3 [00:02<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (23501 / 25000 Steps) (loss=0.03284): 100%|██████████| 3/3 [00:02<00:00,  1.24it/s]\n",
      "Training (23504 / 25000 Steps) (loss=0.03180): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (23507 / 25000 Steps) (loss=0.02681): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (23510 / 25000 Steps) (loss=0.02940): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (23513 / 25000 Steps) (loss=0.02973): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (23516 / 25000 Steps) (loss=0.02321): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (23519 / 25000 Steps) (loss=0.03326): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (23522 / 25000 Steps) (loss=0.03533): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (23525 / 25000 Steps) (loss=0.03360): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (23528 / 25000 Steps) (loss=0.02535): 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
      "Training (23531 / 25000 Steps) (loss=0.02684): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (23534 / 25000 Steps) (loss=0.02932): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (23537 / 25000 Steps) (loss=0.03413): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (23540 / 25000 Steps) (loss=0.03770): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (23543 / 25000 Steps) (loss=0.03131): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (23546 / 25000 Steps) (loss=0.03887): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (23549 / 25000 Steps) (loss=0.03170): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (23552 / 25000 Steps) (loss=0.03305): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (23555 / 25000 Steps) (loss=0.03270): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (23558 / 25000 Steps) (loss=0.02589): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (23561 / 25000 Steps) (loss=0.02585): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (23564 / 25000 Steps) (loss=0.03106): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (23567 / 25000 Steps) (loss=0.02412): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (23570 / 25000 Steps) (loss=0.03528): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (23573 / 25000 Steps) (loss=0.02460): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (23576 / 25000 Steps) (loss=0.01914): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (23579 / 25000 Steps) (loss=0.02645): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (23582 / 25000 Steps) (loss=0.03574): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (23585 / 25000 Steps) (loss=0.02894): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (23588 / 25000 Steps) (loss=0.03597): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (23591 / 25000 Steps) (loss=0.03071): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (23594 / 25000 Steps) (loss=0.03186): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (23597 / 25000 Steps) (loss=0.02765): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (23600 / 25000 Steps) (loss=0.04135): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (23603 / 25000 Steps) (loss=0.02619): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "Training (23606 / 25000 Steps) (loss=0.02349): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (23609 / 25000 Steps) (loss=0.03329): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (23612 / 25000 Steps) (loss=0.03043): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (23615 / 25000 Steps) (loss=0.03104): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (23618 / 25000 Steps) (loss=0.03483): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (23621 / 25000 Steps) (loss=0.02402): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (23624 / 25000 Steps) (loss=0.03137): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (23627 / 25000 Steps) (loss=0.03066): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (23630 / 25000 Steps) (loss=0.02901): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (23633 / 25000 Steps) (loss=0.02459): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (23636 / 25000 Steps) (loss=0.03107): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (23639 / 25000 Steps) (loss=0.03336): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (23642 / 25000 Steps) (loss=0.03357): 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
      "Training (23645 / 25000 Steps) (loss=0.03217): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (23648 / 25000 Steps) (loss=0.03504): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (23651 / 25000 Steps) (loss=0.03450): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (23654 / 25000 Steps) (loss=0.02767): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (23657 / 25000 Steps) (loss=0.02939): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (23660 / 25000 Steps) (loss=0.02878): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (23663 / 25000 Steps) (loss=0.03192): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (23666 / 25000 Steps) (loss=0.03303): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (23669 / 25000 Steps) (loss=0.03483): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (23672 / 25000 Steps) (loss=0.03689): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (23675 / 25000 Steps) (loss=0.04208): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (23678 / 25000 Steps) (loss=0.04216): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (23681 / 25000 Steps) (loss=0.05141): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (23684 / 25000 Steps) (loss=0.03496): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (23687 / 25000 Steps) (loss=0.03613): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (23690 / 25000 Steps) (loss=0.04015): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (23693 / 25000 Steps) (loss=0.03140): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (23696 / 25000 Steps) (loss=0.03495): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (23699 / 25000 Steps) (loss=0.03523): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (23702 / 25000 Steps) (loss=0.03458): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (23705 / 25000 Steps) (loss=0.03436): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (23708 / 25000 Steps) (loss=0.03500): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (23711 / 25000 Steps) (loss=0.02526): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (23714 / 25000 Steps) (loss=0.02824): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (23717 / 25000 Steps) (loss=0.02478): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (23720 / 25000 Steps) (loss=0.03009): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (23723 / 25000 Steps) (loss=0.02667): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (23726 / 25000 Steps) (loss=0.02160): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (23729 / 25000 Steps) (loss=0.02982): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (23732 / 25000 Steps) (loss=0.03188): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (23735 / 25000 Steps) (loss=0.02144): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (23738 / 25000 Steps) (loss=0.02382): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (23741 / 25000 Steps) (loss=0.02860): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (23744 / 25000 Steps) (loss=0.02325): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (23747 / 25000 Steps) (loss=0.02094): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (23750 / 25000 Steps) (loss=0.03220): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (23753 / 25000 Steps) (loss=0.02782): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (23756 / 25000 Steps) (loss=0.03295): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (23759 / 25000 Steps) (loss=0.02634): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (23762 / 25000 Steps) (loss=0.03442): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (23765 / 25000 Steps) (loss=0.03285): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (23768 / 25000 Steps) (loss=0.02815): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (23771 / 25000 Steps) (loss=0.03900): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (23774 / 25000 Steps) (loss=0.02458): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (23777 / 25000 Steps) (loss=0.02663): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (23780 / 25000 Steps) (loss=0.02537): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (23783 / 25000 Steps) (loss=0.03602): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (23786 / 25000 Steps) (loss=0.02794): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (23789 / 25000 Steps) (loss=0.02965): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (23792 / 25000 Steps) (loss=0.02910): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (23795 / 25000 Steps) (loss=0.03550): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (23798 / 25000 Steps) (loss=0.04050): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (23801 / 25000 Steps) (loss=0.03214): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (23804 / 25000 Steps) (loss=0.02610): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (23807 / 25000 Steps) (loss=0.02725): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (23810 / 25000 Steps) (loss=0.03000): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (23813 / 25000 Steps) (loss=0.03985): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (23816 / 25000 Steps) (loss=0.04674): 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "Training (23819 / 25000 Steps) (loss=0.03432): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (23822 / 25000 Steps) (loss=0.03007): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (23825 / 25000 Steps) (loss=0.03659): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (23828 / 25000 Steps) (loss=0.03567): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (23831 / 25000 Steps) (loss=0.02445): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (23834 / 25000 Steps) (loss=0.02436): 100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
      "Training (23837 / 25000 Steps) (loss=0.03346): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (23840 / 25000 Steps) (loss=0.02718): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (23843 / 25000 Steps) (loss=0.02639): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (23846 / 25000 Steps) (loss=0.03526): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (23849 / 25000 Steps) (loss=0.03111): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (23852 / 25000 Steps) (loss=0.02436): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (23855 / 25000 Steps) (loss=0.03574): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (23858 / 25000 Steps) (loss=0.03661): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (23861 / 25000 Steps) (loss=0.03002): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (23864 / 25000 Steps) (loss=0.02703): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (23867 / 25000 Steps) (loss=0.03212): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (23870 / 25000 Steps) (loss=0.03051): 100%|██████████| 3/3 [00:02<00:00,  1.09it/s]\n",
      "Training (23873 / 25000 Steps) (loss=0.03075): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (23876 / 25000 Steps) (loss=0.02968): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (23879 / 25000 Steps) (loss=0.04345): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (23882 / 25000 Steps) (loss=0.03687): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (23885 / 25000 Steps) (loss=0.03042): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (23888 / 25000 Steps) (loss=0.03525): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (23891 / 25000 Steps) (loss=0.04390): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (23894 / 25000 Steps) (loss=0.03754): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (23897 / 25000 Steps) (loss=0.03546): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (23900 / 25000 Steps) (loss=0.02609): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (23903 / 25000 Steps) (loss=0.03486): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (23906 / 25000 Steps) (loss=0.03035): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (23909 / 25000 Steps) (loss=0.03347): 100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
      "Training (23912 / 25000 Steps) (loss=0.04036): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (23915 / 25000 Steps) (loss=0.03341): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (23918 / 25000 Steps) (loss=0.02955): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (23921 / 25000 Steps) (loss=0.03209): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (23924 / 25000 Steps) (loss=0.03300): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (23927 / 25000 Steps) (loss=0.03411): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "Training (23930 / 25000 Steps) (loss=0.02762): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (23933 / 25000 Steps) (loss=0.02706): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (23936 / 25000 Steps) (loss=0.03833): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (23939 / 25000 Steps) (loss=0.03685): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (23942 / 25000 Steps) (loss=0.02935): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (23945 / 25000 Steps) (loss=0.02846): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (23948 / 25000 Steps) (loss=0.02599): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (23951 / 25000 Steps) (loss=0.02610): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (23954 / 25000 Steps) (loss=0.03368): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (23957 / 25000 Steps) (loss=0.03345): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (23960 / 25000 Steps) (loss=0.02638): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (23963 / 25000 Steps) (loss=0.04899): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (23966 / 25000 Steps) (loss=0.03226): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (23969 / 25000 Steps) (loss=0.04421): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (23972 / 25000 Steps) (loss=0.03273): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (23975 / 25000 Steps) (loss=0.03221): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (23978 / 25000 Steps) (loss=0.03733): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (23981 / 25000 Steps) (loss=0.02675): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
      "Training (23984 / 25000 Steps) (loss=0.02744): 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]\n",
      "Training (23987 / 25000 Steps) (loss=0.02750): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (23990 / 25000 Steps) (loss=0.02402): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (23993 / 25000 Steps) (loss=0.03457): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (23996 / 25000 Steps) (loss=0.02941): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (23999 / 25000 Steps) (loss=0.03156): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Validate (24000 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "Training (24002 / 25000 Steps) (loss=0.02618): 100%|██████████| 3/3 [00:02<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (24002 / 25000 Steps) (loss=0.02618): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "Training (24005 / 25000 Steps) (loss=0.02047): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (24008 / 25000 Steps) (loss=0.02610): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (24011 / 25000 Steps) (loss=0.03111): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (24014 / 25000 Steps) (loss=0.02533): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (24017 / 25000 Steps) (loss=0.02878): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (24020 / 25000 Steps) (loss=0.01927): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (24023 / 25000 Steps) (loss=0.04008): 100%|██████████| 3/3 [00:01<00:00,  2.02it/s]\n",
      "Training (24026 / 25000 Steps) (loss=0.04140): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (24029 / 25000 Steps) (loss=0.02507): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (24032 / 25000 Steps) (loss=0.03066): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (24035 / 25000 Steps) (loss=0.02201): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (24038 / 25000 Steps) (loss=0.02816): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (24041 / 25000 Steps) (loss=0.02260): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (24044 / 25000 Steps) (loss=0.03463): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (24047 / 25000 Steps) (loss=0.02695): 100%|██████████| 3/3 [00:02<00:00,  1.09it/s]\n",
      "Training (24050 / 25000 Steps) (loss=0.03033): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (24053 / 25000 Steps) (loss=0.02611): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (24056 / 25000 Steps) (loss=0.02442): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (24059 / 25000 Steps) (loss=0.03592): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (24062 / 25000 Steps) (loss=0.03365): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (24065 / 25000 Steps) (loss=0.02878): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (24068 / 25000 Steps) (loss=0.02717): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (24071 / 25000 Steps) (loss=0.03330): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (24074 / 25000 Steps) (loss=0.04904): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (24077 / 25000 Steps) (loss=0.02933): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (24080 / 25000 Steps) (loss=0.03014): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (24083 / 25000 Steps) (loss=0.04304): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (24086 / 25000 Steps) (loss=0.02576): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (24089 / 25000 Steps) (loss=0.02892): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (24092 / 25000 Steps) (loss=0.03405): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (24095 / 25000 Steps) (loss=0.02979): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (24098 / 25000 Steps) (loss=0.02977): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (24101 / 25000 Steps) (loss=0.03584): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (24104 / 25000 Steps) (loss=0.03388): 100%|██████████| 3/3 [00:02<00:00,  1.32it/s]\n",
      "Training (24107 / 25000 Steps) (loss=0.02277): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (24110 / 25000 Steps) (loss=0.03903): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (24113 / 25000 Steps) (loss=0.03677): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (24116 / 25000 Steps) (loss=0.02246): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (24119 / 25000 Steps) (loss=0.02479): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (24122 / 25000 Steps) (loss=0.03067): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (24125 / 25000 Steps) (loss=0.03071): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (24128 / 25000 Steps) (loss=0.04267): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (24131 / 25000 Steps) (loss=0.02872): 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
      "Training (24134 / 25000 Steps) (loss=0.02698): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (24137 / 25000 Steps) (loss=0.03412): 100%|██████████| 3/3 [00:01<00:00,  1.98it/s]\n",
      "Training (24140 / 25000 Steps) (loss=0.03667): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (24143 / 25000 Steps) (loss=0.03348): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (24146 / 25000 Steps) (loss=0.03177): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (24149 / 25000 Steps) (loss=0.02041): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (24152 / 25000 Steps) (loss=0.02456): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (24155 / 25000 Steps) (loss=0.02948): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (24158 / 25000 Steps) (loss=0.02805): 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "Training (24161 / 25000 Steps) (loss=0.02295): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (24164 / 25000 Steps) (loss=0.03302): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (24167 / 25000 Steps) (loss=0.03405): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (24170 / 25000 Steps) (loss=0.02355): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (24173 / 25000 Steps) (loss=0.02644): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (24176 / 25000 Steps) (loss=0.03262): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (24179 / 25000 Steps) (loss=0.02955): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (24182 / 25000 Steps) (loss=0.02622): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (24185 / 25000 Steps) (loss=0.02711): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (24188 / 25000 Steps) (loss=0.02641): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (24191 / 25000 Steps) (loss=0.03327): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (24194 / 25000 Steps) (loss=0.02485): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (24197 / 25000 Steps) (loss=0.02932): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (24200 / 25000 Steps) (loss=0.02827): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (24203 / 25000 Steps) (loss=0.03744): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (24206 / 25000 Steps) (loss=0.02981): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (24209 / 25000 Steps) (loss=0.02552): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (24212 / 25000 Steps) (loss=0.02858): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (24215 / 25000 Steps) (loss=0.03432): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (24218 / 25000 Steps) (loss=0.02303): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Training (24221 / 25000 Steps) (loss=0.03774): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (24224 / 25000 Steps) (loss=0.03497): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (24227 / 25000 Steps) (loss=0.03059): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (24230 / 25000 Steps) (loss=0.02860): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (24233 / 25000 Steps) (loss=0.03349): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (24236 / 25000 Steps) (loss=0.04064): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (24239 / 25000 Steps) (loss=0.02833): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (24242 / 25000 Steps) (loss=0.03634): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (24245 / 25000 Steps) (loss=0.04285): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (24248 / 25000 Steps) (loss=0.03823): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (24251 / 25000 Steps) (loss=0.03400): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (24254 / 25000 Steps) (loss=0.02940): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (24257 / 25000 Steps) (loss=0.03274): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (24260 / 25000 Steps) (loss=0.02903): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (24263 / 25000 Steps) (loss=0.03601): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (24266 / 25000 Steps) (loss=0.03992): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (24269 / 25000 Steps) (loss=0.03720): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (24272 / 25000 Steps) (loss=0.02884): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (24275 / 25000 Steps) (loss=0.02508): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (24278 / 25000 Steps) (loss=0.03595): 100%|██████████| 3/3 [00:02<00:00,  1.00it/s]\n",
      "Training (24281 / 25000 Steps) (loss=0.03131): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (24284 / 25000 Steps) (loss=0.02930): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (24287 / 25000 Steps) (loss=0.02952): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (24290 / 25000 Steps) (loss=0.03622): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (24293 / 25000 Steps) (loss=0.02807): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (24296 / 25000 Steps) (loss=0.03297): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (24299 / 25000 Steps) (loss=0.03027): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (24302 / 25000 Steps) (loss=0.03310): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (24305 / 25000 Steps) (loss=0.04233): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (24308 / 25000 Steps) (loss=0.03739): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (24311 / 25000 Steps) (loss=0.02808): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (24314 / 25000 Steps) (loss=0.04144): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (24317 / 25000 Steps) (loss=0.02602): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (24320 / 25000 Steps) (loss=0.03808): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (24323 / 25000 Steps) (loss=0.02894): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (24326 / 25000 Steps) (loss=0.03411): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (24329 / 25000 Steps) (loss=0.02637): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (24332 / 25000 Steps) (loss=0.03271): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (24335 / 25000 Steps) (loss=0.03678): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (24338 / 25000 Steps) (loss=0.03553): 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "Training (24341 / 25000 Steps) (loss=0.03960): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (24344 / 25000 Steps) (loss=0.03016): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (24347 / 25000 Steps) (loss=0.02506): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (24350 / 25000 Steps) (loss=0.02860): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (24353 / 25000 Steps) (loss=0.02930): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (24356 / 25000 Steps) (loss=0.02415): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "Training (24359 / 25000 Steps) (loss=0.02498): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (24362 / 25000 Steps) (loss=0.03534): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (24365 / 25000 Steps) (loss=0.03666): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (24368 / 25000 Steps) (loss=0.04299): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (24371 / 25000 Steps) (loss=0.04566): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (24374 / 25000 Steps) (loss=0.03177): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (24377 / 25000 Steps) (loss=0.02708): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (24380 / 25000 Steps) (loss=0.04097): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (24383 / 25000 Steps) (loss=0.02926): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (24386 / 25000 Steps) (loss=0.03399): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (24389 / 25000 Steps) (loss=0.03048): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (24392 / 25000 Steps) (loss=0.02632): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (24395 / 25000 Steps) (loss=0.02907): 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]\n",
      "Training (24398 / 25000 Steps) (loss=0.03648): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (24401 / 25000 Steps) (loss=0.04703): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (24404 / 25000 Steps) (loss=0.03786): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (24407 / 25000 Steps) (loss=0.03090): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (24410 / 25000 Steps) (loss=0.02817): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (24413 / 25000 Steps) (loss=0.04467): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (24416 / 25000 Steps) (loss=0.04077): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (24419 / 25000 Steps) (loss=0.04525): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (24422 / 25000 Steps) (loss=0.04254): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (24425 / 25000 Steps) (loss=0.03749): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (24428 / 25000 Steps) (loss=0.02678): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (24431 / 25000 Steps) (loss=0.03120): 100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "Training (24434 / 25000 Steps) (loss=0.04386): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (24437 / 25000 Steps) (loss=0.03052): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (24440 / 25000 Steps) (loss=0.03299): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (24443 / 25000 Steps) (loss=0.03562): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (24446 / 25000 Steps) (loss=0.03362): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (24449 / 25000 Steps) (loss=0.03166): 100%|██████████| 3/3 [00:02<00:00,  1.10it/s]\n",
      "Training (24452 / 25000 Steps) (loss=0.03297): 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "Training (24455 / 25000 Steps) (loss=0.02595): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (24458 / 25000 Steps) (loss=0.03591): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (24461 / 25000 Steps) (loss=0.03075): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (24464 / 25000 Steps) (loss=0.02448): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (24467 / 25000 Steps) (loss=0.03491): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (24470 / 25000 Steps) (loss=0.02525): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "Training (24473 / 25000 Steps) (loss=0.03169): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (24476 / 25000 Steps) (loss=0.02807): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (24479 / 25000 Steps) (loss=0.02596): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (24482 / 25000 Steps) (loss=0.03211): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (24485 / 25000 Steps) (loss=0.02357): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (24488 / 25000 Steps) (loss=0.02419): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (24491 / 25000 Steps) (loss=0.02461): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (24494 / 25000 Steps) (loss=0.02763): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (24497 / 25000 Steps) (loss=0.03905): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Validate (24498 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]/s]\n",
      "Training (24500 / 25000 Steps) (loss=0.02584): 100%|██████████| 3/3 [00:02<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (24500 / 25000 Steps) (loss=0.02584): 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]\n",
      "Training (24503 / 25000 Steps) (loss=0.02334): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (24506 / 25000 Steps) (loss=0.03237): 100%|██████████| 3/3 [00:02<00:00,  1.07it/s]\n",
      "Training (24509 / 25000 Steps) (loss=0.02969): 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n",
      "Training (24512 / 25000 Steps) (loss=0.03495): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "Training (24515 / 25000 Steps) (loss=0.03547): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (24518 / 25000 Steps) (loss=0.02960): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (24521 / 25000 Steps) (loss=0.02539): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (24524 / 25000 Steps) (loss=0.02979): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (24527 / 25000 Steps) (loss=0.03296): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (24530 / 25000 Steps) (loss=0.02129): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (24533 / 25000 Steps) (loss=0.03072): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (24536 / 25000 Steps) (loss=0.02809): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (24539 / 25000 Steps) (loss=0.02617): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (24542 / 25000 Steps) (loss=0.03615): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (24545 / 25000 Steps) (loss=0.03254): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (24548 / 25000 Steps) (loss=0.02472): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (24551 / 25000 Steps) (loss=0.02839): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (24554 / 25000 Steps) (loss=0.03790): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (24557 / 25000 Steps) (loss=0.03338): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (24560 / 25000 Steps) (loss=0.03330): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (24563 / 25000 Steps) (loss=0.03463): 100%|██████████| 3/3 [00:02<00:00,  1.03it/s]\n",
      "Training (24566 / 25000 Steps) (loss=0.02343): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (24569 / 25000 Steps) (loss=0.03467): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (24572 / 25000 Steps) (loss=0.02939): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (24575 / 25000 Steps) (loss=0.03093): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (24578 / 25000 Steps) (loss=0.02327): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (24581 / 25000 Steps) (loss=0.03180): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (24584 / 25000 Steps) (loss=0.02542): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (24587 / 25000 Steps) (loss=0.01883): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (24590 / 25000 Steps) (loss=0.04777): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (24593 / 25000 Steps) (loss=0.03559): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (24596 / 25000 Steps) (loss=0.03105): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (24599 / 25000 Steps) (loss=0.03637): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (24602 / 25000 Steps) (loss=0.03798): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (24605 / 25000 Steps) (loss=0.03123): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (24608 / 25000 Steps) (loss=0.03236): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (24611 / 25000 Steps) (loss=0.03028): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (24614 / 25000 Steps) (loss=0.02352): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (24617 / 25000 Steps) (loss=0.03417): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (24620 / 25000 Steps) (loss=0.03266): 100%|██████████| 3/3 [00:02<00:00,  1.16it/s]\n",
      "Training (24623 / 25000 Steps) (loss=0.03888): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (24626 / 25000 Steps) (loss=0.03461): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (24629 / 25000 Steps) (loss=0.03286): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (24632 / 25000 Steps) (loss=0.03242): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (24635 / 25000 Steps) (loss=0.03074): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (24638 / 25000 Steps) (loss=0.03620): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (24641 / 25000 Steps) (loss=0.02824): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (24644 / 25000 Steps) (loss=0.03430): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (24647 / 25000 Steps) (loss=0.04043): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (24650 / 25000 Steps) (loss=0.02902): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (24653 / 25000 Steps) (loss=0.03518): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (24656 / 25000 Steps) (loss=0.02515): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (24659 / 25000 Steps) (loss=0.02443): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (24662 / 25000 Steps) (loss=0.02428): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (24665 / 25000 Steps) (loss=0.03228): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (24668 / 25000 Steps) (loss=0.02908): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (24671 / 25000 Steps) (loss=0.02716): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (24674 / 25000 Steps) (loss=0.02059): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (24677 / 25000 Steps) (loss=0.04076): 100%|██████████| 3/3 [00:02<00:00,  1.19it/s]\n",
      "Training (24680 / 25000 Steps) (loss=0.02833): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (24683 / 25000 Steps) (loss=0.02725): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (24686 / 25000 Steps) (loss=0.02086): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (24689 / 25000 Steps) (loss=0.02772): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (24692 / 25000 Steps) (loss=0.03085): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (24695 / 25000 Steps) (loss=0.02937): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (24698 / 25000 Steps) (loss=0.02296): 100%|██████████| 3/3 [00:02<00:00,  1.16it/s]\n",
      "Training (24701 / 25000 Steps) (loss=0.03620): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "Training (24704 / 25000 Steps) (loss=0.03604): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (24707 / 25000 Steps) (loss=0.02929): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (24710 / 25000 Steps) (loss=0.02921): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (24713 / 25000 Steps) (loss=0.02676): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (24716 / 25000 Steps) (loss=0.03617): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (24719 / 25000 Steps) (loss=0.02801): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (24722 / 25000 Steps) (loss=0.03739): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (24725 / 25000 Steps) (loss=0.02375): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (24728 / 25000 Steps) (loss=0.03337): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (24731 / 25000 Steps) (loss=0.03059): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (24734 / 25000 Steps) (loss=0.02520): 100%|██████████| 3/3 [00:02<00:00,  1.10it/s]\n",
      "Training (24737 / 25000 Steps) (loss=0.03181): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (24740 / 25000 Steps) (loss=0.02231): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (24743 / 25000 Steps) (loss=0.03521): 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "Training (24746 / 25000 Steps) (loss=0.02726): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (24749 / 25000 Steps) (loss=0.02876): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (24752 / 25000 Steps) (loss=0.02024): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (24755 / 25000 Steps) (loss=0.03144): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (24758 / 25000 Steps) (loss=0.03396): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Training (24761 / 25000 Steps) (loss=0.02678): 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "Training (24764 / 25000 Steps) (loss=0.03286): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "Training (24767 / 25000 Steps) (loss=0.03787): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Training (24770 / 25000 Steps) (loss=0.03749): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (24773 / 25000 Steps) (loss=0.01947): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (24776 / 25000 Steps) (loss=0.02597): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (24779 / 25000 Steps) (loss=0.02544): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (24782 / 25000 Steps) (loss=0.02847): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (24785 / 25000 Steps) (loss=0.04025): 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
      "Training (24788 / 25000 Steps) (loss=0.02920): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (24791 / 25000 Steps) (loss=0.04231): 100%|██████████| 3/3 [00:02<00:00,  1.24it/s]\n",
      "Training (24794 / 25000 Steps) (loss=0.03056): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (24797 / 25000 Steps) (loss=0.03881): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "Training (24800 / 25000 Steps) (loss=0.03086): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (24803 / 25000 Steps) (loss=0.02511): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (24806 / 25000 Steps) (loss=0.03003): 100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
      "Training (24809 / 25000 Steps) (loss=0.03230): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Training (24812 / 25000 Steps) (loss=0.03200): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (24815 / 25000 Steps) (loss=0.03224): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (24818 / 25000 Steps) (loss=0.02820): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (24821 / 25000 Steps) (loss=0.05389): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "Training (24824 / 25000 Steps) (loss=0.02514): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (24827 / 25000 Steps) (loss=0.03242): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (24830 / 25000 Steps) (loss=0.03387): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (24833 / 25000 Steps) (loss=0.03102): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (24836 / 25000 Steps) (loss=0.03638): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Training (24839 / 25000 Steps) (loss=0.03020): 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n",
      "Training (24842 / 25000 Steps) (loss=0.03691): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (24845 / 25000 Steps) (loss=0.03286): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (24848 / 25000 Steps) (loss=0.02754): 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
      "Training (24851 / 25000 Steps) (loss=0.02680): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Training (24854 / 25000 Steps) (loss=0.03435): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (24857 / 25000 Steps) (loss=0.03799): 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "Training (24860 / 25000 Steps) (loss=0.02990): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (24863 / 25000 Steps) (loss=0.02342): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (24866 / 25000 Steps) (loss=0.03168): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (24869 / 25000 Steps) (loss=0.02834): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "Training (24872 / 25000 Steps) (loss=0.02892): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (24875 / 25000 Steps) (loss=0.02659): 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Training (24878 / 25000 Steps) (loss=0.02544): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (24881 / 25000 Steps) (loss=0.03145): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (24884 / 25000 Steps) (loss=0.02900): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (24887 / 25000 Steps) (loss=0.03200): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (24890 / 25000 Steps) (loss=0.02625): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (24893 / 25000 Steps) (loss=0.02803): 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "Training (24896 / 25000 Steps) (loss=0.02920): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "Training (24899 / 25000 Steps) (loss=0.03290): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (24902 / 25000 Steps) (loss=0.02783): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "Training (24905 / 25000 Steps) (loss=0.03305): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Training (24908 / 25000 Steps) (loss=0.03164): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "Training (24911 / 25000 Steps) (loss=0.02400): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (24914 / 25000 Steps) (loss=0.02806): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (24917 / 25000 Steps) (loss=0.03284): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (24920 / 25000 Steps) (loss=0.03688): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (24923 / 25000 Steps) (loss=0.03738): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n",
      "Training (24926 / 25000 Steps) (loss=0.02758): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "Training (24929 / 25000 Steps) (loss=0.02827): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (24932 / 25000 Steps) (loss=0.03211): 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n",
      "Training (24935 / 25000 Steps) (loss=0.03182): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (24938 / 25000 Steps) (loss=0.03877): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Training (24941 / 25000 Steps) (loss=0.02580): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
      "Training (24944 / 25000 Steps) (loss=0.02576): 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]\n",
      "Training (24947 / 25000 Steps) (loss=0.02615): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Training (24950 / 25000 Steps) (loss=0.02850): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Training (24953 / 25000 Steps) (loss=0.02408): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "Training (24956 / 25000 Steps) (loss=0.03408): 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "Training (24959 / 25000 Steps) (loss=0.03539): 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "Training (24962 / 25000 Steps) (loss=0.03801): 100%|██████████| 3/3 [00:02<00:00,  1.19it/s]\n",
      "Training (24965 / 25000 Steps) (loss=0.04578): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
      "Training (24968 / 25000 Steps) (loss=0.03588): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (24971 / 25000 Steps) (loss=0.03579): 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Training (24974 / 25000 Steps) (loss=0.02867): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "Training (24977 / 25000 Steps) (loss=0.03012): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "Training (24980 / 25000 Steps) (loss=0.02601): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "Training (24983 / 25000 Steps) (loss=0.02737): 100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
      "Training (24986 / 25000 Steps) (loss=0.03113): 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "Training (24989 / 25000 Steps) (loss=0.03104): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "Training (24992 / 25000 Steps) (loss=0.03849): 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Training (24995 / 25000 Steps) (loss=0.03100): 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n",
      "Training (24998 / 25000 Steps) (loss=0.03439): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "Validate (24999 / 10 Steps) (dice=0.49949): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]it]\n",
      "Training (25001 / 25000 Steps) (loss=0.04809):  67%|██████▋   | 2/3 [00:02<00:01,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.49948519468307495 Current Avg. Dice: 0.49948519468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (25001 / 25000 Steps) (loss=0.04809): 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validation(epoch_iterator_val):\n",
    "    model.eval()\n",
    "    dice_vals = list()\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(epoch_iterator_val):\n",
    "            val_inputs, val_labels = (batch[\"image\"].cuda(), batch[\"label\"].cuda())\n",
    "            val_outputs = sliding_window_inference(val_inputs, size, 4, model)\n",
    "            val_labels_list = decollate_batch(val_labels)\n",
    "            val_labels_convert = [\n",
    "                post_label(val_label_tensor) for val_label_tensor in val_labels_list\n",
    "            ]\n",
    "            val_outputs_list = decollate_batch(val_outputs)\n",
    "            val_output_convert = [\n",
    "                post_pred(val_pred_tensor) for val_pred_tensor in val_outputs_list\n",
    "            ]\n",
    "            dice_metric(y_pred=val_output_convert, y=val_labels_convert)\n",
    "            dice = dice_metric.aggregate().item()\n",
    "            dice_vals.append(dice)\n",
    "            epoch_iterator_val.set_description(\n",
    "                \"Validate (%d / %d Steps) (dice=%2.5f)\" % (global_step, 10.0, dice)\n",
    "            )\n",
    "        dice_metric.reset()\n",
    "    mean_dice_val = np.mean(dice_vals)\n",
    "    return mean_dice_val\n",
    "\n",
    "\n",
    "def train(global_step, train_loader, dice_val_best, global_step_best):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    epoch_iterator = tqdm(\n",
    "        train_loader, desc=\"Training (X / X Steps) (loss=X.X)\", dynamic_ncols=True\n",
    "    )\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        step += 1\n",
    "        x, y = (batch[\"image\"].cuda(), batch[\"label\"].cuda())\n",
    "        logit_map = model(x)\n",
    "        loss = loss_function(logit_map, y)\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        epoch_iterator.set_description(\n",
    "            \"Training (%d / %d Steps) (loss=%2.5f)\" % (global_step, max_iterations, loss)\n",
    "        )\n",
    "        if (\n",
    "            global_step % eval_num == 0 and global_step != 0\n",
    "        ) or global_step == max_iterations:\n",
    "            epoch_iterator_val = tqdm(\n",
    "                val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True\n",
    "            )\n",
    "            dice_val = validation(epoch_iterator_val)\n",
    "            epoch_loss /= step\n",
    "            epoch_loss_values.append(epoch_loss)\n",
    "            metric_values.append(dice_val)\n",
    "            if dice_val > dice_val_best:\n",
    "                dice_val_best = dice_val\n",
    "                global_step_best = global_step\n",
    "                torch.save(\n",
    "                    model.state_dict(), os.path.join(root_dir, \"best_metric_model.pth\")\n",
    "                )\n",
    "                print(\n",
    "                    \"Model Was Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(\n",
    "                        dice_val_best, dice_val\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                print(\n",
    "                    \"Model Was Not Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(\n",
    "                        dice_val_best, dice_val\n",
    "                    )\n",
    "                )\n",
    "        global_step += 1\n",
    "    return global_step, dice_val_best, global_step_best\n",
    "\n",
    "\n",
    "max_iterations = 25000\n",
    "eval_num = 500\n",
    "post_label = AsDiscrete(to_onehot = 2)\n",
    "post_pred = AsDiscrete(argmax=True, to_onehot = 2)\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "global_step = 0\n",
    "dice_val_best = 0.0\n",
    "global_step_best = 0\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "while global_step < max_iterations:\n",
    "    global_step, dice_val_best, global_step_best = train(\n",
    "        global_step, train_loader, dice_val_best, global_step_best\n",
    "    )\n",
    "model.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model.pth\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train completed, best_metric: 0.4995 at iteration: 500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\n",
    "    f\"train completed, best_metric: {dice_val_best:.4f} \"   \n",
    "    f\"at iteration: {global_step_best}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check best model output with the input image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_map = {\n",
    "    \"027-VE-liver.nii.gz\": 64,\n",
    "    \"028-VE-liver.nii.gz\": 230,\n",
    "    \"030-VE-liver.nii.gz\": 204,\n",
    "    \"031-VE-liver.nii.gz\": 204,\n",
    "    \"032-VE-liver.nii.gz\": 38,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABA4AAAFWCAYAAADpO999AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABVkElEQVR4nO3de5Bu113e+WdJ1rnr3CRZ1s2SLDmyEeCbygZsg7FNuMTgJMUQCDPjEFMmM5lASDLcqjIhUzMBaqhgpmYGxoNDuSYuDBim7ABj4xgZMAMqW7ZsWZawhS7W/UhHOjq3PudI1po/ut+tp7f3s3u93X3ePt3v91Pl8uq392Wttfe762j377d+pdYqAAAAAACAIedtdAcAAAAAAMC5ixcHAAAAAAAg4sUBAAAAAACIeHEAAAAAAAAiXhwAAAAAAICIFwcAAAAAACDixQFmrpRyRynlTRvdDwDA80op95VS3tqwXS2lXL/Kc6x6XwAAsHF4cYCZq7XeWGv9xEb3AwAAANhM1vsFLC900YoXBwAAAAAAIOLFAWZuEg5bSvn5UsrvllL+YynlWCnl9lLK3yql/Gwp5VAp5YFSyt+2/X6klHLn0rb3lFJ+rHfcnyqlPFJKebiU8qP+BrWUsr2U8sullK+UUh4rpfx6KWXnrMcOAOe6UsprSyl/WUo5svRM/d9KKdt6m33P0nP4iVLK/1JKOc/2/8dLz+qnSikfLaVcPeMhAMA5r5Ty8lLKJ5aetXeUUr5v6fNPlFJ+1Lb7R6WUTy61/2zp48+VUo6XUv5BKeVNpZQHSyk/t/RMvq+U8sO2/1THO9vjxubFiwNstO+V9H9LOiDps5I+qsX78gpJ/6Ok/9O2PSTpbZL2SvoRSb9SSnm1JJVSvkvSv5D0VknXS3pT7zy/KOlvSXrl0u+vkPQ/nIXxAMBm91VJPynpYknfLOktkv7b3jZ/T9JNkl4t6e2S/rEklVLeLunnJP19SZdI+nNJvzWTXgPAJlFKuUDSf5L0x5JeKOmfSXp/KeWGsf1qrd+61HxFrXVPrfW3l35+kRaf2VdIeoek96x0rBWOB3wNXhxgo/15rfWjtdZnJf2uFv+h+Yu11mckfUDSNaWU/ZJUa/3DWuvf1EV/qsWH7RuXjvMDkn6z1npHrfWkpJ+fnKCUUiS9S9JP1lqfrLUek/TvJP3gbIYIAJtHrfXWWutf1VqfrbXep8UXuN/W2+yXlp6nX5H0bkk/tPT5P5H0C7XWO5ee6/9O0iuJOgCAZb5J0h4t/pv3TK31TyT9gZ5/lq7Gv661nl76N/IfavHfxsC64cUBNtpj1l6Q9ESt9av2s7T4YFUp5btLKX9VSnmylHJE0vdo8e2qJF0u6QE7lrcvkbRL0q1L4WBHJH1k6XMAgFlKGfuDUsqjpZSjWvyP/4t7m/kz9n4tPoMl6WpJv2rP2iclFS3+FQwAsOhySQ/UWp+zz+7X6p+VT9VaT/SOdXnaGFgNXhxgUyilbJf0e5J+WdKltdb9kv5Ii/8glaRHJF1pu1xl7Se0+BLixlrr/qX/7au17jn7PQeATefXJN0l6aW11r1aTD0ovW38GftiSQ8vtR+Q9GP2rN1fa91Za/3/znqvAWDzeFjSVb4+jBafpQ9JOqHFP3hNvKjheAdKKbt7x5o8l1dzPOBr8OIAm8U2SdslPS7p2VLKd0v62/b735H0I0sLzeyS9K8nv1h6m/t/aXFNhBdKUinlilLKd86s9wCweVwo6aik46WUl0n6bwa2+e9LKQdKKVdJ+glJk7zYX5f0s6WUGyWplLKvlPJfzKLTALCJ3CLppKSfKqVcUEp5kxbX/fqApNsk/f1Syq6lRb7f2dv3MUkvGTjmvy2lbCulvFGLa4L97tLnqz0esAwvDrApLK1L8ONafEHwlKR/KOnD9vv/V9L/KulmSXdL+qulX51e+v+fnny+FHr7nyWtuGgMAMyhf6XFZ+wxLb50HVos60OSbtXiP0j/UNJ7JanW+v9I+iVJH1h61n5B0nef/S4DwOZRaz2jxRcF363FyNj/Q9J/XWu9S9KvSDqjxf+gf5+k9/d2/3lJ71tKCZusY/CoFv99/PDS9v9k6Vha5fGAr1FqrRvdB2DdlVJersV/sG5fWqALAAAA2FKWohX+Y631yhU2BdaEiANsGaWUv1dK2V5KOaDFv3j9J14aAAAAAMDa8OIAW8mPSTok6W+0WId8KC8XAAAAADAFUhUAAAAAAEC0poiDUsp3lVL+upRydynlZ9arUwCAdjyLAWBj8RwGsNWtOuKglHK+pC9J+g5JD0r6lKQfqrV+Me2zY8eOumfPHknSzp07B7fx/px33vPvNUrpl5Ae3sfbF1xwQdd+wQte0LWfeeaZrv3cc88N7uv83Kkf/X39uGPbDfFxe7/H5mBom7MVTZLmO435bJ3btcxNy3HGfuf30/bt2we38c/9Op46dWrw82efHV6CYWwu/XenT58e/Nzn4/zzz+/a27ZtG9zG++Tbe9vvRUk6c+bMYP/Sd83HurCwMNiPjXL48GEdP3584zuyCtM+i7eV7XWHdg/9CgA21DE99USt9ZKN7se0VvNvYp7FAM5Fp3RCZ+rpwX8Tv2Dow0avlXR3rfUeSSqlfEDS2yXFh+SePXv0vd/7vZKkV7ziFd3n/h8UX/3qV7v2rl27nu/oyH9A+388+X/0vehFL+raBw8e7NqPPfZY1z5+/PjguZ2f2/9DyvX39f8w8t+1vFDYsWNH177ooou6tv9HX3qp4u3W/5D3/qXj+rF8e597/w/JdMy+9BLC90nndum6OB+P33P9efKfve3300te8ny5W+/rNddc07UnL8kk6a677urau3c//w+Fw4cPD/bJ7x9p+fhOnjzZte++++6u7S8nfPu9e/d27auuuqpr+/3k3zXffv/+/V3bv0OS9MADDwye78CBA1374Ycf7tpPPPFE1/7iF59/TPi+6cXXal6IpXt56N78hV/4haZjnqOmehbv0G69rrxlht0DgDb/uX7w/o3uwypN/W9insUAzkW31I/H360lVeEKSQ/Yzw8ufbZMKeVdpZRPl1I+7f9hAwBYFys+i/05/IxOCwCwrqb+NzHPYgCbzVoiDprUWt8j6T2SdOWVV9aXv/zlkpb/ddXDmf0vn+mvyP3wbv8L5JVXPl/C1P/66y8tfP/0V+6Wv7yPhXH7X5v9L5zeD/8Lve9/4YUXdm3/q3D6y2yap7G/zLb8ZTe1va9p39Z0kBSmnsLuU/SCX9OWqBDvX397H19LKoAf1yMI/K/1l112Wdd+5JFHBo/vY/PvgbT8Xjl06NDgOHx/n2ff98iRI107RU2kaBE/b7+PHhnjkQh+bo+U8M/9Hk/fTd+m/11LfP+VUkK2+iKx/hzeWw5u7cECwDmKZzGAzWwtEQcPSbrKfr5y6TMAwOzwLAaAjcVzGMCWt5YXB5+S9NJSyrWllG2SflDSh9enWwCARjyLAWBj8RwGsOWtOlWh1vpsKeW/k/RRSedL+g+11jvG9jnvvPO6hf988TdfDDCF47v+Ankecu0Lu/n+viBiShFoqeKQVp8fk0Lc/XOfAw8BT31K/R6TFgT0tlcF8M9TGHzL9fJw+rS44dj+LWkZKfUiLRDpFRLGFkdM+3jbeTi+h/Z7Cs1TTz3VtX2RwFR5QVo+b/7dSdVJUnqIpyp86UtfGtzXF2/0flx66aXLtvPv2oMPPti1jx07NnhuT+NoSatoSSPqz1NKOfD7Zmibc6Gyw2qt5lkMAFg/PIcBzIM1rXFQa/0jSX+0Tn0BAKwCz2IA2Fg8hwFsdWtJVQAAAAAAAFvcWa+q4J577jmdOHFC0vLQ/BRu7SHFHqp93XXXLdvOV3T37Z5++umu/eSTTw6eI63Y37KSf2vVAt/fUwx83F6FoSUFIq3q731q7Z/zEPdUPSGlG7SkTKQ0gP450uep3z5n3r+WCgv9fvu4vZ32Sav/Hz9+vGvfe++9Xfv666/v2vfdd1/Xfuih59dR8vSOoZ9T34ekNA5PjfB58jSMF77whfG4jz76aNeefK/7fTp69GjX9hQG75OnJ6Rr5+2UQtP/eayaR3+brV5VAQAAAFgLIg4AAAAAAEDEiwMAAAAAABDNNFVBej6UOK1q76HGHrZ8+eWXd+1rrrlm2TFPnz7dtb0qwGc+85nBY6UQ6LRae0oLaF2J3bfzcXsYvIe4t6QReIWEVKmhn1Lg+6T+pXlKIeCpf76vp6X0Q8u9QkCqPrFSmHn/uKsNVx/azq+Lb5cqc/i96O00x+l+8DSCvpb0hDQH/nm6h/bt2zfYp366j8+Tf+/8mvo+Pmd+f/gcp+9BSjnp39MtVU+GUl82c1UFAAAA4Gwj4gAAAAAAAES8OAAAAAAAANFMUxXOO++8rpJACrf20OPdu3d37a//+q/v2keOHFm2j1dVuO2227q2h4qnlfJTSHzLCv+t0jlSKkDa10POW8L6++HXHiKf9k/h6x5Cnla4T/12HtLe386vawrnT+NLaRhpXr1KwVjof6o84OH4e/fuHey3V83YtWtX1/7CF77QtR9//PGu7fdrfzzpeqUUiJbUklQZIqUzjKV0+Nx4SoKnKrT0o2VsYxVP0phaKnMAAAAAGEbEAQAAAAAAiHhxAAAAAAAAopmmKpRSujSBFLbsrr766q598uTJrn3gwIFl2915551d+4knnujaHrbs6QmuJT3BeUh2SiPoSyv7p2O1pC34cTycfGxVeU838HDyNG4/bkrvcKlaRUqxkJanLlx44YVd20PcPS3Ax+B98nF7GkJKYfDQ9/694X3yefJjHTt2rGsfPHiwa3t6jfvSl77UtR944IGu7akQY2kBSQrBT5+33EOPPvpo1/bvWn9sPm++/+HDh7u2p1+4VAXD59uvo1+TsXuxJaVj2u88AAAAMO+IOAAAAAAAABEvDgAAAAAAQMSLAwAAAAAAEM10jQPp+XzmVPLNy9bt37+/a3uO80MPPbTsmIcOHeraXrovlXlL6wz452ldgqSfa53Ol3K7U951WrPA+9cyTinPTVoTwM/huefOt0lrHKRSff39d+zY0bX92vv19f19ex9bf22HIT7mfh6+34N+XJfWWvD79OjRo13b8/7Tugnpmval9Q/Suga+nkO695339XOf+1zX9jUopOXz5Px6eV+9PGUq7+l9TaVB03e2v53z+fRzAAAAAFgZEQcAAAAAACDixQEAAAAAAIhmnqowCV32EGYPHfZwaA9n9vJ399133+AxpVyiL4X/+7lT+bbVSOkNLWXyUih2yzFTOkOfz5PPQUo98LBxb/u5PUw/9akf+u/nSykrqUyjlzJMqQop/cTTHDxtoX8OL0Ho7XS9fA5S2o2nKvh18PH0r11KN0ha7jNvez9S2c6nn3562Tm8RGo6t6cnuJSekEqoppSO/v3k+6Rrv9bvNgAAADBviDgAAAAAAAARLw4AAAAAAEA081SFoTDhlDrgq7M//PDDXdvDlqXl4cotof2uJS0ghX2PpQK4VPUghU+n9AmXQuXTSvT93zkPkfdtvN/eVw/t97lPKQyuv5J/mg/f30P+PTw+hbgn6Tp6aL60PDzf2wcPHhw8rvfJ++ph85dffvlgXz0tIh2zVcu94rwfnrqRUnz6949Xo/BzpEogfr3S+Hz7lpSC/ncwXeOWZwEAAACAYUQcAAAAAACAiBcHAAAAAAAgmnmqwhAPdz9+/HjX9lBoD5P2EHAprxSfKgS4lnD3FIY9Fv6cqkb0+77SvqkfqU9j6RMpdNtD9dP8eci+pyq0hLWnVI2x/qUwem/7veJz3F9pf6Jl7qXl8+Hj2Lt3b9f2tAXv61NPPdW103xfcsklXTtVjDh69OiyPnlFA78WKaUmVSfwuUkVIHz7EydOdG3/Pvb74e2URpN4n6ZNBepfU78PnN+zQyk1aT8AAAAARBwAAAAAAIARvDgAAAAAAADRTFMVaq1xZf+JltX7W1Zb72+XUhJaQqNbKh700xxaUxpWOl/63EO0/fipSkSfjzUdy8PPE98mHbM1RSBVVfAx7dmzZ8XjrCZNwqW+HzhwoGvv27eva3uFgIWFha7tc+N9StfI7/Hdu3cv65OnEngVjH76wFC//biehuHtnTt3dm2fM0+l6F9HTxVxKa3F59/Pl1I6WipljG3j91NKe5psQ9UFAAAAICPiAAAAAAAARLw4AAAAAAAA0cyrKkxCgltCyD2keyz0339uqTawlu1TSPPYCvAtIdepT6mdVqsfWjF+6HcupV84DzlPY/VtDh8+3LU9TNxX8u//nI7r8+fh9R6Cn65LmtfW0HSfZz+fV09I1R18Ply694dC6Id+5/3w9AHfx9vpmvo2nmLhY/bjezUIaXnqhld98Pk4duzY4PlarktLqtEY3yedGwAAAMDKiDgAAAAAAAARLw4AAAAAAEA081SFCQ+HTuH4KaS7H3rdkj6Q0hDScdK5Pfx5LOTZf5fCxlNYtm+f0jWmTb3oS2kLaf+VqmH0903j789ZGqtLFRY8ZN/TIVJofko56W/vY/VUCt/HUxU8zD9pSc3xbfrXLqU0pHn2FINUxSFVekjX0edbknbs2DF4Pt/O+3TixInBz6edG9e/n6Z9fkz63VpxAwAAAJhHRBwAAAAAAICIFwcAAAAAACCaearCJHw4hRG3hKuPhRW3huoPHTd9no7Tmj6RzuFpDz7uNActUgh4XwqL9/D1tM2pU6e6tlc5cB6u7uPpp4mka5/SG1KfUii/a0198b5724/r6QlePWEtFULG0kFaQvU9XSD1o6XCQktbWj5uP/eePXu6tt/jnk7SUqWjhR+/z8+Rttu5c6ckUhUAAACAMUQcAAAAAACAiBcHAAAAAAAgmmmqQillWUjzREpDSNUM+qH8LeHXLdunPrVUP+gbC89f6Rw+1pRGkELffX774dkeut0y515R4MILLxzsh5+jJcR97969y/rkfU9jSudrSU9IVQf8XP19/dy7d+/u2inUftr7o6Uyx1hVhWmraExbsSPdZ/37yfdJ30+/h1J1h5ZrlL4T/TH7dn6NnKef7Nu372vOBQAAAGA5Ig4AAAAAAEDEiwMAAAAAABDNvKrCJCw5hcdPW21Bmj4lIYWHp36ksOq0jZTD0VM4uYdVeyh1CktPq/Gn9I6+llX63a5duwbP4eH7Xm0hhfX7cfp9TCHrLeH8nqLRkjowdm95nzzU/syZM4Pn8O1bwvxbqzu0aKmekMbtfR1KIerv2w/9TxU1fB/fxtt+f6RqEOn+HUsRSqkKfg5PP5l811oqsAAAAADzin8tAwAAAACAiBcHAAAAAAAgmnmqwlDKQQqTdin8fOx3KbQ/VTxoWem9NbR8LI1hpe1Tv10K1059lZbPc0pvSDzMPIV1+/E93SJVWJDa5iZVbpg2dcP7nVbv7+/jv2u5T52nNvi5fS5bqyq09M/HNJamMiTNa0qh6W+XjpW+mym1xPvdsk2fp0Ckud25c2fXppoCAAAAsDIiDgAAAAAAQMSLAwAAAAAAEJ1zVRVaQofHVlVPIdctq/Sn0Ou0Or5rDS33fnhIfTpuPzx8peOnlAcph7W7lnSNlvD9lNrQ75OPz+cgVSFIx0rzNG0qRP+4Y/fa0PbpfGnu073fP066N1Mah0tpOi6ld/i89u/xlmuUUgf8fC7NQZqnfqWH9D1K9+xqKlkAAAAA84aIAwAAAAAAEPHiAAAAAAAARLw4AAAAAAAA0czXOJhIefkpx34sF7mlRGJLjnmL1pJ8Kd+8Jac9rceQ5ql1jYi0Xco3d96nlM/u6xr4PPm+vs1Yf1vmI5n2mo4d0+dm165dg/ukEoIt6w+0XgffLq2nkcbtn7eU4Uxz319PIN2bqezltKUn0xoKY+U90/nSugYt9xMAAAAw71aMOCilXFVKubmU8sVSyh2llJ9Y+vxgKeVjpZQvL/3/gbPfXQCYPzyHAWDj8SwGMM9aUhWelfQva61fJ+mbJP3TUsrXSfoZSR+vtb5U0seXfgYArD+ewwCw8XgWA5hbK8bd11ofkfTIUvtYKeVOSVdIerukNy1t9j5Jn5D00ysdbxImnEreeUh2CinuhxenUOcUHp7CntP5Wj5vDY9vOV8KWfdw6zSGM2fOdO1+icJUls8/93D0adMF/HxpPGPlDVM4firTmNInWq77WIi6/+748eNd+8CB5/+AkFISvO3z0ZK6Mpaa48dN34VUqjKF/KdjtqYFuJZUhdSP1Nex8pQT/fSJ1I+1pL6cC9b7OQwAmB7PYgDzbKrFEUsp10h6laRbJF269ACVpEclXRr2eVcp5dOllE/7f4QBAKa31ufwMzo9m44CwBbGsxjAvGl+cVBK2SPp9yT981rrUf9dXfyz3eCf7mqt76m13lRrvWnPnj1r6iwAzLP1eA5foO0z6CkAbF08iwHMo6YSAaWUC7T4gHx/rfX3lz5+rJRyWa31kVLKZZIOtRxrEiacwu5bwrD7qQktlRhSSHhKc0jHbwmfHtvfpRSNtI2H/Ht1gpa0hf45PIx+2jlIx0yVK1pTBFqqAiQtKS4tKQzS8vD3U6dOde0Uau/3sl8j3z6NIW0zdk38d34+73fLve9StZCxVIWUFpP6l1JW/F5OaR9pPvr99nOk79Tp06e/ZpvNkLKwns9hAMDq8CwGMK9aqioUSe+VdGet9d/brz4s6R1L7XdI+tD6dw8AwHMYADYez2IA86wl4uD1kv4rSbeXUm5b+uznJP2ipN8ppbxT0v2SfuCs9BAAwHMYADYez2IAc6ulqsInJaVY8bdMe8KVwuJTSPfYSuit1ReG+tCyKn1LmH4/jHu9VvlPK863hIn3Q7VTpYOWsPaUApLmrCWUX1oeXp/C130cvn06d0u1i7EQfD/fwsJC1z527FjX9jGlShQt6Sfp/hurHJIqD6Sxpuue7tE0hv53d+z+n/C0gHSPt6QkpPP2qyq0fJ99n8n1HasYcS5Y7+cwAGB6PIsBzLOpqioAAAAAAID5wosDAAAAAAAQNVVVWC+llC5kuCUtIIXH90OeW6ovtIQip3DtaVfpb91/2m287eHdztMWxlI60lhTOHlLZYjVVFJwKRWjpSJBy5y1Vhrw33mo/dGjz1dc2rt3b9dOqRjpvkwpDGNSaonzc3i//Z5Ix0x9SlUO+udLx/X0jpYqIi0pQunel6QdO3Z0bU93SffE5D7bDFUVAAAAgI1CxAEAAAAAAIh4cQAAAAAAAKKZpiq4lKrg0udjod4pdL4lTH/a1fhbVoDvHyuFWU9b0SFtk1bcX81xXcuc+blbKi9Ibav8p36nvrqWe6s/Fz4O78fx48e79v79+weP25KGkFJcWtMnUoWFfoWBiX4li6FztFQg6d/vKf3C0yS8KoX3I6XUtKaTTHhqQl+6H72vk3bLvQQAAADMKyIOAAAAAABAxIsDAAAAAAAQzTxVYRLenKoTtIQt90O9fR8PQ572HC1SWkA/lDqlMaRQ9pbUgZYwbg9XH6v64JUAWlMuho7rx3EpPH5Myyr/adyp6kBLlYj++NP4vNLDqVOnurav3p+qELSkBYylyrSMNaWEpPtg2nuxn2aT0gS8kkLqX0sVg5TW4/0eu3fTfA6lWJCqAAAAAGREHAAAAAAAgIgXBwAAAAAAIJppqkIppQsNbgmPT6HN04bW9/cZC+EfsprQcpcqMawlPDpVT0ipFGO/a6no4G1fET9J+/bHnFbtT5UN3MmTJ7v2kSNHuvb27du7tqcRtKQtSMvTE1LKxZNPPtm1r7jiisF9nY/bj9naJ09BSXPm526p3JDC99P2PpfS8vvu6aef7tpHjx7t2uk+cy3fx9b7qeW7tprnBwAAADDP+Bc0AAAAAACIeHEAAAAAAACimVdVmGgJ0W5pS23h9SktoGWbtPq8h2G3ph20rBTfMoaWVfNb++Tn8MoBCwsLXfv06dNd21MB9u3b17U9hSGFg4+lT6Tr6H06ceJE1z5+/HjXTikF6fhrTRnxPh0+fLhrHzx4sGu3pDykUP7+PZ7uwZZj+XVJofxJSr2QlqckPPbYY13b0yq836l/3vb7zK+L98NTJsYqrPj+LfMHAAAAYBgRBwAAAAAAIOLFAQAAAAAAiDYsVaEldaAltLm/T0tof0ufWvo3piVEPlUOSBUkUv/G0jha+uSfe0j47t27u7aHens4uVcX2LlzZ9f2dIbWMHGfA6+Y4G0/t/PxeKh8Cpv38P2xSg++T6rM4f3z+du7d++Kx/QUhnRv9M+Xrl26Z1PIf8v23idPE5GWX3u/Lim9IaXjpHvf5yZVxxhL6WgZX+v3GQAAAJhnRBwAAAAAAICIFwcAAAAAACDaNFUVxrSkArSEy6cV51PqQFoxvi+lG0ybtpCOuZp5aknp8PF5GoKHjXs4uVca8ND1sfH473wOPMUgrf7fUlnCj+l9HauI4efzlIsdO3YMbuPn9koD/vn+/fsHz5fu0f6YUwh+qtbg27fc+34+n/unn366a3sVC2n5+PyeaEnzSfPnPJ2kpepI/7gt9zupCgAAAMDKiDgAAAAAAAARLw4AAAAAAEA001SFWmsXGtxSdcClz/vHSvu0VF5IWkLix86dPk/tltXgvR9pxf1+X9dSNSKFvnu/PbTcUxU8hcHb0vJQ+zS3ni6Q5tXP7RYWFrq2h+B7aH2/CkCqyuDnaKlOcOzYsa7t4zxw4MBgP1rTTzy9Yaw6xFBf/dr52Lxigvfbr1drWkBLKkD63PvakjrUH/NavjsAAAAAhhFxAAAAAAAAIl4cAAAAAACAiBcHAAAAAAAgmukaB6WULtc45aqnfP3Wcof98020lF1r2T6txzC2nkAak+ebe656Ko3Xsi7E2JoNaT69nY6VxpByz31dAm/3SwN6ib+WfHMvidiy9sGuXbu69qlTpwbP1d/Xr4Xn+Ps6Bak8YrpvfK0FP6b3b+/evV3bx9k/R8rRT9+RkydPdm1fy8Dvrf7aExNjpRxTmc2W9TPSPedrHHj/kv650voPaZ+WUpUAAADAvCPiAAAAAAAARLw4AAAAAAAA0czLMU5CiT1suaWs21iZwRTi3lKaLUlpCCk0fKxcZAqLbxlrGncqL+n6ZQZdCtf2Y6X0hHQc39eP6cfZvXt37OPRo0e7tofO+zYewj8250Pb7Nmzp2t7GLynIEjLx+TlEtM+af5a0nE8VcPTCPrXLl3LlHKSrl26Xv05WGl7KYf5t6T5+FymdJKW69vvd5qPlC4zlgIFAAAAYBERBwAAAAAAIOLFAQAAAAAAiGaaqiA9H8acwrtbQvPHUg1aQu1bQqBT+kPatx+e7funsH0Px/eQ+BQq72HZHuqdwsnHqhSk+Uxh3Ola+PZpnGNVH3bu3Dl4XA/bT+kJLfdEul6+4v7Yyvxpbv3aeRi8pxSkdJIU4u/X10P2+/ukChxePSFVtXAphSRV8ujP5bTfT58zn2P/3M/t/U4VGfqpCqk6RBrrZF5b0pcAAACAeUXEAQAAAAAAiHhxAAAAAAAAopmnKkykMO5pUwT6+6cUiJYqBOmYq5H6m0LfT58+3bU9PaElFSCtDN8Pv05jSiHnzkPw0zVKIfgtfZWWpyS4looTLfdAy/b9nz103sfhn7dU10gpFil1ZazSg4fwp/louf9SWoXzPvWve0pxSfPkY/J9PS2j5Xp5278r0vIx+XXxz31Mk36v9fsOAAAAbGVEHAAAAAAAgIgXBwAAAAAAINqwVIUUut2iv30K/U7HbVmZP32ethnrY0s//Lge3t1SASL1qZ8WMO04fC5TlYQ096k6w1jfUzWJtIp+mr9UTSMZm2Pvh4e7pxSG1I8Upu/nTu2+dI1TWks6t/Pt0zg9nUZaXhEjpQgsLCwMni/dfz5u71O61v1UhZQu4+Pw1IjJmMYqkAAAAADzjogDAAAAAAAQ8eIAAAAAAABEM09VmIQcT5ueMBZ+3hKO3pLOkMKh07laQ+JT2HlLmkRacT7tm47f70dKH0jzka6Xf96vBNBy3mlTOlpSSJJpUxjGzuch8iklwdspjcClygT9fhw7dqxrX3DBBV3bq1KktJEkXQdPQfDUhP5x0z5pntP952NoqZDS/261XC/f5sSJE5JIVQAAAADGEHEAAAAAAAAiXhwAAAAAAIBo5qkKkzDhllSFFIo+lqqQwtFbVnFvOeZqQppbUhI8dDv1qSXUfiy9IIWvp2vREs6f5inph8233Adpnrzt4fEpLSXNaz/FYtrqE6kagvfpzJkzg8fxbVz6vN9fr3TgaQsemu99Smk6ac58jvvX18+XzuGpB17ZwKstbN++ffCY3iff18fvn0vS7t27B4/rffK5maRftFQvAQAAAOYV/1oGAAAAAAARLw4AAAAAAEC0YVUVWlIE3Njq+y2pAEkK/2+pIjC2fUtqxLRz4J+nlISWNAypLWTdpZXy0/bp+H0tVRKmTSdxLSHoYyvzp+1aKnN4SLz31Stl+PYeWj9WCcHD873t5/AUg5bvQaoo4qkQ3pZyOkVKu/HtPYUhzVNLlQ5PeZCWz5unPTifj0k/SFUAAAAAMv61DAAAAAAAIl4cAAAAAACAaOapChNptfuWsOpWKYS8pVqAmzasv3+OlrQFD+NO8+Eh4B7G7dt7qHZ/nKk6xLTpIWlsKbx+bJ7SdUmpB+nc6X5K42wZf7/vq6moMdQnD9NPqSut95bztAU/x7SpPKmqQp+nLvj9622/J1IFiJRike5x718/XcJ/9v3TtV/P5w0wSx99+LbBz7/z8lfOtB8AAGA+EHEAAAAAAACi5hcHpZTzSymfLaX8wdLP15ZSbiml3F1K+e1SyraVjgEAWD2ewwCw8XgWA5hH06Qq/ISkOyXtXfr5lyT9Sq31A6WUX5f0Tkm/ttJBhkKDpw0Xbt1+2rD2dI60wv9Y2HdLSkNKMXB+Dg9F93097HssJSOF3ad0iBQ6P201iBRyLi1fUd/PcebMmcFj+f7e1zQen9fW+6ZlrCnVoWXOUr+93b8fWtINPBXAt0lznMbj12sspcN/59fL+54qQHhKgd+/fm7f3o19b3wO0twOfQ/WkoYyY+vyHMbW5SkMpC0AZw3PYgBzpynioJRypaS/I+k3ln4ukt4s6YNLm7xP0t89C/0DAIjnMACcC3gWA5hXrakK75b0U5Imf5a7SNKRWuvkz4MPSrpiaMdSyrtKKZ8upXz6+PHja+krAMyzd2sdnsPP6PTQJgCANu8Wz2IAc2jFVIVSytskHaq13lpKedO0J6i1vkfSeyTpmmuuqSuFi6dw95YV95fON/h5y+r60/KQ836/W6oqeHj3WJj60DZp5foU0t7n+6TV511a1b4lFWAspcPPnbSkWLSkkKRrneZ7rB/p+qZUBW/7tUv3UL+v6Rzbt2/v2j6Xfr6W6gIp7WCswkKqCOHn89QB/9zbPv+etpAqMvgY+lUVnKc6rFQZ5VyvrrCez+G95eC5PVisG9IWgPXFsxjAPGtZ4+D1kr6vlPI9knZoMZ/rVyXtL6W8YOkN65WSHjp73QSAucZzGAA2Hs9iAHNrxVSFWuvP1lqvrLVeI+kHJf1JrfWHJd0s6fuXNnuHpA+dtV4CwBzjOQwAG49nMYB5Nk1Vhb6flvSBUsr/JOmzkt67Hh1KIcNjocQpvL4l/HgsjH7o85ZUirFjtVR6SO0Urp6O3+9DCjtPYdx+LN/ew8PTeFrTBVI4f9rfw9f7ofMr8X3THPfPndIbWu65VL0jjWdMy/VuqQCRUhhSysjYtUtpKp7q4Ndo586dg+dwXgHCeQrDWIrQtNUuJtunudsEzspzGOc+Tz3wlAQAG4JnMYAtb6oXB7XWT0j6xFL7HkmvXf8uAQASnsMAsPF4FgOYN5v2z2wAAAAAAODs48UBAAAAAACI1rLGwbppyXMfK/uX8ppTnnzLmgUt24zlRaec6pQ/n/qaxuOl5lpyufvna1n/wXPJUzlGz433PPSktZRmGneLVKYxnbu/VkK671qkOUumHdvY/n4+78e093Ja76B/fdP4UqnFPXv2DPajZS2IlvP2f9dSonPSv7VeB+BcR2lGAACwFkQcAAAAAACAiBcHAAAAAAAgmnmqwiRMOJWkaynJ1xru3nKstO+0JR7727eWbRySwrW9nUoRjpXn8xDydNyWtI8kXZexNJMUFp/CzFtC81tSVHxfLy/Z3y6VoWwJr2+5n9J8t/L+eRlEP6732/u6ffv2rr2wsNC1/Zr48fulElvmyffpz/NKY2iZ1/493vLdTtcO2KwozQgAAM42/tUMAAAAAAAiXhwAAAAAAIBopqkKtdYuTDiFlns7rVA/Fp68ljSEtL2bNoVByivze8j0tCHrKfw/HXPo56HzjaUVrPR5yzb9azfttWhJW2hJaxm7Z1qOO22/W/oxlk7jv/NUAq+ukb4vni6Qwvy9YsKpU6cG+9pPj/GffX8/X6pq0VLhw8eZUgr6fWpJPWip3ABsZf10BqosAACAlRBxAAAAAAAAIl4cAAAAAACAaOZVFSbGVv8f+rwlHaH/u5Zw8tSPscoNK/Wv/3NaxT2t0p8qJiStFRw8DcHP4ef2bVrmwMPJfd8Udp/SNqTlIfIpNSX1qSVVoTUtYC2VJdL2Lfe7G0sL8Dn346ZKCmNzPuGpBi1j6O+T0hOcp1W4lrQF52Prz1NLVYu1VrLA5pcqDxCyDwAAMIyIAwAAAAAAEPHiAAAAAAAARBuWqpBC81vDpKeVQtPXErY8FsqfVrhvCdtPKQWuJTR/bDwpJWHaVeZ9+2nTFqTlYece7p6qBfixfN+W1BCXUjX6+6QQd9cy1pZQed++f91ThYHTp0937TNnzgz2KRk739A2npogSdu3b+/a6bua7qdp00Fa+tqXrv3QtaC6wnzxlARPW/D2Zk1bSGMbsxXGDQAAzi4iDgAAAAAAQMSLAwAAAAAAEM00VaGU0oUPe7hwS1j12Gr/LRUX0ud+3NbKDS3btIwphZ+7taRo9PdNId7pHD6GlkoALlVq6PM59NQDl1bj9/mbth9jY0vXNc1TS+pBSp/wMXjb0w76+zvfx8/nc+bpDCm9w7dJVRs8NaEvfXemrVSSjpk+71+Tlu/tULoL1RXm12YKzW9NPVivc2ymuQEAAGcXEQcAAAAAACDixQEAAAAAAIhmmqpQa+3CldMq8yl1YGwl9bHQ5SEtVQRaVncfO1dLyPRaQrfTvmMpBalagH+etmmZD+fXy9v9dIQ0Dj+fr+Y/bcpEMhZC7z+3pAikOUsVJ/xzT0nwdIH+/e5pAinlIlUqOXHiRNf2ufRtUv/8vP25959bqjK0XLuU0tH6PW1JFRn6DlNVAeeSWaQkAAAATIOIAwAAAAAAEPHiAAAAAAAARDNNVTjvvPO0bds2SXk1+RQev56hxCkEOoVSt4TT9027uvu0FR1aztXvXwqpb5EqB6QxpFSAsfSMaVMjPEy/pR9+n431I6VupG1S+opXNlhYWIjnW+mYY6at3pFSCtLnntrQ11L1oOXebLnurc+FluopQ2lSVFXARjsX0xOosAAAACaIOAAAAAAAABEvDgAAAAAAQDTTVIVt27bp6quvliQdPny4+/zpp5/u2h4ynSosrMa0KQl+7hRCPlZhoSUNIW3TErrdkj7R3yYdN81Hy5y3hKK3Xke/9utV7SKt0j92zLQaf8ux3M6dO7u2V5NIKRNjlR5aKhi4lNKRxuPbeF/H+tSSVpC+O6nKQUvqxVgqREvVk5R2A2A50hMAAMAEEQcAAAAAACDixQEAAAAAAIhmmqrw3HPP6cSJE5KkK6+8svv81KlTg+20uv1YyHQK6U7h6yl8P+2b0gvG+jRtRYKWcPx0rrFQ79TfNLfpWKkfKfw8fT7Gw/md98lX/G+pSJDG3N++pfrEtOku3j5z5kzX9soLrt+ndFz/fFKxpL/N9u3bB89x8uTJwc/T96l/j097z7akC7VsP1ZVoSVFaDXVK4Cz4WxXUiDVAAAArBciDgAAAAAAQMSLAwAAAAAAEM00VeGrX/2qjhw5Iml5WPVll13Wte+9995l20+MrX4+bUhySzhzS7j7WGWCaas4JNNWZBhLC/Dw9WlD8NM5PKXA2y3zN/TzhKch+LFOnz49uH0Kx3ctlRBapX6nChLpurRW6XC+nVdA8H38c59L74d/7nxfP1c/rWLa+zel6bRUWGidGzdtBQ5gMyENAQAAzBIRBwAAAAAAIOLFAQAAAAAAiGaaqlBK0Y4dOyRJhw4d6j5/8Ytf3LV3797dtScVGKTlaQv91f5TWHzLiukpZDodJ4Vb97VUUkipDi39bk0FSPuktAWfZ+dpCKk6wdhq90Pn7W/n55jcJ2PH9eoEqbrAWDpJkq53Cp13af5cShfwz/tpASkNwceU0kZaUnZaQvb727SktSTTVmRouUf7+7RUBWlJtwDOFaQnAACAjULEAQAAAAAAiHhxAAAAAAAAIl4cAAAAAACAaKZrHJx//vnau3evJOnJJ5/sPvf1Di688MKuffLkya49tsZBS651Sz73tDnfad/V7O99TWUoW/o9pmVNBf/c+5G2Sbn3biyPPK0xsbCw0LW91KKfO5WFTOUK/fNUirB/jmmlNQda+jRWSnOsvxMpp9/XS0jfiZZykX3pflrNsYa0rFcw1qf0zJi2H8BGYl0DAABwLiDiAAAAAAAARLw4AAAAAAAA0UxTFc4777yuzN6uXbu6z73sopdj9PBiD7fuh76n0PKWMm9JKqfovH/9UOppw8BT2HcqRdhSvrE/Ly3z0RL+33K+NLb+vj5vXoLRSy2m1A2XUjrS3J86dapreyrESv0dOq6P+/Tp04PbeKpBCqf3+e6nfbSkAiTp2rWkLbSey8fRcv+2pBG1XIf+/dBy37UcFzhbPvrwbRvdBQAAgKkRcQAAAAAAACJeHAAAAAAAgGimqQpf/epXdfToUUnLqyc89dRTXdtD1D2E3MO4vS0tD+tOq69PG6rcsrL+WLWAaVdxT6kRrSHaE2P9bqmkkMY07Xhaws+Hfp7wa59SKZx/7mHzKezez+v3nCTt3LlzsB/pHJ720FK5we9fT20Ym6eWdBe/jqk6xrSVOcbup5ZrMW36Skta0Fj6RJqb1KdJChQpCziXUEkBAACca4g4AAAAAAAAES8OAAAAAABANNNUhWeeeUaPP/64JOlFL3pR97lXUvDqCa3hwy0r/rdIYdJpm7GQaR+HmzZlIvUphYn7cVLaxtg+LVUE0nFbKlGM7eNS2L6fu+VaeFpAqmawsLCw7Nz+s6cbtITde9qMt/1+8D75MX1s/RSBFGqf+PjWK02n9bvVkm4w7XHTeMbShXwcPueeWnLy5MmvOT4AAACA5Yg4AAAAAAAAES8OAAAAAABANNNUhVprt4r84cOHu8/379/ftX2VeW+n8O6+lvD8aUPqpw0N7+8zbah4yyrzLWH6/X1bVpxP+6cw/5b5Tiv/98/t0vhSdQffPlUXSPPdr37gaQWpYoKnIaSQeG97v33fdD+03k9urCrDSvu6ftWSdMxpU3tapJSMsZSEtH+qguHtyTmm7Sew3qikAAAAzmVNEQellP2llA+WUu4qpdxZSvnmUsrBUsrHSilfXvr/A2e7swAwr3gOA8DG41kMYF61pir8qqSP1FpfJukVku6U9DOSPl5rfamkjy/9DAA4O3gOA8DG41kMYC6tmKpQStkn6Vsl/SNJqrWekXSmlPJ2SW9a2ux9kj4h6adXOt4kVPro0aPdZ2ll+ZYw9r4UHu7nmDbE2vf1MOfW8OaWdIMUst4SWt46tpa5bUnjSH1dTbh3Sj1wLakiLlVSSMfppyqkygiTFfj7fU1VH7wfKV2jtVpCShU521USxtIfWu7T1L+UfuLbnzlzpmunZ4Rfn76hlATpa693/5jnovV+DmN2PvrwbRvdBQDrhGcxgHnW8l9k10p6XNJvllI+W0r5jVLKbkmX1lofWdrmUUmXnq1OAsCc4zkMABuPZzGAudXy4uAFkl4t6ddqra+SdEK9EKy6+KfEwT85llLeVUr5dCnl08ePH19rfwFgHq3bc/gZnR7aBACwMp7FAOZWS1WFByU9WGu9ZennD2rxIflYKeWyWusjpZTLJB0a2rnW+h5J75Gkq6++uk5Chj1s2dMWWkLXB84x9T5D26eQbg95Xk2fWlISWkLq0zhbUgqk5eNoWaV+2moQLf3u9ylVGPD+pVX+W6pBpDSOtG/ftm3bBo/lfUph9y7NferfWNpH2mfa1IHW+yZpuSda9vW5TNUPUkqCV8CQlqch+D5+LD/fWKrDOWbdnsN7y8HpLhbOGiopAJsOz2IAc2vFiINa66OSHiil3LD00VskfVHShyW9Y+mzd0j60FnpIQDMOZ7DALDxeBYDmGetf277Z5LeX0rZJukeST+ixZcOv1NKeaek+yX9wNnpIgBAPIcB4FzAsxjAXGp6cVBrvU3STQO/esu0J5yENKfQ5n7o8URaiV5ae8h1v2+t+46FZ6f908ryLZUR0r4p/Lw/T/6ztz1c2/vRUjmgJeQ/9VtaHkKejjvt9W2Zj7Hjp+N6/7ztY/D7N6UnpFD51uoRLfdHSplI91yaj7GUlpb0hLS/7+vVE3zOPE0kjaffB59bH5+3N1F6wjLr+RzGxiE9AdjceBYDmFfT1bkDAAAAAABzhRcHAAAAAAAgmmnMbq21CyX21c9TeHxLOH7/Z9/fw55TKkAK124Jux8z7f7rtTp+CseXcnWINE++f9rGw749tNzDz8fmLK2i71pC8FMqRUvVjDEt18KPu3379q7taQsphSGF04/1w8eajpWu9bSVEFq3b01vGOpf2r4lfaefdpCOlb7bk/2nTWsCWpGaAAAAtgIiDgAAAAAAQMSLAwAAAAAAEG1YqoKHk6dw6NbQ8hRCncK4XQptbgnRHtumpTqBW2tqxJCxkPGW8aUV+P3aeXqCb+OpKGNVFVqkdIGW8P2W4/SvSQr5n7a6g8+Bt1PYvKcz9O9X/9krB6RzLywsDO7r1yulArV+B1O6Qcv+PoY0ntbr5Vq+50PttXzPAAAAgK2OiAMAAAAAABDx4gAAAAAAAEQzT1WYhGP7augprH+a4650LA+r9nOvpZrB2OctK9m3hGK3hmhPeBpBPy2gpXpF6yr/K0lh7P0xpNSFltSNNB/TpkOM3XNpDlrmL92Xfv/5PJ0+fXrwmP39/XdexcHP5+H//coDQ1J6hx+nPxfpXvN2Skk4depU1/YUDT+mp3ek50VrNYSWqhsAAAAAhhFxAAAAAAAAIl4cAAAAAACAaKapCqWULszYw5NbQqnHtITUpwoLKWx52jD9sZDnadMTpq280JpukVa+bzlHCs33z30ux0LcXUv6REto+bQVD8ak1IM07nQOv69Tv1No/rFjx5Zt5/Pp+6QQ/pRGkI7Top8+kVJQvJ3O7d9Hn5szZ84MHsft3LkzbjOL+wMAAACYN0QcAAAAAACAiBcHAAAAAAAg4sUBAAAAAACIZrrGwXPPPaeFhQVJ0rZt27rPPbfb2ylv2kvQ9Y+VSr6lUnWupZSeG9smlaebtvRkylVvWRtgrPShHzflpLesnZDKLqY8/H6fPKfdpbUFWvo07foUrWUr07l9f78XW/qdrulYH327tHZHKtOY1l1I/Ru7X6ctD+p9SiUp0/0weW5Iy7+//WeBPz/SPe4mn7PWAQAAAJARcQAAAAAAACJeHAAAAAAAgGimqQqnT5/WPffcI0m64YYbus89PDmFF/vnO3bsiOdI5e28/GNKW0jh9a4f1j7UV2l5iHcKg/ZtUph6Gk/qk49nLAS/tYTj0PYtpe3S2Prj9PH5fZBC89M5pi2VOJbakH6XUg9S6kBLP3z706dPD27T3z8dN91Dfu/7OfxeScdMaUT9n1NqTioXmVIV/JipNKP39ejRo7FPfg5/Zgw9Y1rShgAAAIB5RcQBAAAAAACIeHEAAAAAAACimaYqLCws6Pbbb5ckXXXVVd3ne/bs6doetjztyut9Ht6cjuXSCvVrCfHv/64ltDztm46TxjMWgt+SCpD2TWkLq0lzSNclpQgkaXsPS3cptWGsvy19SnPQUonC9a9d6pPvf+zYsa79wAMPdO2TJ092bU9P8DB/39fPfckll3Tt66+/flmf/HdjfR/qt2up9OBz5mPon8vTMo4fP961vcKKV2iYVGUYSxMBAAAA5h0RBwAAAAAAIOLFAQAAAAAAiGaaqnDmzJkuhPpLX/pS9/krX/nKZdtMeJi5hyT3w4o91DlVZUjh+Cls3MOhU4WFsRD8sVD4lT73vno/Uqh3Wu0/bd8/x9h2K/U1beN9SpUGpDy+lvSOlMaR0gJSiH8/XcDvoXR/pHD8dN1TGobbtm3b4Of9Y41VhJjw79Fjjz3WtR988MGu/eijj3ZtT2fwvnqfrrjiimXneM1rXtO1PY3h4MGDXdvnw9MIUuUGH09KM0nPiP457r777q79qU99qms/9dRTX7P/4cOHB88FAAAAgIgDAAAAAAAwghcHAAAAAAAgmmmqQimlC0W+6667us9f/OIXd+2LL764a6cwcw9HHtNSDSGlNvi5vZ2274e7t4T/p/3TuKdNF+hv7/ORVrJP525JgfDPPQVhNdUnpt2mpRpE2n6sgkFL6kGq+OH3qZ9j586dXdvD9P1c/bQFP7fPrfPjXnvttV3bqwt8/vOf79peScH76v3w8Xh6kSQ99NBDXfuGG27o2jfddFPX3r9//+AY/HueUpLS99fnxscmSU888UTX/tznPjfYVx/rpE9pTgEAAAAQcQAAAAAAAEbw4gAAAAAAAEQzTVV47rnnutXbjxw50n1+++23d+03vvGNXbtfPWGiX+UgrVifVuBPYe0eMp0qBKSQ/X5IfPpdSz+mTU9olVIxPEzb56CffrFSn9LcpOP0t0vnaJmPlHqwmmuX0hM8xD2Ftqc0mu3btw/2r6XyhyTt2LFj8NxprH5977nnnq599OjRwW2SsTQTT3W47bbbBs936aWXdu3LL7+8a3/bt31b1/axpeuV0ov6KR3ep6effnpw/7H7EQAAAMDXIuIAAAAAAABEvDgAAAAAAADRTFMVaq1dmPDCwkL3+R133NG1r7rqqq593XXXdW0PAe+nKqTV7j2MO4Xgp5B439ePmVbK76/Mn0KrWyoMTJvC0JIWIeUQ7ZTCMG34f0tf+9Lvpk3RaKli0XKt+z/7WE+dOtW1U6WNVCHAUxVa7r/+eFrSLLxPXl3Av2te8cArDdx///1de6jqwFCfnKdPPPnkk13bqx54etKVV17Ztb0CxO7du7u2V4lI5+4/C9J3zedmPdN/AAAAgHlAxAEAAAAAAIh4cQAAAAAAAKKZpypMKiX4SuoeRvz5z3++a7/whS/s2nv37u3aZ86cWXZcD1duCf1uCVX27f34HsbtVR88FL2vZRX3lioEa622cDZSI1xKYeinAqQ+eTvtM21VipSiklIyxs7tK/j7Pn5P+Od+T6Q+pWvS70NLtYGUYuHVDL75m7+5a3s6w/vf//6u7dUIVnPP+Xb+XX388ce79kc/+tGu/fKXv3ywf/6McD7OfqqCPyf8eq1UIYT0BQAAACAj4gAAAAAAAES8OAAAAAAAANHMUxUmIeIeDr1r166u/eijj3btW2+9tWu/4Q1v6NpjoeWpGkJa+b7fv6Fz+DH9c09V6PfpggsuGNw/na8lnaElTH9sm5ZKDC3h/+mYLeMcs5YUiGkrQ4xVn/D9/dy+v4fBu1R1o6Xqg+v3qaXChd/XXrXAtzlw4MDg+TwtwKsipO/KWH/TveVz89hjjw1uf/DgwcF9L7744q6dUkAkaf/+/V3bnysAAAAAVo+IAwAAAAAAEPHiAAAAAAAARDNNVZCeD5v2MGQPDffw/y9+8Ytd+5JLLunaN95447Jj+srtacX6tPJ9Cl9PfBV3DwH3fvfP0RLunVb/T2HfLSkCfSl0PqVMrCW8vrWihf/sc9CSSpHSCFrmzPXH2VLVwtspLaXluqymakFL2sLu3bu79tVXX921fY6PHz/etf07lI7Zt5bUF3fo0KGu/ZnPfKZrX3TRRV3bUxjSd0Vansbg+6zUv2nvdQAAAGCeEHEAAAAAAAAiXhwAAAAAAIBo5qkKQzxMOqUweIUFXzldkq644oqu7SkDvlK8H+vZZ5/t2h5mPm24sqct+PEl6eTJk4PbpfD1FBI+bdh3CuXvHyuF9recYy0pE/1tvI8pVD+lk7SEx6e+jo1zLRUn0v3UkibRmtKRUhXS9v49OHXqVNe+9957u7bfr+k4Y9e3JW0k8Tm7/PLLu/a1117btffs2dN0TE9j8OeEf97/rgIAAAAYR8QBAAAAAACIeHEAAAAAAACimacqDIUZe+rAkSNHuraHJ3t48Sc/+cll+3/Hd3xH1/aV2J2Ha3tYtR+3pfpBy8r60vIxPf3001177969g/u0hNR7v8dWlm+RQsuT1ooEK23T7+u0aRJpm5ZqENOG0EttVRmSdI50nLG0gJTCk86Xzr2wsNC1H3jgga7tVUdS//rXbi2VLPz+9fSEN7zhDV17165dg/umKiD9flx44YWD5xs61rTXFgAAAJgnRBwAAAAAAICIFwcAAAAAACDixQEAAAAAAIhmvsbBJJc45b372gCed+w52Pfdd9+yY/7lX/5l137Tm97UtT3H2cs0btu2bfAc3o9UQjG1+3z9Aj/30aNHu7av4dBSxs/Pl8oYjpXqa8mtT5+3rLWQjOXup/6mNQs8v7+lvGTLPPXH31JGcdrtW9ZU8HuuL60bkNp+Xfw75efYuXPniv1rLRHZ0m+X1mnwvqZ+p/71f/bxpe/qZPtpS7ECW9VHH76ta3/n5a/csH4AAIBzS1PEQSnlJ0spd5RSvlBK+a1Syo5SyrWllFtKKXeXUn67lLJt5SMBAFaD5zAAbDyexQDm1YovDkopV0j6cUk31Vq/XtL5kn5Q0i9J+pVa6/WSnpL0zrPZUQCYVzyHAWDj8SwGMM9aUxVeIGlnKeUZSbskPSLpzZL+4dLv3yfp5yX92mo6kcKhPcTfw/o9bUGS/vqv/7prb9++vWu/8Y1vHDyfh3F728OnW0K3x9ICUurBsWPHuraXady/f//gvuncriWFYexYLSH8LdukuRkLA/f+prKSvn8qQzltOb2xcpRpTC3bTFtSMqW+9OeiJWUlXRe/n/z7cdVVV3VtLxP61FNPrXj8vpZxe7/9u/bggw927Ztvvrlr+/f3uuuuGzzOGH9OpNSITeasPocBifQEoAHPYgBzacV/gddaH5L0y5K+osWH49OSbpV0pNY6SUJ+UNIVQ/uXUt5VSvl0KeXT69NlAJgv6/kcfkanhzYBAKyAZzGAedaSqnBA0tslXSvpckm7JX1X6wlqre+ptd5Ua71p1b0EgDm2ns/hC7R95R0AAF+DZzGAedaSqvBWSffWWh+XpFLK70t6vaT9pZQXLL1hvVLSQ9OcuCX0/eTJk13bQ6a9WoIknTlzpmvffvvtXdurJ3zLt3zL4Pmch3R7mLP3qXV1d9/Of+d9P3HiRNc+cuRI1/aw8VQBYq0r+U9bSWEtFRlaQv9b9/dUhWnTCFxrP/x8ftxU3aGlT4nfx2PVAqatAOBj8EoDL3vZy7r23/zN33Tt2267bfA4/XD/fsrQStI8+XEeeuj5x8hdd93VtS+//PKu3f/+p3N4BZO1VLs4R5yV5zAAYCo8iwHMrZZk4a9I+qZSyq6y+K/st0j6oqSbJX3/0jbvkPShs9NFAJh7PIcBYOPxLAYwt1rWOLhF0gclfUbS7Uv7vEfST0v6F6WUuyVdJOm9Z7GfADC3eA4DwMbjWQxgnjVVVai1/htJ/6b38T2SXrsenWgJ4/Zw5v6K8/6zVyr4zGc+07U95P+1r32+22mF+5ZqCy1h8/3tfKy7d+/u2gsLC13bKy94WLaPwaX5689TSxi9z0FL5QDfJlUqSJUQ+qZNjZg2BWI1aQv+O78PWuap5RypakG/csC0VT5c6t++ffu69jd+4zd2bU+ZuOyyy7r24cOHlx33jjvu6NrHjx8fPHfqhzt48GDXftvb3ta1L7744q7t8+FpQP30iWeffbZrP/LII107zfPk82mrcmyEs/0cBgCsjGcxgHnVVtcMAAAAAADMJV4cAAAAAACAqClVYZZSuLWHJJ8+vbz2ra8U7/t72sItt9zStXfs2NG1X/WqV3XtU6dODR7Tw6Q9FNp5OH5/Hw+D9soNvo9v79UkfGX4PXv2DI7B900h2WP6YfErHdeNhddPpFSI/nFbKjqkdIhk2lSDoZ+HPl9LmkRLCshYmon3PZ3bt0mpNn4v3nDDDV3b731PI+ify4976623Dn6erpHf+54ycfXVVw+e2+csfQcl6amnnuraDz/88GCf3GRMm6i6AgAAADBzRBwAAAAAAICIFwcAAAAAACCaearCJOS4JTQ4hXR7KL+0PKzbKxV4eLKvCP8Xf/EXXdsrFdx4441d29MhfJuWtIW+FKbu4dre9lXjT5w40bV95Xo/ZupfP+R+2lX3W0LzUzuFx/e13ActKQktx2wJ8e9rWW1/2soGrjX1IqV0pHSSseoVQ/t6esKLX/zipv55xY/UvzRunyf/Hvl321MVfBs/V/876OkJXp0EAAAAwOoRcQAAAAAAACJeHAAAAAAAgGjmqQrrsYp5f4V0TyvwagMe/u8h048//njXTmkL119/fdf20GgP6fZj9vuUVsFPq92nVAUPB/cwbq8YsX379q7tqRp+nL6WygEpBL9l3/R5S+h//3wt1R2m1doPN5YGstpztMxrf7u1Hmtoe7///DvkqQBesUCSDh06NHgsr9bg36mUbvDMM88MtlsqSfRTFTwlKVVSmLYiBgAAADDviDgAAAAAAAARLw4AAAAAAEC0YakK04aKj4UXp7BnD7n2UGcP+X/kkUe69p/92Z91bQ/zf8lLXtK1PS3CUwRaKxiksPuUFuDb+/l8nF554cyZM13b0xak5fOxlv65llXzx7SEjXvIecv5UtUB32ZsbC19mrZyQEufWkPofbtU9WDa1BLfN6X4eNqBJF188cVd+6qrrura1113Xdf2lJq77767a/t30NN/9u3bt2Kfxq6d97Gl+gcAAACAlRFxAAAAAAAAIl4cAAAAAACAaOapCqs1FnrtPy8sLAx+7mH+3vYw/4ceeqhre9qChz9feeWVg/3zY0o5vD6FX/vniadP7Nq1q2t76LaP39MWpOWpCt5O4d0tofMtofytYfepakFK3UhSSkLaZixVwbVUdEjb+LWbtqLF2O/8fCl9omVe/XPvq2/jFT4k6c1vfnPXfs1rXtO1X/jCF3bte+65p2ufOnWqa3tFhmuvvbZr7927d8W++vfG29LytKIvfOELXfsrX/lK116vyhwAAADAvCDiAAAAAAAARLw4AAAAAAAA0TmRqjDtCvBj+3uKgIdGe/i1h25727e///77u/af/umfdu1v//Zv79pXX3111/ZqC1KuuOBh0t6+4IILBvvkUpqD7+vH7PfJf/Y++Zz5PCUtK9SvJlWhJR2iJZUiXd8Usj92bz377LPxd0P7p9SBtH1LNY2+lmoXLfOUjpMqNfh9Ji2vqrB///7BY3mFBU9D8GoLF1100eA5Uj/8c0+5kaSXvvSlXfv1r3991z58+HDXPnr0aNeetroLAAAAMI+IOAAAAAAAABEvDgAAAAAAQDTzVIVJyHFLSPdqpBXTPeR89+7dXdvDqr3Cgqct3HvvvYPHfOtb39q1L7vssmW/87QAD//3FIM07rFV4ydSCHlaHb//uxQKP214fQohd2OpCi1aQu1dCnH3+fBt+tUnPHXD2yn8v6XdkiYxlhaQxpE+T/u6ljSRsW1SGojP2c6dO7u2VyR50YteNHg+vxZ+zPQ97Y95z549Xfv666/v2l714ctf/nLXfuKJJ76mzwAAAACWI+IAAAAAAABEvDgAAAAAAADRTFMVzjvvvK7awMmTJ9ftuCm8fqzCwIRXP9i2bVvX9v55+5577unaH/nIR7q2V1uQpGuvvbZre/i1h1b7+byvHjadwsFbVs3vh5anFIiWcHzfPq3Gv5qUhGn3aQmvT+kgKQWhn/LgaS3PPPPM4HYptD31KaVPpLSF/nFa5qmlcki6h9K5xs7r6RQtKTgtKUkp/cS/Q36cfprJk08+Objd6173uq594403du3J9/nmm29esW8AAADAvCLiAAAAAAAARLw4AAAAAAAAES8OAAAAAABANNM1DkopXV6/5yZ7TvlqtOS9p3N4ubhUDs/39fUO7rvvvq79x3/8x8uO+4Y3vKFrv/zlL+/anhu/sLAweL60/kDK805l+Pr8uP1yfxPrVV6xdd2FlpKF02pZZyCVlJSWz00qZejHSmsipD75dfDjp+s7xrfzdTzSWhWpfGNaH2FsLtL1SiUzW8p4pvl2vi5J/x5NY/X1RHbt2tW19+3bJ0m65ZZbVjwvAAAAMK+IOAAAAAAAABEvDgAAAAAAQDTTVAXp+dBiDx1OpfFaS/Wl7VKpO2/7+Xbs2NG1PXT72LFjXdvD0j3V4Ctf+cqyc3/sYx/r2keOHOnar371q7u2h1yfOnVq8Nw+T6nknY9/LG0hhZD7cVukMPi0zWrKNCYtaSlrSXPoHzelGPg8p/KA3vY0glQWMoXZS8tTBlKJyBTm7/eQ33PenrbUZ19LWcn0eUspx1bpu+Bj9TmffD7tdwAAAACYJ0QcAAAAAACAiBcHAAAAAAAgmmmqwnPPPdeFbHtagIdxp1Dl1hDmlrB4D1X2NIQUxt0SEu9h6ZL02GOPde1PfvKTXfuRRx7p2q973eu69hVXXNG1PRTd+5pWu0+h9f3Q9ZSi4dL+LfO/mpSEadMeWvqR0jBaV/L3OW9JufBjpfB4v16e4uLncv3Qef/Z77UU8r979+7Bc7ekJLjWazrt/ZHSFrx/aW7G7nHn1yV9jybXaz3TaQAAAICthogDAAAAAAAQ8eIAAAAAAABEM01VqLV2Yfi+0ru3PYx7NekJaWX6tOq7h317P/yYnlbhx/R9+3316gtPPvlk1/a0jEOHDnXtV77ylV37G77hG7r2nj17Bo/pbQ9F93D1fvh1CttvmecUWj5tGkF/m2lDxFu2T9UjUnpG//O0T8tYUwrJzp07Bz/3+92vaT9MP6VPeDqE36cp1aal0khLGsHYdtOmLaS0kZRako7T/7mlT+m4AAAAAJ5HxAEAAAAAAIh4cQAAAAAAAKKZpipIz4cGe8i+h3H75yk8u6+lEkPLqvEpRN1TGDx8OqUO9M/nx/IqDr6PV1647777uvZNN93UtV/ykpd0bV+9P6VM9EPLPYze9/ftPJ2hZV5bKg2MrXyfTJsakbZJ12iswkSqVNASUt8SHu9z79UP/Phj4f7eJz/WWJrKSv1L4xyTvjvTnnvaagtrrbBCBQUAAABgOkQcAAAAAACAiBcHAAAAAAAgKq1hv+tyslIel3RC0hMzO+m542LN37jnccwS496Mrq61XrLRnZiFpefw/drc12u15nHM0nyOex7HLG3+cc/bs5h/E8+PeRyzxLg3o/gcnumLA0kqpXy61nrTyltuLfM47nkcs8S4N7ofaDOP12sexyzN57jncczS/I57s5rX6zWP457HMUuMe6P7sd5IVQAAAAAAABEvDgAAAAAAQLQRLw7eswHnPBfM47jnccwS48bmMI/Xax7HLM3nuOdxzNL8jnuzmtfrNY/jnscxS4x7S5n5GgcAAAAAAGDzIFUBAAAAAABEvDgAAAAAAADRTF8clFK+q5Ty16WUu0spPzPLc89KKeWqUsrNpZQvllLuKKX8xNLnB0spHyulfHnp/w9sdF/PhlLK+aWUz5ZS/mDp52tLKbcsXfPfLqVs2+g+rqdSyv5SygdLKXeVUu4spXzzPFzrUspPLt3fXyil/FYpZcdWv9ZbxTw8h6X5fhbP23NYms9nMc/hzW0ensXz/ByW5u9ZPI/PYWm+nsUze3FQSjlf0v8u6bslfZ2kHyqlfN2szj9Dz0r6l7XWr5P0TZL+6dI4f0bSx2utL5X08aWft6KfkHSn/fxLkn6l1nq9pKckvXNDenX2/Kqkj9RaXybpFVoc+5a+1qWUKyT9uKSbaq1fL+l8ST+orX+tN705eg5L8/0snrfnsDRnz2Kew5vbHD2L5/k5LM3fs3iunsPS/D2LZxlx8FpJd9da76m1npH0AUlvn+H5Z6LW+kit9TNL7WNa/NJcocWxvm9ps/dJ+rsb0sGzqJRypaS/I+k3ln4ukt4s6YNLm2ypcZdS9kn6VknvlaRa65la6xHNwbWW9AJJO0spL5C0S9Ij2sLXeguZi+ewNL/P4nl7Dktz/SzmObx5zcWzeF6fw9L8PYvn+DkszdGzeJYvDq6Q9ID9/ODSZ1tWKeUaSa+SdIukS2utjyz96lFJl25Uv86id0v6KUnPLf18kaQjtdZnl37eatf8WkmPS/rNpVC03yil7NYWv9a11ock/bKkr2jx4fi0pFu1ta/1VjF3z2Fp7p7F79Z8PYelOXwW8xze9ObuWTxnz2Fp/p7Fc/cclubvWcziiGdJKWWPpN+T9M9rrUf9d3WxBuaWqoNZSnmbpEO11ls3ui8z9AJJr5b0a7XWV0k6oV4I1ha91ge0+Ab5WkmXS9ot6bs2tFNAME/P4jl9Dktz+CzmOYzNZJ6ew9LcPovn7jkszd+zeJYvDh6SdJX9fOXSZ1tOKeUCLT4g319r/f2ljx8rpVy29PvLJB3aqP6dJa+X9H2llPu0GHL3Zi3mOu1fCt2Rtt41f1DSg7XWW5Z+/qAWH5pb/Vq/VdK9tdbHa63PSPp9LV7/rXytt4q5eQ5Lc/ksnsfnsDSfz2Kew5vb3DyL5/A5LM3ns3gen8PSnD2LZ/ni4FOSXrq0yuQ2LS4c8eEZnn8mlnKY3ivpzlrrv7dffVjSO5ba75D0oVn37Wyqtf5srfXKWus1Wry2f1Jr/WFJN0v6/qXNttS4a62PSnqglHLD0kdvkfRFbfFrrcVwrG8qpexaut8n496y13oLmYvnsDSfz+J5fA5Lc/ss5jm8uc3Fs3gen8PSfD6L5/Q5LM3Zs7gsRo3M6GSlfI8Wc37Ol/Qfaq3/88xOPiOllDdI+nNJt+v5vKaf02JO1+9IerGk+yX9QK31yQ3p5FlWSnmTpH9Va31bKeUlWnzbelDSZyX9l7XW0xvYvXVVSnmlFhe+2SbpHkk/osUXclv6WpdS/q2kf6DFFZM/K+lHtZi/tWWv9VYxD89hiWfxPD2Hpfl8FvMc3tzm4Vk8789hab6exfP4HJbm61k80xcHAAAAAABgc2FxRAAAAAAAEPHiAAAAAAAARLw4AAAAAAAAES8OAAAAAABAxIsDAAAAAAAQ8eIAAAAAAABEvDgAAAAAAADR/w+m1AImaZWgjQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1296x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "case_num = -1\n",
    "model.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model.pth\")))\n",
    "# model.load_state_dict(torch.load('./best_metric_model.pth')) # PRETRAINED NETWORK\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    img_name = os.path.split(val_ds[case_num][\"image_meta_dict\"][\"filename_or_obj\"])[1]\n",
    "    img = val_ds[case_num][\"image\"]\n",
    "    label = val_ds[case_num][\"label\"]\n",
    "    val_inputs = torch.unsqueeze(img, 1).cuda()\n",
    "    val_labels = torch.unsqueeze(label, 1).cuda()\n",
    "    val_outputs = sliding_window_inference(\n",
    "        val_inputs, size, 4, model, overlap=0.8\n",
    "    )\n",
    "    plt.figure(\"check\", (18, 6))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"image\")\n",
    "    plt.imshow(val_inputs.cpu().numpy()[0, 0, :, :, slice_map[img_name]], cmap=\"gray\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"label\")\n",
    "    plt.imshow(val_labels.cpu().numpy()[0, 0, :, :, slice_map[img_name]])\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"output\")\n",
    "    plt.imshow(\n",
    "        torch.argmax(val_outputs, dim=1).detach().cpu()[0, :, :, slice_map[img_name]]\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot loss and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Iteration Average Loss\")\n",
    "x = [eval_num * (i + 1) for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.plot(x, y)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val Mean Dice\")\n",
    "x = [eval_num * (i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save segmentations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position(my_dict, key_dict, myvalue):\n",
    "    \n",
    "    for idx, element in enumerate(my_dict[key_dict]):\n",
    "        if myvalue.split('-')[0] in element:\n",
    "            return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.transform as skTrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model.pth\")))\n",
    "# model.load_state_dict(torch.load('./best_metric_model.pth')) # PRETRAINED NETWORK\n",
    "model.eval()\n",
    "for case_num in range(len(dictionary['validation'])): # len(dictionary['validation']) defined in JSON !!!\n",
    "    with torch.no_grad():\n",
    "        img_name = os.path.split(val_ds[case_num][\"image_meta_dict\"][\"filename_or_obj\"])[1]\n",
    "        img = val_ds[case_num][\"image\"]\n",
    "        label = val_ds[case_num][\"label\"]\n",
    "        val_inputs = torch.unsqueeze(img, 1).cuda()\n",
    "        val_labels = torch.unsqueeze(label, 1).cuda()\n",
    "        val_outputs = sliding_window_inference(\n",
    "            val_inputs, size, 4, model, overlap=0.8\n",
    "        )\n",
    "        result = torch.argmax(val_outputs, dim=1).detach().cpu()[0, :, :, :].permute(2,0,1).numpy()\n",
    "\n",
    "        pos = get_position(info_dict, 'Image name', img_name)\n",
    "\n",
    "        unresized_result = skTrans.resize(result, (\n",
    "            info_dict['Liver coordinates'][pos][1] - info_dict['Liver coordinates'][pos][0] + 1,\n",
    "            info_dict['Liver coordinates'][pos][3] - info_dict['Liver coordinates'][pos][2] + 1,\n",
    "            info_dict['Liver coordinates'][pos][5] - info_dict['Liver coordinates'][pos][4] + 1 \n",
    "        ), order = 1, preserve_range=True)\n",
    "\n",
    "        result = np.zeros(info_dict['Volume shape'][pos])\n",
    "        result[\n",
    "            info_dict['Liver coordinates'][pos][0]:info_dict['Liver coordinates'][pos][1] + 1,\n",
    "            info_dict['Liver coordinates'][pos][2]:info_dict['Liver coordinates'][pos][3] + 1,\n",
    "            info_dict['Liver coordinates'][pos][4]:info_dict['Liver coordinates'][pos][5] + 1 \n",
    "        ] = unresized_result\n",
    "        output_ima = nib.Nifti1Image(result, info_dict['Affine matrix'][pos], info_dict['Header'][pos])\n",
    "        nib.save(output_ima, './data/results/' + info_dict['Image name'][pos] + '_segmented.nii.gz')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "45c3df907f6fafbb712ed4f2b01c5915a78f4bdc42f991edc88ad8e94c7c5bec"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit ('PythonDocs_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
